{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cet technique marche beaucoup mieux que dans tensorflow, avec en très peu de temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "C'est quoi code défaut (4) -> Un code défaut ou DTC (pour Data Trouble Code anglais), ensemble chiffres suivant lettre correspondant à problème détecté votre véhicule\n",
      " (20)\n",
      "quoi Lab Program consiste (4) -> Le Lab Program notre cellule R&D. Elle vocation à penser co-constuire avec réponse à nouveaux besoins\n",
      " (16)\n",
      "veux contrôler l'activité mes collaborateurs (5) -> Consultez votre dashboard, mais restez vigilants avec législation vigueur assurez-vous d'être accord avec recommandations CNIL\n",
      " (15)\n",
      "Où car policy (3) -> Probablement dans coffre-fort administratif. Dans cas contraire, notre équipe peut accompagner à rédiger car c'est l'une nos compétences\n",
      " (18)\n",
      "C'est bon moteur (3) -> On peut considérer que oui, mais module motorisation offira d'autres alternatives moins onéreuse ou plus adapté\n",
      " (16)\n",
      "veux valeur résiduelle véhicule (4) -> La valeur véhicule doit être l'interprêtation son usage réel pendant son cycle vie dans l'entreprise.\n",
      " (15)\n",
      "Désignation conducteur (2) -> La désignation conducteur obligation légale relève constat d'une infraction routière. Plus précisions site l'ANTAI ou avec l'utilisation module #contravention#\n",
      " (19)\n",
      "Carnet santé véhicule (3) -> Le carnet santé véhicule permet considérer tous événements survenus depuis l'entrée véhicule dans votre parc. C'est document précieux qui apporte transparence confiance. Nous avons développé technologies utiles module spécifiques pour cela.\n",
      " (31)\n",
      "WLTP (1) -> Le WLTP s'attaque aux données consommations constructeurs. Un changement système mesures qui eu lieu 1er septembre 2017.ÊLes valeurs annoncées consommations d'émissions à l'échappement véhicules seront à lÕavenir plus proches conditions réelles dÕutilisation Merci Dieselgate\n",
      " (34)\n",
      "WPTL (1) -> Le WLTP s'attaque aux données consommations constructeurs. Un changement système mesures qui eu lieu 1er septembre 2017.ÊLes valeurs annoncées consommations d'émissions à l'échappement véhicules seront à lÕavenir plus proches conditions réelles dÕutilisation Merci Dieselgate\n",
      " (34)\n",
      "WTPL (1) -> Le WLTP s'attaque aux données consommations constructeurs. Un changement système mesures qui eu lieu 1er septembre 2017.ÊLes valeurs annoncées consommations d'émissions à l'échappement véhicules seront à lÕavenir plus proches conditions réelles dÕutilisation Merci Dieselgate\n",
      " (34)\n",
      "Nox (1) -> Notre module #RDE# pour Real-Driving Emissions vise à mesurer rejets deÊNOxÊ (oxyde dÕazote) particules fines\n",
      " (15)\n",
      "veux désigner conducteur (3) -> La désignation conducteur obligation légale relève constat d'une infraction routière. Plus précisions site l'ANTAI ou avec l'utilisation module #contravention#\n",
      " (19)\n",
      "veux éléctrifier flotte (3) -> Belle idée. Notre module développé avec notre partenaire #Vibratec# permettra comparer véhicules base leur TCO\n",
      " (15)\n",
      "Reading lines...\n",
      "Read 383 sentence pairs\n",
      "Trimmed to 369 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "questions 503\n",
      "answers 803\n",
      "[\"Votre module m'intéresse\", \"Merci. Voici l'accès store.\\n\"]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import data\n",
    "import config\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters except digits\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "#    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"[^a-zA-Z0-9.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(questions, answers, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    pairs = []   \n",
    "    encode_file = open(os.path.join(config.PROCESSED_PATH, \"question.txt\"), 'r')\n",
    "    decode_file = open(os.path.join(config.PROCESSED_PATH, \"answer.txt\"), 'r')\n",
    "    encode, decode = encode_file.readline(), decode_file.readline()\n",
    "    while encode and decode:\n",
    "        pairs.append([encode, decode])\n",
    "        encode, decode = encode_file.readline(), decode_file.readline()\n",
    "\n",
    "    \n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(answers)\n",
    "        output_lang = Lang(questions)\n",
    "    else:\n",
    "        input_lang = Lang(questions)\n",
    "        output_lang = Lang(answers)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "MAX_LENGTH = 15\n",
    "\n",
    "stopwords = ['de','d','le','la','l','du','d','ce','c','m','me','ma','si','t','sur'\\\n",
    "             'n','en','il', 'les','des','est','sont','s', 'a','y','au','un','une',\\\n",
    "             'on', 'nous', 'je', 'j','vous']\n",
    "\n",
    "def TrimWords(pairs):\n",
    "    for pair in pairs: #[pair for pair in pairs]:\n",
    "        resultwords  = [word for word in pair[0].split() if word.lower() not in stopwords]\n",
    "        pair[0] = ' '.join(resultwords)\n",
    "    return pairs\n",
    "\n",
    " \n",
    "def TrimWordsTest(question):\n",
    "    resultwords  = [word for word in question.split() if word.lower() not in stopwords]\n",
    "    question = ' '.join(resultwords)\n",
    "    return question\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH \n",
    "\n",
    "    \n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "input_lang, output_lang, pairs = readLangs('questions', 'answers', False)\n",
    "pairs = TrimWords(pairs)\n",
    "for pair in [pair for pair in pairs if not filterPair(pair)]:\n",
    "    print('%s (%d) -> %s (%d)' % (pair[0],len(pair[0].split(' ')),pair[1],len(pair[1].split(' ')))) #   \n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = TrimWords(pairs)\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('questions', 'answers', False)\n",
    "print(random.choice(pairs))\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)))#, dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]))#, dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "            return [lang.word2index[word]  for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  # SOS\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=15):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "def chat():\n",
    "    print('Bonjour, c\\'est le Bot AVICEN, dites ce que vous voulez: ')\n",
    "    encoder, decoder = encoder1, attn_decoder1\n",
    "    output_file = open(os.path.join(config.PROCESSED_PATH, config.OUTPUT_FILE), 'a+')\n",
    "    #pharse = str(input('Bonjour, c\\'est le Bot de AVICEN, dites ce que vous voulez: '))\n",
    "    while True:\n",
    "            line = str(input('Vous: '))\n",
    "            if len(line) > 0 and line[-1] == '\\n':\n",
    "                line = line[:-1]\n",
    "            if line == '':\n",
    "                break\n",
    "            output_file.write('VOUS ++++ ' + line + '\\n')\n",
    "            reponse, _ = evaluate(encoder, decoder, line)\n",
    "            print('Bot AVICEN: ', reponse)\n",
    "            print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:201: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:212: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 4s (- 2m 53s) (500 2%) 3.9696\n",
      "0m 8s (- 2m 41s) (1000 5%) 3.5957\n",
      "0m 12s (- 2m 39s) (1500 7%) 3.6403\n",
      "0m 17s (- 2m 36s) (2000 10%) 3.7000\n",
      "0m 21s (- 2m 32s) (2500 12%) 3.4956\n",
      "0m 26s (- 2m 28s) (3000 15%) 3.3991\n",
      "0m 30s (- 2m 25s) (3500 17%) 3.5170\n",
      "0m 35s (- 2m 22s) (4000 20%) 3.4029\n",
      "0m 40s (- 2m 18s) (4500 22%) 3.0996\n",
      "0m 44s (- 2m 14s) (5000 25%) 2.9740\n",
      "0m 49s (- 2m 11s) (5500 27%) 2.7840\n",
      "0m 54s (- 2m 7s) (6000 30%) 2.7435\n",
      "0m 59s (- 2m 3s) (6500 32%) 2.4437\n",
      "1m 4s (- 2m 0s) (7000 35%) 2.1432\n",
      "1m 9s (- 1m 56s) (7500 37%) 2.1278\n",
      "1m 14s (- 1m 52s) (8000 40%) 1.9263\n",
      "1m 20s (- 1m 48s) (8500 42%) 1.7359\n",
      "1m 25s (- 1m 43s) (9000 45%) 1.5228\n",
      "1m 30s (- 1m 39s) (9500 47%) 1.4590\n",
      "1m 35s (- 1m 35s) (10000 50%) 1.2238\n",
      "1m 40s (- 1m 31s) (10500 52%) 1.0189\n",
      "1m 46s (- 1m 26s) (11000 55%) 0.9942\n",
      "1m 51s (- 1m 22s) (11500 57%) 0.7227\n",
      "1m 56s (- 1m 17s) (12000 60%) 0.6761\n",
      "2m 2s (- 1m 13s) (12500 62%) 0.6204\n",
      "2m 7s (- 1m 8s) (13000 65%) 0.4929\n",
      "2m 13s (- 1m 4s) (13500 67%) 0.3912\n",
      "2m 18s (- 0m 59s) (14000 70%) 0.3732\n",
      "2m 23s (- 0m 54s) (14500 72%) 0.3371\n",
      "2m 28s (- 0m 49s) (15000 75%) 0.2412\n",
      "2m 34s (- 0m 44s) (15500 77%) 0.2567\n",
      "2m 39s (- 0m 39s) (16000 80%) 0.2148\n",
      "2m 45s (- 0m 35s) (16500 82%) 0.1918\n",
      "2m 50s (- 0m 30s) (17000 85%) 0.1612\n",
      "2m 56s (- 0m 25s) (17500 87%) 0.1988\n",
      "3m 1s (- 0m 20s) (18000 90%) 0.1390\n",
      "3m 7s (- 0m 15s) (18500 92%) 0.1307\n",
      "3m 12s (- 0m 10s) (19000 95%) 0.1248\n",
      "3m 17s (- 0m 5s) (19500 97%) 0.1082\n",
      "3m 23s (- 0m 0s) (20000 100%) 0.1258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 100\n",
    " \n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                               1, dropout_p=0.1)\n",
    "\n",
    "if use_cuda:\n",
    "    encoder1 = encoder1.cuda()\n",
    "    attn_decoder1 = attn_decoder1.cuda()\n",
    "trainIters(encoder1, attn_decoder1, 20000, print_every=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir(path):\n",
    "    \"\"\" Create a directory if there isn't one already. \"\"\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "def save_model(encoder, decoder):        \n",
    "    make_dir(config.CHECK_POINT_PATH)\n",
    "    path1= os.path.join(config.CHECK_POINT_PATH, 'encoder_try.ck')\n",
    "    path2 = os.path.join(config.CHECK_POINT_PATH, 'decoder_try.ck')\n",
    "    try: \n",
    "        os.remove(path1);   os.remove(path2)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    torch.save(encoder,path1)\n",
    "    torch.save(decoder, path2)\n",
    "def restore_model():\n",
    "    hidden_size = config.HIDDEN_SIZE\n",
    "    path1 = os.path.join(config.CHECK_POINT_PATH, 'encoder_try.ck')\n",
    "    path2 = os.path.join(config.CHECK_POINT_PATH, 'decoder_try.ck')\n",
    "    if os.path.isdir(path1)and os.path.isdir(path2):\n",
    "        encoder = torch.load(path1)\n",
    "        decoder = torch.load(path2)\n",
    "    else:\n",
    "        encoder = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "        decoder = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                               1, dropout_p=0.1)\n",
    "\n",
    "    if use_cuda:\n",
    "        encoder = encoder.cuda()\n",
    "        decoder = decoder.cuda()\n",
    "    return encoder, decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type EncoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class '__main__.EncoderRNN'>: it's not the same object as __main__.EncoderRNN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-332afce1364a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#encoder2, decoder2 = restore_model()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-7365665b2ba8>\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(encoder, decoder)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrestore_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0mto\u001b[0m \u001b[0moverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0mto\u001b[0m \u001b[0moverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0mserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_storages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class '__main__.EncoderRNN'>: it's not the same object as __main__.EncoderRNN"
     ]
    }
   ],
   "source": [
    "save_model(encoder1, attn_decoder1)\n",
    "#encoder2, decoder2 = restore_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Valeur rachat véhicule\n",
      "= La valeur résiduelle véhicule spécifiée dans votre contrat location\n",
      "\n",
      "< La valeur résiduelle véhicule spécifiée dans votre contrat location\n",
      " <EOS>\n",
      "\n",
      "> souhaite voir où localisés véhicules\n",
      "= Consultez votre dashboard\n",
      "\n",
      "< Consultez votre dashboard\n",
      " <EOS>\n",
      "\n",
      "> Quel planning tournées\n",
      "= Patience. Cette fonction cours développement\n",
      "\n",
      "< Patience. Cette fonction cours développement\n",
      " <EOS>\n",
      "\n",
      "> Quel véhicule disponible dans 1H\n",
      "= Vous pouvez servir #list_vin_immediat#\n",
      "\n",
      "< Vous pouvez servir #list_vin_immediat#\n",
      " <EOS>\n",
      "\n",
      "> TCO véhicule électrique\n",
      "= Nous travaillons actuellement sujet dans cadre d'un consortium franco-allemand. Nous tenons informés ces développements\n",
      "\n",
      "< Nous travaillons actuellement sujet dans cadre d'un consortium franco-allemand. Nous tenons informés ces développements\n",
      " <EOS>\n",
      "\n",
      "> Pourquoi module\n",
      "= Le module #list_module# à pour objectif #detail_module# Le module #list_module# à pour objectif #detail_module#\n",
      "\n",
      "< Le module #list_module# à pour objectif #detail_module# Le module #list_module# à pour objectif #detail_module#\n",
      " <EOS>\n",
      "\n",
      "> Combien kilomètres fait véhicule cette année\n",
      "= Le kilomètrage annuel #km#\n",
      "\n",
      "< Le kilomètrage annuel #km#\n",
      " <EOS>\n",
      "\n",
      "> veux réduire consommations\n",
      "= Super. Comment puis-je aider\n",
      "\n",
      "< Super. Comment puis-je aider\n",
      " <EOS>\n",
      "\n",
      "> Coût d'usage flotte\n",
      "= Le coût #tco_fleet#\n",
      "\n",
      "< Le coût #tco_fleet#\n",
      " <EOS>\n",
      "\n",
      "> Combien kilomètres fait véhicule\n",
      "= Ce véhicule effectué #km#\n",
      "\n",
      "< Ce véhicule effectué #km#\n",
      " <EOS>\n",
      "\n",
      "> Quels indicateurs\n",
      "= Quels indicateurs dont avez besoin\n",
      "\n",
      "< Quels indicateurs dont avez besoin\n",
      " <EOS>\n",
      "\n",
      "> Combien voitures\n",
      "= Il #nb_véhicules#\n",
      "\n",
      "< Il #nb_véhicules#\n",
      " <EOS>\n",
      "\n",
      "> liens avec mobilité\n",
      "= Forte synergie entre acteurs monde professionnel\n",
      "\n",
      "< Forte synergie entre acteurs monde professionnel\n",
      " <EOS>\n",
      "\n",
      "> Respectons-nous échéances\n",
      "= Il convient préciser nature échéances qui importent révision, maintenance, restitution É\n",
      "\n",
      "< Il convient préciser nature échéances qui importent révision, maintenance, restitution É\n",
      " <EOS>\n",
      "\n",
      "> boitier HS\n",
      "= Ne tardez pas à prévenir. Il probable qu'un ticket incident été communiqué.\n",
      "\n",
      "< Nous prenons compte cet incident. Merci préciser son numéro série\n",
      " <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:201: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:212: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, c'est le Bot AVICEN, dites ce que vous voulez: \n",
      "Vous: bonjour\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:201: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:212: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot AVICEN:  ['La', 'révision', 'aura', 'lieu', '<EOS>']\n",
      "--------------------------------------------------\n",
      "Vous: où est ma voiture\n",
      "Bot AVICEN:  ['Par', 'pouvez', 'adresser', 'à', 'partir', 'votre', 'dashboard\\n', '<EOS>']\n",
      "--------------------------------------------------\n",
      "Vous: combien de voiture\n",
      "Bot AVICEN:  ['Par', 'performance,', 'entendez', 'TCO\\n', '<EOS>']\n",
      "--------------------------------------------------\n",
      "Vous: bonjour madame\n",
      "Bot AVICEN:  ['La', 'révision', 'aura', 'lieu', '#date#\\n', '<EOS>']\n",
      "--------------------------------------------------\n",
      "Vous: bonjour monsieur\n",
      "Bot AVICEN:  ['Cordialement\\n', '<EOS>']\n",
      "--------------------------------------------------\n",
      "Vous: \n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(TrimWordsTest(\"a quelle date est la rentree 2018 ?\"))\n",
    "evaluateAndShowAttention(TrimWordsTest(\"ce m2 prepare a quel metier ?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
