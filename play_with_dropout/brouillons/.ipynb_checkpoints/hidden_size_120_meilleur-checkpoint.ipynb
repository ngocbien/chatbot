{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cet technique marche beaucoup mieux que dans tensorflow, avec en très peu de temps.\n",
    "Ce modèle fonctionne mieux que l'autre dans tensorflow parce qu'une raison évidente: il utilise méthode teacher forcing\n",
    "Un autre problème avec ce méthode, c'est dropout qui donne une technique plus ou moins bon. Il donne la réponse plus tôt aléatoire pour une question. En cas général, ce la peut être intéressant, mais dans notre cas, il est très important qu'il capture le mot clés (donc, surtout on risque de  supprimer le mot clés, qui rendra une mauvais réponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Pour lancer un chat, il suffit de taper en même temps CTRL et ENTER"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Pour arrêter le mode chat, il suffit de taper ENTER dans votre conversation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cet technique marche beaucoup mieux que dans tensorflow, avec en très peu de temps. \n",
    "Ce modèle fonctionne mieux que l'autre dans tensorflow parce qu'une raison évidente: \n",
    "il utilise méthode teacher forcing Un autre problème avec ce méthode, \n",
    "c'est dropout qui donne une technique plus ou moins bon. Il donne la \n",
    "réponse plus tôt aléatoire pour une question. En cas général, \n",
    "ce la peut être intéressant, mais dans notre cas, il est très important \n",
    "qu'il capture le mot clés \n",
    "(donc, surtout on risque de supprimer le mot clés, qui rendra une mauvais réponse)\n",
    "modèle est bien entrainé, donc, il ne sert à rien d'entrainer encore.\n",
    "hidden_size =45 tres mauvais; =70 bien; =100 tres bien; =120 très bien; =150 overfit.\n",
    "\"\"\"\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(\"### Pour lancer un chat, il suffit de taper en même temps CTRL et ENTER\"))\n",
    "display(Markdown(\"### Pour arrêter le mode chat, il suffit de taper ENTER dans votre conversation\"))\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import data\n",
    "import config\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "hidden_size = 120\n",
    "SOS_token  = config.SOS_token\n",
    "EOS_token  = config.EOS_token\n",
    "MAX_LENGTH = config.MAX_LENGTH\n",
    "stopwords  = config.STOPWORDS\n",
    "learning_rate = config.LEARNING_RATE\n",
    "teacher_forcing_ratio = config.TEACHER_FORCING\n",
    "dropout = config.DROPOUT\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  \n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "def normalizeString(s):\n",
    "    \"\"\"\n",
    "    Whith a tring s, we make it in lower case, delete \\n if exists at \n",
    "    the end of string, and delete specical case ? . and !\n",
    "    \"\"\"\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([,.!?\\n])\", r\"\", s)# sumprimer tous les caractères .! et ?\n",
    "    #s = re.sub(r\"[^a-zA-Z0-9.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(questions, answers, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    pairs = []   \n",
    "    encode_file = open(os.path.join(config.PROCESSED_PATH, \"question.txt\"), 'r')\n",
    "    decode_file = open(os.path.join(config.PROCESSED_PATH, \"answer.txt\"), 'r')\n",
    "    encode, decode = encode_file.readline(), decode_file.readline()\n",
    "    while encode and decode:\n",
    "        encode, decode = normalizeString(encode), normalizeString(decode)\n",
    "        pairs.append([encode, decode])\n",
    "        encode, decode = encode_file.readline(), decode_file.readline()\n",
    "\n",
    "    \n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(answers)\n",
    "        output_lang = Lang(questions)\n",
    "    else:\n",
    "        input_lang = Lang(questions)\n",
    "        output_lang = Lang(answers)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def TrimWords(pairs):\n",
    "    for pair in pairs: #[pair for pair in pairs]:\n",
    "        resultwords  = [word for word in pair[0].split() if word.lower() not in stopwords]\n",
    "        pair[0] = ' '.join(resultwords)\n",
    "    return pairs\n",
    "\n",
    " \n",
    "def TrimWordsTest(question):\n",
    "    resultwords  = [word for word in question.split() if word.lower() not in stopwords]\n",
    "    question = ' '.join(resultwords)\n",
    "    return question\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH \n",
    "\n",
    "    \n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = TrimWords(pairs)\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=dropout, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        #embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)))#, dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]))#, dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "def closetWord(word, lang):\n",
    "    \"\"\"\n",
    "    find and return the closest word in lang\n",
    "    \"\"\"\n",
    "    Dict = lang.word2index\n",
    "    corpus = lang.index2word\n",
    "    if word in Dict:\n",
    "        return word\n",
    "    else:\n",
    "        distance = levenshtein(word, corpus[0])\n",
    "        close_word = corpus[0]\n",
    "        for ix in corpus:\n",
    "            if levenshtein(word, corpus[ix]) <distance:\n",
    "                close_word = corpus[ix]\n",
    "                distance = levenshtein(word, corpus[ix])\n",
    "        if distance <=1:\n",
    "            return close_word\n",
    "        else:\n",
    "            return word\n",
    "def normalizeSentenceInChat(sentence):\n",
    "    sentence = sentence.strip().lower().split()\n",
    "    s = [closetWord(word, input_lang) for word in sentence]\n",
    "    return ' '.join(s)\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    #sentence = normalizeSentence\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index ]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(n_iters, print_every=1000, plot_every=100, learning_rate=learning_rate):\n",
    "    encoder, decoder = restore_model()\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    save_model(encoder, decoder)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    #sentence = normalizeSentenceInChat(sentence)\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  \n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        ni = int(ni)\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "def evaluateRandomly(n):\n",
    "    encoder, decoder = restore_model()\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('Question: ', pair[0])\n",
    "        print('Réponse: ', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words[:-1])\n",
    "        print('Bot: ', output_sentence)\n",
    "        print('-'*50)\n",
    "        \n",
    "def make_dir(path):\n",
    "    \"\"\" Create a directory if there isn't one already. \"\"\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "def save_model(encoder, decoder):        \n",
    "    make_dir(config.CHECK_POINT_PATH)\n",
    "    path1= os.path.join(config.CHECK_POINT_PATH, 'encoder_120.ck')\n",
    "    path2 = os.path.join(config.CHECK_POINT_PATH, 'decoder_120.ck')\n",
    "    try: \n",
    "        os.remove(path1)  \n",
    "        os.remove(path2)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    torch.save(encoder,path1)\n",
    "    torch.save(decoder, path2)\n",
    "    \n",
    "memo = {}\n",
    "def levenshtein(s, t):\n",
    "    \"\"\"\n",
    "    Pour calculer la distance  Levenshtein entre 2 string s et t\n",
    "    \"\"\"\n",
    "    if s == \"\":\n",
    "        return len(t)\n",
    "    if t == \"\":\n",
    "        return len(s)\n",
    "    cost = 0 if s[-1] == t[-1] else 1\n",
    "       \n",
    "    i1 = (s[:-1], t)\n",
    "    if not i1 in memo:\n",
    "        memo[i1] = levenshtein(*i1)\n",
    "    i2 = (s, t[:-1])\n",
    "    if not i2 in memo:\n",
    "        memo[i2] = levenshtein(*i2)\n",
    "    i3 = (s[:-1], t[:-1])\n",
    "    if not i3 in memo:\n",
    "        memo[i3] = levenshtein(*i3)\n",
    "    res = min([memo[i1]+1, memo[i2]+1, memo[i3]+cost])\n",
    "    \n",
    "    return res\n",
    "    \n",
    "def restore_model():\n",
    "    #hidden_size = hidden_size\n",
    "    path1 = os.path.join(config.CHECK_POINT_PATH, 'encoder_120.ck')\n",
    "    path2 = os.path.join(config.CHECK_POINT_PATH, 'decoder_120.ck')\n",
    "    if os.path.exists(path1)and os.path.exists(path2):\n",
    "        print('Reading the parameters from {}...'.format(config.CHECK_POINT_PATH))\n",
    "        encoder = torch.load(path1)\n",
    "        decoder = torch.load(path2)\n",
    "    else:\n",
    "        print('Initializing fresh parameters...')\n",
    "        encoder = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "        decoder = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                               1, dropout_p=0.1)\n",
    "\n",
    "    if use_cuda:\n",
    "        encoder = encoder.cuda()\n",
    "        decoder = decoder.cuda()\n",
    "    return encoder, decoder  \n",
    "\n",
    "def construct_dict(lang):\n",
    "    in_file = open(os.path.join(config.PROCESSED_PATH, 'dictionnary.txt'), 'r')\n",
    "    lines = []\n",
    "    dicts = lang.word2index.copy()\n",
    "    for line in in_file:\n",
    "        line = line.strip().split('|')\n",
    "        for word in dicts:\n",
    "            if str(word) in line and len(word)>0:\n",
    "                line.insert(0,str(word))\n",
    "                lines.append(line)\n",
    "                del dicts[str(word)]\n",
    "                break\n",
    "    return lines\n",
    "def find_close_line(lines, lang, line):\n",
    "    LINE = []\n",
    "    for word in line.strip().split():\n",
    "        if word in lang.word2index:\n",
    "            LINE.append(word)\n",
    "        else:\n",
    "            for pharse in lines:\n",
    "                if word in pharse:\n",
    "                    LINE.append(pharse[0])\n",
    "                    break\n",
    "    return ' '.join(LINE)\n",
    "\n",
    "def chat():\n",
    "    encoder, decoder = restore_model()\n",
    "    make_dir(config.CHECK_POINT_PATH)\n",
    "    lines = construct_dict(input_lang)\n",
    "    output_file = open(os.path.join(config.CHECK_POINT_PATH, 'convos120.txt'), 'a+')\n",
    "    print('Bonjour, c\\'est le Bot d\\'AVICEN, Je peux vous aider? \\n')\n",
    "    while True:\n",
    "            line = str(input('Vous: '))\n",
    "            if len(line) > 0 and line[-1] == '\\n':\n",
    "                line = line[:-1]\n",
    "            if line == '':\n",
    "                break\n",
    "            line = normalizeString(line)\n",
    "            line  = normalizeSentenceInChat(line)\n",
    "            line = find_close_line(lines, input_lang, line)\n",
    "            print('LIGNE TRANFORMÉ: ', line)\n",
    "            output_file.write('VOUS ++++ ' + line + '\\n')\n",
    "            reponse, _ = evaluate(encoder, decoder, line)\n",
    "            reponse = \" \".join(reponse[:-1])\n",
    "            output_file.write('BOT ++++ ' + reponse + '\\n')\n",
    "            print('Bot AVICEN: ', reponse)\n",
    "            print('-'*50)\n",
    "    output_file.close()\n",
    "try:\n",
    "    input_lang\n",
    "except NameError : \n",
    "    input_lang, output_lang, pairs = readLangs('questions', 'answers', False)\n",
    "    pairs = TrimWords(pairs) \n",
    "    input_lang, output_lang, pairs = prepareData('questions', 'answers', False)\n",
    "    \n",
    "def langTest():\n",
    "    pairs_test = []   \n",
    "    test_file = open(os.path.join(config.PROCESSED_PATH, \"test.txt\"), 'r')\n",
    "    i=0\n",
    "    for line in test_file:\n",
    "        line = normalizeString(line)\n",
    "        if i%2 ==0:\n",
    "            question = line\n",
    "        else:\n",
    "            answer = line\n",
    "            pairs_test.append([question, answer])\n",
    "        i +=1\n",
    "    return pairs_test  \n",
    "\n",
    "def test(pairs_test):\n",
    "    \"\"\"\n",
    "    Use test for know how our model is good\n",
    "    \"\"\"\n",
    "    encoder, decoder = restore_model()\n",
    "    total_loss = 0\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "    for pair in pairs_test:\n",
    "        variable = variablesFromPair(pair)\n",
    "        loss = train( variable[0], variable[1], encoder, decoder, encoder_optimizer, decoder_optimizer,\\\n",
    "                     criterion= criterion)\n",
    "        total_loss +=loss\n",
    "    Length_inputs = len(pairs_test) if len(pairs_test) !=0 else 1\n",
    "    return total_loss/Length_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the parameters from check_point...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:203: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:214: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:326: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 11s (- 0m 22s) (1000 33%) 0.0421\n",
      "0m 22s (- 0m 11s) (2000 66%) 0.0336\n",
      "0m 33s (- 0m 0s) (3000 100%) 0.0496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type EncoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type AttnDecoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainIters(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [1, 2], [1, 2], [1, 2], [1, 2], [1, 2]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a= []\n",
    "a.append([1,2])\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
