{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cet technique marche beaucoup mieux que dans tensorflow, avec en très peu de temps. \n",
    "Ce modèle fonctionne mieux que l'autre dans tensorflow parce qu'une raison évidente: \n",
    "il utilise méthode teacher forcing Un autre problème avec ce méthode, \n",
    "c'est dropout qui donne une technique plus ou moins bon. Il donne la \n",
    "réponse plus tôt aléatoire pour une question. En cas général, \n",
    "ce la peut être intéressant, mais dans notre cas, il est très important \n",
    "qu'il capture le mot clés \n",
    "(donc, surtout on risque de supprimer le mot clés, qui rendra une mauvais réponse)\n",
    "modèle est bien entrainé, donc, il ne sert à rien d'entrainer encore.\n",
    "hidden_size =45 tres mauvais; =70 bien; =100 tres bien; =120 très bien; =150 overfit.\n",
    "\"\"\"\n",
    "#from IPython.display import display, Markdown\n",
    "#display(Markdown(\"### Pour lancer un chat, il suffit de taper en même temps CTRL et ENTER\"))\n",
    "#display(Markdown(\"### Pour arrêter le mode chat, il suffit de taper ENTER dans votre conversation\"))\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import data\n",
    "import config\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "hidden_size = 120\n",
    "SOS_token  = config.SOS_token\n",
    "EOS_token  = config.EOS_token\n",
    "MAX_LENGTH = config.MAX_LENGTH\n",
    "stopwords  = config.STOPWORDS\n",
    "learning_rate = config.LEARNING_RATE\n",
    "teacher_forcing_ratio = config.TEACHER_FORCING\n",
    "dropout = config.DROPOUT\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  \n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "def normalizeString(s):\n",
    "    \"\"\"\n",
    "    Whith a tring s, we make it in lower case, delete \\n if exists at \n",
    "    the end of string, and delete specical case ? . and !\n",
    "    \"\"\"\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([,.!?\\n])\", r\"\", s)# sumprimer tous les caractères .! et ?\n",
    "    #s = re.sub(r\"[^a-zA-Z0-9.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(questions, answers, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    pairs = []   \n",
    "    encode_file = open(os.path.join(config.PROCESSED_PATH, \"question.txt\"), 'r')\n",
    "    decode_file = open(os.path.join(config.PROCESSED_PATH, \"answer.txt\"), 'r')\n",
    "    encode, decode = encode_file.readline(), decode_file.readline()\n",
    "    while encode and decode:\n",
    "        encode, decode = normalizeString(encode), normalizeString(decode)\n",
    "        pairs.append([encode, decode])\n",
    "        encode, decode = encode_file.readline(), decode_file.readline()\n",
    "\n",
    "    \n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(answers)\n",
    "        output_lang = Lang(questions)\n",
    "    else:\n",
    "        input_lang = Lang(questions)\n",
    "        output_lang = Lang(answers)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def TrimWords(pairs):\n",
    "    for pair in pairs: #[pair for pair in pairs]:\n",
    "        resultwords  = [word for word in pair[0].split() if word.lower() not in stopwords]\n",
    "        pair[0] = ' '.join(resultwords)\n",
    "    return pairs\n",
    "\n",
    " \n",
    "def TrimWordsTest(question):\n",
    "    resultwords  = [word for word in question.split() if word.lower() not in stopwords]\n",
    "    question = ' '.join(resultwords)\n",
    "    return question\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH \n",
    "\n",
    "    \n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = TrimWords(pairs)\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=dropout, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        #embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)))#, dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]))#, dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "        \n",
    "def closetWord(word, lang):\n",
    "    \"\"\"\n",
    "    find and return the closest word in lang\n",
    "    \"\"\"\n",
    "    Dict = lang.word2index\n",
    "    corpus = lang.index2word\n",
    "    if word in Dict:\n",
    "        return word\n",
    "    else:\n",
    "        distance = levenshtein(word, corpus[0])\n",
    "        close_word = corpus[0]\n",
    "        for ix in corpus:\n",
    "            if levenshtein(word, corpus[ix]) <distance:\n",
    "                close_word = corpus[ix]\n",
    "                distance = levenshtein(word, corpus[ix])\n",
    "        if distance <=1:\n",
    "            return close_word\n",
    "        else:\n",
    "            return word\n",
    "        \n",
    "def normalizeSentenceInChat(sentence):\n",
    "    sentence = sentence.strip().lower().split()\n",
    "    s = [closetWord(word, input_lang) for word in sentence]\n",
    "    return ' '.join(s)\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    #sentence = normalizeSentence\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index ]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "def get_skip_step(n_iters):\n",
    "    return int(n_iters/10)\n",
    "\n",
    "def trainIters(n_iters, plot_every=100, learning_rate=learning_rate):\n",
    "    encoder, decoder = restore_model()\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    skip_step = get_skip_step(n_iters)\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(training_set))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % skip_step == 0:\n",
    "            print_loss_avg = print_loss_total / skip_step\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    save_model(encoder, decoder)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    #sentence = normalizeSentenceInChat(sentence)\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  \n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        ni = int(ni)\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "def evaluate_randomly(n_iters=30, test=True):\n",
    "    encoder, decoder = restore_model()\n",
    "    if not test:\n",
    "        for i in range(n_iters):\n",
    "            pair = random.choice(pairs)\n",
    "            print('Question: ', pair[0])\n",
    "            print('Réponse: ', pair[1])\n",
    "            output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "            output_sentence = ' '.join(output_words[:-1])\n",
    "            print('Bot: ', output_sentence)\n",
    "            print('-'*50)\n",
    "    else:\n",
    "        n_iters = len(test_set)\n",
    "        total_loss = 0\n",
    "        for i in range(n_iters):\n",
    "            pair = test_set[i]\n",
    "            print('Question: ', pair[0])\n",
    "            print('Réponse: ', pair[1])\n",
    "            output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "            reponse = ' '.join(output_words[:-1])\n",
    "            loss = _evaluate_by_right_word(pair[1], reponse)\n",
    "            print('Bot: {}. ACCURACY {:.1f}'.format(reponse, 1-loss))\n",
    "            total_loss +=loss\n",
    "            print('-'*50)\n",
    "        print('Test on {}'.format(n_iters))\n",
    "        print('Accuracy by percent of true words {}'.format(1-total_loss/n_iters))\n",
    "       \n",
    "    \n",
    "def _evaluate_by_right_word(reponse, bonne_reponse):\n",
    "    reponse = reponse.split()\n",
    "    bonne_reponse = bonne_reponse.split()\n",
    "    min_length = min(len(reponse), len(bonne_reponse))\n",
    "    max_length = max(len(reponse), len(bonne_reponse))\n",
    "    error = max_length-min_length\n",
    "    for i in range(min_length):\n",
    "        if reponse[i] != bonne_reponse[i]:\n",
    "            error +=1\n",
    "    return error/max_length      \n",
    "        \n",
    "def make_dir(path):\n",
    "    \"\"\" Create a directory if there isn't one already. \"\"\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "def save_model(encoder, decoder):        \n",
    "    make_dir(config.CHECK_POINT_PATH)\n",
    "    path1= os.path.join(config.CHECK_POINT_PATH, 'encoder_120.ck')\n",
    "    path2 = os.path.join(config.CHECK_POINT_PATH, 'decoder_120.ck')\n",
    "    try: \n",
    "        os.remove(path1)  \n",
    "        os.remove(path2)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    torch.save(encoder,path1)\n",
    "    torch.save(decoder, path2)\n",
    "    \n",
    "memo = {}\n",
    "def levenshtein(s, t):\n",
    "    \"\"\"\n",
    "    Pour calculer la distance  Levenshtein entre 2 string s et t\n",
    "    \"\"\"\n",
    "    if s == \"\":\n",
    "        return len(t)\n",
    "    if t == \"\":\n",
    "        return len(s)\n",
    "    cost = 0 if s[-1] == t[-1] else 1\n",
    "       \n",
    "    i1 = (s[:-1], t)\n",
    "    if not i1 in memo:\n",
    "        memo[i1] = levenshtein(*i1)\n",
    "    i2 = (s, t[:-1])\n",
    "    if not i2 in memo:\n",
    "        memo[i2] = levenshtein(*i2)\n",
    "    i3 = (s[:-1], t[:-1])\n",
    "    if not i3 in memo:\n",
    "        memo[i3] = levenshtein(*i3)\n",
    "    res = min([memo[i1]+1, memo[i2]+1, memo[i3]+cost])\n",
    "    \n",
    "    return res\n",
    "    \n",
    "def restore_model():\n",
    "    #hidden_size = hidden_size\n",
    "    path1 = os.path.join(config.CHECK_POINT_PATH, 'encoder_120.ck')\n",
    "    path2 = os.path.join(config.CHECK_POINT_PATH, 'decoder_120.ck')\n",
    "    if os.path.exists(path1)and os.path.exists(path2):\n",
    "        print('Reading the parameters from {} and {}...'.format(path1, path2))\n",
    "        encoder = torch.load(path1)\n",
    "        decoder = torch.load(path2)\n",
    "    else:\n",
    "        print('Initializing fresh parameters...')\n",
    "        encoder = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "        decoder = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                               1, dropout_p=0.1)\n",
    "\n",
    "    if use_cuda:\n",
    "        encoder = encoder.cuda()\n",
    "        decoder = decoder.cuda()\n",
    "    return encoder, decoder  \n",
    "\n",
    "def construct_dict(lang):\n",
    "    in_file = open(os.path.join(config.PROCESSED_PATH, 'dictionnary.txt'), 'r')\n",
    "    lines = []\n",
    "    dicts = lang.word2index.copy()\n",
    "    for line in in_file:\n",
    "        line = line.strip().split('|')\n",
    "        for word in dicts:\n",
    "            if str(word) in line and len(word)>0:\n",
    "                line.insert(0,str(word))\n",
    "                lines.append(line)\n",
    "                del dicts[str(word)]\n",
    "                break\n",
    "    return lines\n",
    "\n",
    "def find_close_line(lines, lang, line):\n",
    "    LINE = []\n",
    "    for word in line.strip().split():\n",
    "        if word in lang.word2index:\n",
    "            LINE.append(word)\n",
    "        else:\n",
    "            for pharse in lines:\n",
    "                if word in pharse:\n",
    "                    LINE.append(pharse[0])\n",
    "                    break\n",
    "    return ' '.join(LINE)\n",
    "\n",
    "def chat():\n",
    "    encoder, decoder = restore_model()\n",
    "    make_dir(config.CHECK_POINT_PATH)\n",
    "    lines = construct_dict(input_lang)\n",
    "    output_file = open(os.path.join(config.CHECK_POINT_PATH, 'convos120.txt'), 'a+')\n",
    "    print('Bonjour, c\\'est le Bot d\\'AVICEN, Je peux vous aider? \\n')\n",
    "    while True:\n",
    "            line = str(input('Vous: '))\n",
    "            if len(line) > 0 and line[-1] == '\\n':\n",
    "                line = line[:-1]\n",
    "            if line == '':\n",
    "                break\n",
    "            line = normalizeString(line)\n",
    "            line  = normalizeSentenceInChat(line)\n",
    "            line = find_close_line(lines, input_lang, line)\n",
    "            print('LIGNE TRANFORMÉ: ', line)\n",
    "            output_file.write('VOUS ++++ ' + line + '\\n')\n",
    "            reponse, _ = evaluate(encoder, decoder, line)\n",
    "            reponse = \" \".join(reponse[:-1])\n",
    "            output_file.write('BOT ++++ ' + reponse + '\\n')\n",
    "            print('Bot AVICEN: ', reponse)\n",
    "            print('-'*50)\n",
    "    output_file.close()\n",
    "    \n",
    "def langTest():\n",
    "    pairs_test = []   \n",
    "    test_file = open(os.path.join(config.PROCESSED_PATH, \"test.txt\"), 'r')\n",
    "    i=0\n",
    "    for line in test_file:\n",
    "        line = normalizeString(line)\n",
    "        if i%2 ==0:\n",
    "            question = line\n",
    "        else:\n",
    "            answer = line\n",
    "            pairs_test.append([question, answer])\n",
    "        i +=1\n",
    "    return pairs_test  \n",
    "\n",
    "def test(pairs_test):\n",
    "    \"\"\"\n",
    "    Use test for know how our model is good\n",
    "    \"\"\"\n",
    "    encoder, decoder = restore_model()\n",
    "    total_loss = 0\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "    for pair in pairs_test:\n",
    "        variable = variablesFromPair(pair)\n",
    "        loss = train( variable[0], variable[1], encoder, decoder, encoder_optimizer, decoder_optimizer,\\\n",
    "                     criterion= criterion)\n",
    "        total_loss +=loss\n",
    "    Length_inputs = len(pairs_test) if len(pairs_test) !=0 else 1\n",
    "    return total_loss/Length_inputs\n",
    "\n",
    "def construct_train_test_set(pairs):\n",
    "    max_length = len(pairs)\n",
    "    portion_of_train = int(max_length*0.85)\n",
    "    index_of_train = random.sample(range(max_length), portion_of_train)\n",
    "    train, test = [], []\n",
    "    for index in range(max_length):\n",
    "        if index in index_of_train:\n",
    "            train.append(pairs[index])\n",
    "        else:\n",
    "            test.append(pairs[index])\n",
    "    return train, test\n",
    "\n",
    "if __name__=='__main__':\n",
    "    try:\n",
    "        input_lang\n",
    "    except NameError : \n",
    "        input_lang, output_lang, pairs = readLangs('questions', 'answers', False)\n",
    "        pairs = TrimWords(pairs) \n",
    "        input_lang, output_lang, pairs = prepareData('questions', 'answers', False)\n",
    "        training_set, test_set = construct_train_test_set(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the parameters from check_point/encoder_120.ck and check_point/decoder_120.ck...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:179: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:190: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:302: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 12s (- 20m 5s) (1000 1%) 0.0438\n",
      "0m 21s (- 17m 50s) (2000 2%) 0.0474\n",
      "0m 31s (- 17m 1s) (3000 3%) 0.0379\n",
      "0m 41s (- 16m 33s) (4000 4%) 0.0420\n",
      "0m 53s (- 16m 48s) (5000 5%) 0.0346\n",
      "1m 6s (- 17m 16s) (6000 6%) 0.0378\n",
      "1m 16s (- 16m 51s) (7000 7%) 0.0405\n",
      "1m 25s (- 16m 28s) (8000 8%) 0.0362\n",
      "1m 35s (- 16m 6s) (9000 9%) 0.0300\n",
      "1m 45s (- 15m 50s) (10000 10%) 0.0323\n",
      "1m 55s (- 15m 33s) (11000 11%) 0.0348\n",
      "2m 5s (- 15m 19s) (12000 12%) 0.0332\n",
      "2m 15s (- 15m 4s) (13000 13%) 0.0339\n",
      "2m 25s (- 14m 52s) (14000 14%) 0.0234\n",
      "2m 35s (- 14m 40s) (15000 15%) 0.0428\n",
      "2m 45s (- 14m 28s) (16000 16%) 0.0303\n",
      "2m 55s (- 14m 15s) (17000 17%) 0.0354\n",
      "3m 6s (- 14m 8s) (18000 18%) 0.0321\n",
      "3m 16s (- 13m 57s) (19000 19%) 0.0345\n",
      "3m 25s (- 13m 43s) (20000 20%) 0.0412\n",
      "3m 36s (- 13m 33s) (21000 21%) 0.0388\n",
      "3m 45s (- 13m 21s) (22000 22%) 0.0410\n",
      "3m 56s (- 13m 10s) (23000 23%) 0.0291\n",
      "4m 5s (- 12m 58s) (24000 24%) 0.0284\n",
      "4m 15s (- 12m 47s) (25000 25%) 0.0353\n",
      "4m 25s (- 12m 35s) (26000 26%) 0.0354\n",
      "4m 35s (- 12m 24s) (27000 27%) 0.0396\n",
      "4m 48s (- 12m 22s) (28000 28%) 0.0276\n",
      "4m 58s (- 12m 11s) (29000 28%) 0.0378\n",
      "5m 8s (- 11m 59s) (30000 30%) 0.0302\n",
      "5m 18s (- 11m 48s) (31000 31%) 0.0274\n",
      "5m 28s (- 11m 37s) (32000 32%) 0.0388\n",
      "5m 38s (- 11m 26s) (33000 33%) 0.0315\n",
      "5m 47s (- 11m 15s) (34000 34%) 0.0290\n",
      "5m 57s (- 11m 4s) (35000 35%) 0.0393\n",
      "6m 11s (- 11m 0s) (36000 36%) 0.0398\n",
      "6m 21s (- 10m 50s) (37000 37%) 0.0352\n",
      "6m 31s (- 10m 39s) (38000 38%) 0.0349\n",
      "6m 41s (- 10m 28s) (39000 39%) 0.0359\n",
      "6m 51s (- 10m 17s) (40000 40%) 0.0278\n",
      "7m 1s (- 10m 6s) (41000 41%) 0.0404\n",
      "7m 11s (- 9m 55s) (42000 42%) 0.0294\n",
      "7m 21s (- 9m 44s) (43000 43%) 0.0363\n",
      "7m 31s (- 9m 34s) (44000 44%) 0.0271\n",
      "7m 41s (- 9m 23s) (45000 45%) 0.0290\n",
      "7m 51s (- 9m 13s) (46000 46%) 0.0288\n",
      "8m 1s (- 9m 2s) (47000 47%) 0.0322\n",
      "8m 11s (- 8m 52s) (48000 48%) 0.0319\n",
      "8m 21s (- 8m 41s) (49000 49%) 0.0298\n",
      "8m 31s (- 8m 31s) (50000 50%) 0.0221\n",
      "8m 41s (- 8m 20s) (51000 51%) 0.0309\n",
      "8m 51s (- 8m 10s) (52000 52%) 0.0359\n",
      "9m 1s (- 8m 0s) (53000 53%) 0.0296\n",
      "9m 12s (- 7m 50s) (54000 54%) 0.0304\n",
      "9m 22s (- 7m 40s) (55000 55%) 0.0307\n",
      "9m 32s (- 7m 29s) (56000 56%) 0.0318\n",
      "9m 42s (- 7m 19s) (57000 56%) 0.0342\n",
      "9m 52s (- 7m 8s) (58000 57%) 0.0286\n",
      "10m 1s (- 6m 58s) (59000 59%) 0.0219\n",
      "10m 11s (- 6m 47s) (60000 60%) 0.0297\n",
      "10m 21s (- 6m 37s) (61000 61%) 0.0377\n",
      "10m 31s (- 6m 27s) (62000 62%) 0.0299\n",
      "10m 41s (- 6m 16s) (63000 63%) 0.0275\n",
      "10m 51s (- 6m 6s) (64000 64%) 0.0350\n",
      "11m 0s (- 5m 55s) (65000 65%) 0.0252\n",
      "11m 10s (- 5m 45s) (66000 66%) 0.0344\n",
      "11m 20s (- 5m 35s) (67000 67%) 0.0209\n",
      "11m 30s (- 5m 24s) (68000 68%) 0.0304\n",
      "11m 40s (- 5m 14s) (69000 69%) 0.0351\n",
      "11m 49s (- 5m 4s) (70000 70%) 0.0387\n",
      "11m 59s (- 4m 53s) (71000 71%) 0.0387\n",
      "12m 10s (- 4m 43s) (72000 72%) 0.0340\n",
      "12m 22s (- 4m 34s) (73000 73%) 0.0316\n",
      "12m 33s (- 4m 24s) (74000 74%) 0.0295\n",
      "12m 43s (- 4m 14s) (75000 75%) 0.0263\n",
      "12m 53s (- 4m 4s) (76000 76%) 0.0317\n",
      "13m 3s (- 3m 53s) (77000 77%) 0.0306\n",
      "13m 13s (- 3m 43s) (78000 78%) 0.0252\n",
      "13m 23s (- 3m 33s) (79000 79%) 0.0292\n",
      "13m 33s (- 3m 23s) (80000 80%) 0.0356\n",
      "13m 43s (- 3m 13s) (81000 81%) 0.0279\n",
      "13m 52s (- 3m 2s) (82000 82%) 0.0268\n",
      "14m 2s (- 2m 52s) (83000 83%) 0.0339\n",
      "14m 12s (- 2m 42s) (84000 84%) 0.0336\n",
      "14m 22s (- 2m 32s) (85000 85%) 0.0362\n",
      "14m 32s (- 2m 21s) (86000 86%) 0.0316\n",
      "14m 42s (- 2m 11s) (87000 87%) 0.0265\n",
      "14m 51s (- 2m 1s) (88000 88%) 0.0354\n",
      "15m 1s (- 1m 51s) (89000 89%) 0.0276\n",
      "15m 12s (- 1m 41s) (90000 90%) 0.0407\n",
      "15m 21s (- 1m 31s) (91000 91%) 0.0313\n",
      "15m 31s (- 1m 21s) (92000 92%) 0.0328\n",
      "15m 41s (- 1m 10s) (93000 93%) 0.0299\n",
      "15m 51s (- 1m 0s) (94000 94%) 0.0321\n",
      "16m 3s (- 0m 50s) (95000 95%) 0.0345\n",
      "16m 16s (- 0m 40s) (96000 96%) 0.0352\n",
      "16m 26s (- 0m 30s) (97000 97%) 0.0389\n",
      "16m 36s (- 0m 20s) (98000 98%) 0.0418\n",
      "16m 46s (- 0m 10s) (99000 99%) 0.0353\n",
      "16m 56s (- 0m 0s) (100000 100%) 0.0290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type EncoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type AttnDecoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainIters(100000, learning_rate = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the parameters from check_point/encoder_120.ck and check_point/decoder_120.ck...\n",
      "Question:  des véhicules hors périmètre\n",
      "Réponse:  #oui/non#\n",
      "Bot: le véhicule ou période. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules hors périmètre\n",
      "Réponse:  il y a #nb_véhicules# en dehors de la zone définie\n",
      "Bot: le véhicule ou proche est ou mieux le. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  délai de livraison des boîtiers\n",
      "Réponse:  la livraison des boitiers est prévue le #date#\n",
      "Bot: la date de livraison approximative est #date#. ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  mode de paiement\n",
      "Réponse:  vous pouvez régler par virement ou carte bancaire\n",
      "Bot: vous pouvez régler par virement ou carte bancaire veuillez contacter. ACCURACY 0.8\n",
      "--------------------------------------------------\n",
      "Question:  où est la facture\n",
      "Réponse:  la facture est disponible dans votre espace client\n",
      "Bot: elle est disponible dans votre espace client. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  le boitier ne fonctionne plus que dois-je faire\n",
      "Réponse:  merci de nous avoir prévenu pouvez-vous nous indiquer son numéro de série\n",
      "Bot: oui. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  comment modifier les informations relatives à mon compte\n",
      "Réponse:  vous pouvez réaliser cette opération à partir de l'interface client\n",
      "Bot: vous pouvez modifier les informations de à partir de l'interface client. ACCURACY 0.2\n",
      "--------------------------------------------------\n",
      "Question:  quels sont les indicateurs de pollution\n",
      "Réponse:  la liste des indicateurs de conduite sont disponibles dans #kpi_pollution#\n",
      "Bot: la liste des indicateurs de conduite sont disponibles dans #kpi_finance#. ACCURACY 0.9\n",
      "--------------------------------------------------\n",
      "Question:  quels kpi\n",
      "Réponse:  quel est votre besoin\n",
      "Bot: en préalable est disponible votre besoin. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  les véhicules sont-ils en bonne santé\n",
      "Réponse:  #oui/non#\n",
      "Bot: il convient de faire un check visuel. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  quels sont les codes défauts\n",
      "Réponse:  la liste des codes défaut est disponible #code_dtc#\n",
      "Bot: la liste des indicateurs de conduite sont disponibles dans #kpi_finance#. ACCURACY 0.3\n",
      "--------------------------------------------------\n",
      "Question:  quel est le dernier trajet\n",
      "Réponse:  le dernier trajet connu est #trajet#\n",
      "Bot: quel est le point de départ. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  quel est l'état de la route\n",
      "Réponse:  le traffic est #état_traffic#\n",
      "Bot: il y #total_veh_movement# véhicules en circulation. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  y'a-t-il des bouchons\n",
      "Réponse:  le traffic est #état_traffic#\n",
      "Bot: le traffic est #état_traffic#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  est-ce que le niveau de consommation de carburant est normal\n",
      "Réponse:  la consommation est de #consumption#\n",
      "Bot: #oui/non#. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de kilomètres a fait ce véhicule ce mois\n",
      "Réponse:  la distance parcourue par ce véhicule est de #km#\n",
      "Bot: ce véhicule a effectué #km#. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  quel est le kilomètrage moyen de ce véhicule\n",
      "Réponse:  en moyenne ce véhicule a roulé #km#\n",
      "Bot: le tco de #base_marque#. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules ont roulés\n",
      "Réponse:  #total_veh_movement#\n",
      "Bot: #total_veh_movement#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  avons-nous le carnet d'entretien\n",
      "Réponse:  oui\n",
      "Bot: oui vous disposez d'une par de santé de chacun votre dashboard. ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  lequel choisir\n",
      "Réponse:  vous pouvez choisir plusieurs modules parmi #nb_module#\n",
      "Bot: il faut effectivement faire. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  je souhaite m'inscrire\n",
      "Réponse:  les inscriptions se font sur #lab_program#\n",
      "Bot: il faut nous contacter par mail ou mieux vous inscrire sur eventbrite. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  je souhaite postuler\n",
      "Réponse:  les inscriptions se font sur #lab_program#\n",
      "Bot: ton véhicule plus proche est à en cours merci. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  les atouts de ce workshop\n",
      "Réponse:  un temps d'échange pour les pros réalisé par des pros\n",
      "Bot: les inscriptions de se font sur de. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  quel coût\n",
      "Réponse:  cela dépend de vos besoin contactez-nous au #num_telephone#\n",
      "Bot: merci à. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  c'est quand la révision\n",
      "Réponse:  le #date#\n",
      "Bot: la révision aura lieu le #date_last_entretien#. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  je veux acheter ce module\n",
      "Réponse:  merci voici la procédure\n",
      "Bot: le module #list_module# à 92. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  votre module m'intéresse\n",
      "Réponse:  merci voici l'accès au store\n",
      "Bot: vous pouvez utiliser personnes un socle. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  bonjour monsieur\n",
      "Réponse:  bonjour madame #lastname#\n",
      "Bot: j'en #nb_véhicules# prends note plus voici pros procédure. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  quel est le taux de disponibilité\n",
      "Réponse:  #tx_dispo#\n",
      "Bot: #tx_dispo#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  j'ai des questions\n",
      "Réponse:  je suis là pour vous aider\n",
      "Bot: oui posez vos questions. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  je voudrais m'inscrire à un workshop\n",
      "Réponse:  il faut nous contacter par mail ou mieux vous inscrire sur eventbrite\n",
      "Bot: 12. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  y a t-il d'autres versions de ce module\n",
      "Réponse:  oui\n",
      "Bot: le module #list_module# à objectif de #detail_module#. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  avez-vous une description détaillée des modules\n",
      "Réponse:  le descriptif détaillé de tous modules est disponible sur le store\n",
      "Bot: quel est votre besoin. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  je viens de clermont-ferrand\n",
      "Réponse:  la durée de votre trajet sera de #calcul_roadtrip#\n",
      "Bot: la durée de votre trajet sera de #calcul_roadtrip#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules roulent\n",
      "Réponse:  #total_veh_movement# véhicules de la société roulent en ce moment\n",
      "Bot: #total_veh_movement# véhicules de la société roulent. ACCURACY 0.7\n",
      "--------------------------------------------------\n",
      "Question:  j'aime cette interface\n",
      "Réponse:  c'est un bon point merci pour votre feedback :)\n",
      "Bot: le livret retrace tous la sélection est de votre empreinte. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  je n'aime pas cette interface\n",
      "Réponse:  c'est noté pouvez-vous préciser pourquoi\n",
      "Bot: pourquoi pas si ce sujet vous intéresse venez en discuter avec nous lors. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  pardon\n",
      "Réponse:  pouvez-vous reformuler votre question\n",
      "Bot: oui. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  je souhaite visualiser un état de la flotte\n",
      "Réponse:  consultez votre dashboard pour une vision exhaustive du parc\n",
      "Bot: #tco_fleet#. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  je souhaite obtenir un état du parc\n",
      "Réponse:  consultez votre dashboard\n",
      "Bot: c'est une question intéressante qui mérite d'être partagée avec. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  quel véhicule est disponible dans 1h\n",
      "Réponse:  vous pouvez vous servir du #list_vin_immediat#\n",
      "Bot: désolé je ne sais pas. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  quel véhicule est disponible ce matin\n",
      "Réponse:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:179: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:190: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vous pouvez vous servir du #list_vin_morning#\n",
      "Bot: #list_vin_morning#. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  quel est le temps estimé d'arrivée\n",
      "Réponse:  la durée du trajet est approximativement de #calcul_roadtrip#\n",
      "Bot: #oui/non#. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  quels sont les instances non-traitées\n",
      "Réponse:  vous devez traiter les #list_instances#\n",
      "Bot: la liste des indicateurs de conduite sont disponibles dans #kpi_conduite#. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  quel est le taux d'indisponibilité\n",
      "Réponse:  il s'élève à #tx_veh_indisponible#\n",
      "Bot: #oui/non#. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de passagers pouvons-nous embarquer\n",
      "Réponse:  le nombre de passagers déclarés #nb_passagers#\n",
      "Bot: la date de faire un compte cet incident quel est votre besoin. ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  tco du véhicule\n",
      "Réponse:  #tco_vehicule#\n",
      "Bot: il s'agit de livraison véhicule est. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  etat de la batterie\n",
      "Réponse:  la tension est de #voltage#\n",
      "Bot: la tension est de #voltage#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  valeur de rachat du véhicule\n",
      "Réponse:  la valeur résiduelle de ce véhicule est spécifiée dans votre contrat de location\n",
      "Bot: il s'agit de livraison carnet_de_santé #date#. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  pouvons-nous partager les véhicules\n",
      "Réponse:  si vous disposez du nombre de véhicules nécessaires et adaptés pour cela c'est une très bonne idée\n",
      "Bot: c'est une façon intelligible de valoriser l'immobilisation que réprésente votre flotte. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  la tournée est-elle optimisée\n",
      "Réponse:  quel est le véhicule concerné\n",
      "Bot: la révision aura lieu le #date#. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  nombre de mois de location\n",
      "Réponse:  la durée du contrat de location est de #durée_contrat# mois\n",
      "Bot: le contrat de location de durée de location égale à mesurer les rejets nox de particules fines. ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  je veux voir le meilleur trajet\n",
      "Réponse:  pouvez-vous m'indiquer le point de départ et d'arrivée souhaité\n",
      "Bot: tu véhicule est de #vin_proxi#. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  je veux traiter les amendes\n",
      "Réponse:  la gestion des contraventions est un module en cours développement en lien avec les services de l'antai\n",
      "Bot: consultez votre dashboard. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  je veux rédiger un plan de mobilité\n",
      "Réponse:  nous pouvons vous accompagner\n",
      "Bot: forte synergie entre acteurs. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  je veux le détail de nos contrats fournisseurs\n",
      "Réponse:  voici #contract#\n",
      "Bot: a bien merci. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  je veux restituer un véhicule\n",
      "Réponse:  pas de souci quel est le véhicule concerné\n",
      "Bot: ton véhicule plus proche est #position#. ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  où est ma voiture\n",
      "Réponse:  elle est à #position#\n",
      "Bot: elle est à #position#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  je cherche ma voiture\n",
      "Réponse:  elle est à #position#\n",
      "Bot: elle est à #position#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  pourquoi tu est là\n",
      "Réponse:  je suis là pour tes questions concernants tes voitures\n",
      "Bot: je vais en compte cet incident. ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  quelle est la couleur du ciel\n",
      "Réponse:  désolé je ne sais pas\n",
      "Bot: le la est de #consumptionr#. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  merci beaucoup\n",
      "Réponse:  de rien\n",
      "Bot: le #date#. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  au revoir\n",
      "Réponse:  au revoir\n",
      "Bot: au revoir. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  à bientôt\n",
      "Réponse:  à bientôt\n",
      "Bot: désolé. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  quel est l’état d’usure des plaquettes de frein\n",
      "Réponse:  #usure_plaquette_frein#\n",
      "Bot: #usure_plaquette_frein#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  mes freinages sont ils trop brusques\n",
      "Réponse:  #oui/non#\n",
      "Bot: voici les #list_events_driving# que la monte #vin#. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  quelle est la consommation moyenne de mon véhicule hebdomadaire\n",
      "Réponse:  #consommation#\n",
      "Bot: #consommation#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  bonjour mademoiselle\n",
      "Réponse:  bonjour\n",
      "Bot: le #date#. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  comment tu t’appelles\n",
      "Réponse:  je suis un chatbot d’avicen comment je peux t’aider\n",
      "Bot: oui posez je suis un bot de avicen tu peux m'appeler charlie. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  t’es un con bot\n",
      "Réponse:  pourquoi des mots méchants\n",
      "Bot: pourquoi t'es méchant avec un bot. ACCURACY 0.2\n",
      "--------------------------------------------------\n",
      "Question:  quel véhicule dois-je restituer prochainement\n",
      "Réponse:  #oui/non#\n",
      "Bot: ce véhicule. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  au revoir\n",
      "Réponse:  au revoir\n",
      "Bot: au revoir. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  bonjour\n",
      "Réponse:  bonjour\n",
      "Bot: bonjour. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules sont immobilisés\n",
      "Réponse:  ce véhicule #vin# semble immobilisé\n",
      "Bot: la liste des véhicules est rude. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  tout va bien\n",
      "Réponse:  ça va et toi\n",
      "Bot: ça va. ACCURACY 0.5\n",
      "--------------------------------------------------\n",
      "Question:  je veux une aide\n",
      "Réponse:  je suis là pour t'aider\n",
      "Bot: je suis là pour t'aider. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  bonjour\n",
      "Réponse:  social :) approximative descriptif par détaillé\n",
      "Bot: bonjour. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:  tu vas bien\n",
      "Réponse:  ça va merci\n",
      "Bot: ça va merci. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  y a t-il des problèmes\n",
      "Réponse:  #oui/non#\n",
      "Bot: #oui/non#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  tout va bien\n",
      "Réponse:  ça va et toi\n",
      "Bot: ça va. ACCURACY 0.5\n",
      "--------------------------------------------------\n",
      "Question:  comment trouver un véhicule\n",
      "Réponse:  il faut mettre à jour la base de données véhicules\n",
      "Bot: il faut mettre à jour la base de données véhicules. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  est ce que j'ai des problèmes de frein\n",
      "Réponse:  #oui/non#\n",
      "Bot: #oui/non#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Test on 82\n",
      "Accuracy by percent of true words 0.2635283973160588\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
