{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cet technique marche beaucoup mieux que dans tensorflow, avec en très peu de temps.\n",
    "Ce modèle fonctionne mieux que l'autre dans tensorflow parce qu'une raison évidente: il utilise méthode teacher forcing\n",
    "Un autre problème avec ce méthode, c'est dropout qui donne une technique plus ou moins bon. Il donne la réponse plus tôt aléatoire pour une question. En cas général, ce la peut être intéressant, mais dans notre cas, il est très important qu'il capture le mot clés (donc, surtout on risque de  supprimer le mot clés, qui rendra une mauvais réponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Reading lines...\n",
      "Read 555 sentence pairs\n",
      "Trimmed to 548 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "questions 594\n",
      "answers 772\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cet technique marche beaucoup mieux que dans tensorflow, avec en très peu de temps. \n",
    "Ce modèle fonctionne mieux que l'autre dans tensorflow parce qu'une raison évidente: \n",
    "il utilise méthode teacher forcing Un autre problème avec ce méthode, \n",
    "c'est dropout qui donne une technique plus ou moins bon. Il donne la \n",
    "réponse plus tôt aléatoire pour une question. En cas général, \n",
    "ce la peut être intéressant, mais dans notre cas, il est très important \n",
    "qu'il capture le mot clés \n",
    "(donc, surtout on risque de supprimer le mot clés, qui rendra une mauvais réponse)\n",
    "modèle est bien entrainé, donc, il ne sert à rien d'entrainer encore.\n",
    "\"\"\"\n",
    "#from IPython.display import display, Markdown\n",
    "#display(Markdown(\"### Pour lancer un chat, il suffit de taper en même temps CTRL et ENTER\"))\n",
    "#display(Markdown(\"### Pour arrêter le mode chat, il suffit de taper ENTER dans votre conversation\"))\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import data\n",
    "import config\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "SOS_token  = config.SOS_token\n",
    "EOS_token  = config.EOS_token\n",
    "MAX_LENGTH = config.MAX_LENGTH\n",
    "stopwords  = config.STOPWORDS\n",
    "learning_rate = config.LEARNING_RATE\n",
    "teacher_forcing_ratio = config.TEACHER_FORCING\n",
    "dropout = config.DROPOUT\n",
    "hidden_size = 70\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  \n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "def normalizeString(s):\n",
    "    \"\"\"\n",
    "    Whith a tring s, we make it in lower case, delete \\n if exists at \n",
    "    the end of string, and delete specical case ? . and !\n",
    "    \"\"\"\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([,.!?\\n])\", r\"\", s)# sumprimer tous les caractères .! et ?\n",
    "    #s = re.sub(r\"[^a-zA-Z0-9.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(questions, answers, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    pairs = []   \n",
    "    encode_file = open(os.path.join(config.PROCESSED_PATH, \"question.txt\"), 'r')\n",
    "    decode_file = open(os.path.join(config.PROCESSED_PATH, \"answer.txt\"), 'r')\n",
    "    encode, decode = encode_file.readline(), decode_file.readline()\n",
    "    while encode and decode:\n",
    "        encode, decode = normalizeString(encode), normalizeString(decode)\n",
    "        pairs.append([encode, decode])\n",
    "        encode, decode = encode_file.readline(), decode_file.readline()\n",
    "\n",
    "    \n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(answers)\n",
    "        output_lang = Lang(questions)\n",
    "    else:\n",
    "        input_lang = Lang(questions)\n",
    "        output_lang = Lang(answers)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def TrimWords(pairs):\n",
    "    for pair in pairs: #[pair for pair in pairs]:\n",
    "        resultwords  = [word for word in pair[0].split() if word.lower() not in stopwords]\n",
    "        pair[0] = ' '.join(resultwords)\n",
    "    return pairs\n",
    "\n",
    " \n",
    "def TrimWordsTest(question):\n",
    "    resultwords  = [word for word in question.split() if word.lower() not in stopwords]\n",
    "    question = ' '.join(resultwords)\n",
    "    return question\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH \n",
    "\n",
    "    \n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = TrimWords(pairs)\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=dropout, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        #embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)))#, dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]))#, dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "def closetWord(word, lang):\n",
    "    \"\"\"\n",
    "    find and return the closest word in lang\n",
    "    \"\"\"\n",
    "    Dict = lang.word2index\n",
    "    corpus = lang.index2word\n",
    "    if word in Dict:\n",
    "        return word\n",
    "    else:\n",
    "        distance = levenshtein(word, corpus[0])\n",
    "        close_word = corpus[0]\n",
    "        for ix in corpus:\n",
    "            if levenshtein(word, corpus[ix]) <distance:\n",
    "                close_word = corpus[ix]\n",
    "                distance = levenshtein(word, corpus[ix])\n",
    "        if distance <=2:\n",
    "            return close_word\n",
    "        else:\n",
    "            return ''\n",
    "def normalizeSentenceInChat(sentence):\n",
    "    sentence = sentence.strip().lower().split()\n",
    "    s = [closetWord(word, input_lang) for word in sentence]\n",
    "    return ' '.join(s)\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    #sentence = normalizeSentence\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index ]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(n_iters, print_every=1000, plot_every=100, learning_rate=learning_rate):\n",
    "    encoder, decoder = restore_model()\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    save_model(encoder, decoder)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    sentence = normalizeSentenceInChat(sentence)\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  \n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        ni = int(ni)\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "def evaluateRandomly(n):\n",
    "    encoder, decoder = restore_model()\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('Question: ', pair[0])\n",
    "        print('Réponse: ', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words[:-1])\n",
    "        print('Bot: ', output_sentence)\n",
    "        print('-'*50)\n",
    "        \n",
    "def make_dir(path):\n",
    "    \"\"\" Create a directory if there isn't one already. \"\"\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "def save_model(encoder, decoder):        \n",
    "    make_dir(config.CHECK_POINT_PATH)\n",
    "    path1= os.path.join(config.CHECK_POINT_PATH, 'encoder_70.ck')\n",
    "    path2 = os.path.join(config.CHECK_POINT_PATH, 'decoder_70.ck')\n",
    "    try: \n",
    "        os.remove(path1)  \n",
    "        os.remove(path2)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    torch.save(encoder,path1)\n",
    "    torch.save(decoder, path2)\n",
    "    \n",
    "memo = {}\n",
    "def levenshtein(s, t):\n",
    "    \"\"\"\n",
    "    Pour calculer la distance  Levenshtein entre 2 string s et t\n",
    "    \"\"\"\n",
    "    if s == \"\":\n",
    "        return len(t)\n",
    "    if t == \"\":\n",
    "        return len(s)\n",
    "    cost = 0 if s[-1] == t[-1] else 1\n",
    "       \n",
    "    i1 = (s[:-1], t)\n",
    "    if not i1 in memo:\n",
    "        memo[i1] = levenshtein(*i1)\n",
    "    i2 = (s, t[:-1])\n",
    "    if not i2 in memo:\n",
    "        memo[i2] = levenshtein(*i2)\n",
    "    i3 = (s[:-1], t[:-1])\n",
    "    if not i3 in memo:\n",
    "        memo[i3] = levenshtein(*i3)\n",
    "    res = min([memo[i1]+1, memo[i2]+1, memo[i3]+cost])\n",
    "    \n",
    "    return res\n",
    "    \n",
    "def restore_model():\n",
    "    hidden_size = config.HIDDEN_SIZE\n",
    "    path1 = os.path.join(config.CHECK_POINT_PATH, 'encoder_70.ck')\n",
    "    path2 = os.path.join(config.CHECK_POINT_PATH, 'decoder_70.ck')\n",
    "    if os.path.exists(path1)and os.path.exists(path2):\n",
    "        print('Reading the parameters from {}...'.format(config.CHECK_POINT_PATH))\n",
    "        encoder = torch.load(path1)\n",
    "        decoder = torch.load(path2)\n",
    "    else:\n",
    "        print('Initializing fresh parameters...')\n",
    "        encoder = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "        decoder = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                               1, dropout_p=0.1)\n",
    "\n",
    "    if use_cuda:\n",
    "        encoder = encoder.cuda()\n",
    "        decoder = decoder.cuda()\n",
    "    return encoder, decoder  \n",
    "def chat():\n",
    "    encoder, decoder = restore_model()\n",
    "    make_dir(config.CHECK_POINT_PATH)\n",
    "    output_file = open(os.path.join(config.CHECK_POINT_PATH, config.OUTPUT_FILE), 'a+')\n",
    "    print('Bonjour, c\\'est le Bot d\\'AVICEN, Je peux vous aider? \\n')\n",
    "    while True:\n",
    "            line = str(input('Vous: '))\n",
    "            if len(line) > 0 and line[-1] == '\\n':\n",
    "                line = line[:-1]\n",
    "            if line == '':\n",
    "                break\n",
    "            line = normalizeString(line)\n",
    "            output_file.write('VOUS ++++ ' + line + '\\n')\n",
    "            reponse, _ = evaluate(encoder, decoder, line)\n",
    "            reponse = \" \".join(reponse[:-1])\n",
    "            output_file.write('BOT ++++ ' + reponse + '\\n')\n",
    "            print('Bot AVICEN: ', reponse)\n",
    "            print('-'*50)\n",
    "    output_file.close()\n",
    "try:\n",
    "    input_lang\n",
    "except NameError : \n",
    "    input_lang, output_lang, pairs = readLangs('questions', 'answers', False)\n",
    "    pairs = TrimWords(pairs) \n",
    "    input_lang, output_lang, pairs = prepareData('questions', 'answers', False)\n",
    "\n",
    "def langTest():\n",
    "    pairs_test = []   \n",
    "    test_file = open(os.path.join(config.PROCESSED_PATH, \"test.txt\"), 'r')\n",
    "    i=0\n",
    "    for line in test_file:\n",
    "        line = normalizeString(line)\n",
    "        if i%2 ==0:\n",
    "            question = line\n",
    "        else:\n",
    "            answer = line\n",
    "            pairs_test.append([question, answer])\n",
    "        i +=1\n",
    "    return pairs_test  \n",
    "\n",
    "def test(pairs_test):\n",
    "    \"\"\"\n",
    "    Use test for know how our model is good\n",
    "    \"\"\"\n",
    "    encoder, decoder = restore_model()\n",
    "    total_loss = 0\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "    for pair in pairs_test:\n",
    "        variable = variablesFromPair(pair)\n",
    "        loss = train( variable[0], variable[1], encoder, decoder, encoder_optimizer, decoder_optimizer,\\\n",
    "                     criterion= criterion)\n",
    "        total_loss +=loss\n",
    "    Length_inputs = len(pairs_test) if len(pairs_test) !=0 else 1\n",
    "    return total_loss/Length_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the parameters from check_point...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:202: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:213: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:325: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 5s (- 0m 51s) (1000 10%) 0.0638\n",
      "0m 11s (- 0m 45s) (2000 20%) 0.0562\n",
      "0m 16s (- 0m 39s) (3000 30%) 0.0573\n",
      "0m 22s (- 0m 33s) (4000 40%) 0.0541\n",
      "0m 27s (- 0m 27s) (5000 50%) 0.0647\n",
      "0m 33s (- 0m 22s) (6000 60%) 0.0598\n",
      "0m 39s (- 0m 16s) (7000 70%) 0.0414\n",
      "0m 44s (- 0m 11s) (8000 80%) 0.0534\n",
      "0m 50s (- 0m 5s) (9000 90%) 0.0555\n",
      "0m 56s (- 0m 0s) (10000 100%) 0.0613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type EncoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type AttnDecoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainIters(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the parameters from check_point...\n",
      "Bonjour, c'est le Bot d'AVICEN, Je peux vous aider? \n",
      "\n",
      "Vous: combien de véhicules  sont utilisés aujourd'hui\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:201: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:212: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot AVICEN:  la\n",
      "--------------------------------------------------\n",
      "Vous: combien de véhicules sont roulés\n",
      "Bot AVICEN:  #total_veh_movement#\n",
      "--------------------------------------------------\n",
      "Vous: combien de véhicules sont utilisés\n",
      "Bot AVICEN:  #oui/non#\n",
      "--------------------------------------------------\n",
      "Vous: combien de voitures sont roulées\n",
      "Bot AVICEN:  #total_veh_movement#\n",
      "--------------------------------------------------\n",
      "Vous: combien de voitures sont à l'arrêt\n",
      "Bot AVICEN:  ce véhicule #vin# semble immobilisé\n",
      "--------------------------------------------------\n",
      "Vous: combien de voitures sont immobilisées?\n",
      "Bot AVICEN:  #list_vin_free# véhicules de ce véhicule\n",
      "--------------------------------------------------\n",
      "Vous: combien de véhicules sont immobilisés\n",
      "Bot AVICEN:  #list_vin_free# véhicules du parc sont\n",
      "--------------------------------------------------\n",
      "Vous: est-ce-que tout va bien\n",
      "Bot AVICEN:  ça va et toi\n",
      "--------------------------------------------------\n",
      "Vous: est ce que tout va bien\n",
      "Bot AVICEN:  ça\n",
      "--------------------------------------------------\n",
      "Vous: tout va bien\n",
      "Bot AVICEN:  ça va et toi\n",
      "--------------------------------------------------\n",
      "Vous: il y a des problèmes\n",
      "Bot AVICEN:  le #date#\n",
      "--------------------------------------------------\n",
      "Vous: y a t-il des problèmes\n",
      "Bot AVICEN:  oui le numéro\n",
      "--------------------------------------------------\n",
      "Vous: y a t-il des problèmes\n",
      "Bot AVICEN:  oui le numéro\n",
      "--------------------------------------------------\n",
      "Vous: \n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the parameters from check_point...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:202: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:213: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:325: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/THNN/generic/ClassNLLCriterion.c:97",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-70b29a170307>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-df3993c20f30>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         loss = train(input_variable, target_variable, encoder,\n\u001b[0;32m--> 363\u001b[0;31m                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-df3993c20f30>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mni\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEOS_token\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         return F.nll_loss(input, target, self.weight, self.size_average,\n\u001b[0;32m--> 193\u001b[0;31m                           self.ignore_index, self.reduce)\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1330\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/THNN/generic/ClassNLLCriterion.c:97"
     ]
    }
   ],
   "source": [
    "trainIters(3000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
