{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 2301 couples and test on 597 couple\n",
      "ON TEST, WE HAVE: PRECISION = 0.55640,  RECALL = 0.54830, F_MESURE = 0.552 \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ON TRAINS, WE HAVE PRECISION = 0.99885,  RECALL = 0.99907, F_MESURE = 0.999 \n",
      "ON TEST, WE HAVE: PRECISION = 0.55685,  RECALL = 0.55092, F_MESURE = 0.554 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "les symboles particulières comme ? ! et . sont supprimé dans la question.\n",
    "Il faut peut être returner une réponse spécifique si il rencontre plus 1 mot qu'il existe pas dans le corpus\n",
    "Nous suprimmons également:\n",
    "  1. Mot qui contient une seule lettre(qui sont suivante des erreurs)\n",
    "  2. Une fonction unique pour nettoyage tous les données dans train-test et chat\n",
    "Nous allons traiter tous les mots clés suivant :\n",
    "km, vitesse, carburant, huile, position, batterie, pression_pneu. Il reste trajet et vin\n",
    "  \n",
    "\"\"\"\n",
    "#import sys\n",
    "#!{sys.executable} -m pip uninstall gtts\n",
    "\n",
    "#from gtts import gTTS\n",
    "#from playsound import playsound\n",
    "#import speech_recognition\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = stopwords.words('french')\n",
    "from nltk.stem import *\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"french\", ignore_stopwords = False)\n",
    "import csv\n",
    "import re\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from dateparser.search import search_dates\n",
    "import pandas as pd\n",
    "\n",
    "def date_time_():\n",
    "    \n",
    "    DICT_NUMERO = {'ce':1, 'cette':1, 'un':1, 'une':1, 'deux':2, 'trois':3,\\\n",
    "                   'quatre':4, 'cinq':5, 'six':6, 'sept':7,\\\n",
    "              'huit':8, 'neuf':9, 'dix':10, 'onze':11, 'douze':12, 'treize':13,'quartoze':14,\\\n",
    "               'quinze':15, 'seize':16, 'dix-sept':17,'dix sept':17, 'dix huit':18, \\\n",
    "               'dix-huit':18, 'dix-neuf':19, 'vingt':20, 'ving et un':21, 'trente':30, 'quarante':40,\\\n",
    "                  'quarante cinq':45, 'soixante':60}\n",
    "    DICT_TEMPS = {'heure':1, 'matin':4, 'après-midi':2,  'journée':24,  'jour':24, \\\n",
    "              'mois':30*24, 'semaine':7*24, \\\n",
    "              'an':24*365, 'année':24*365, 'minute': 1/60}\n",
    "    DICT_COMPLET_TEMPS = {}\n",
    "    for temps in DICT_TEMPS:\n",
    "        for numéro in DICT_NUMERO:\n",
    "            key1 = numéro + ' '+temps\n",
    "            key2 = str(DICT_NUMERO[numéro]) + ' ' +temps\n",
    "            value = DICT_NUMERO[numéro]*DICT_TEMPS[temps]\n",
    "            DICT_COMPLET_TEMPS[key1] = value\n",
    "            DICT_COMPLET_TEMPS[key2] = value\n",
    "    DICT_FOR_SPECIAL_CASE = {'aujourd\\'hui':8, 'hébdomadaire':7*24, 'annuel': 365*24, \\\n",
    "                           'hier': 24, 'avant-hier': 48, 'annuelle': 365*24 , 'actuellement':1/2,\\\n",
    "                            'maintenant':1/2}\n",
    "    DICT_COMPLET_TEMPS['#cas_particulier#'] = DICT_FOR_SPECIAL_CASE\n",
    "    DICT_COMPLET_TEMPS['avant hier'] = 72\n",
    "    DICT_COMPLET_TEMPS['semaine dernière'] = 24*7\n",
    "    return DICT_COMPLET_TEMPS\n",
    "\n",
    "def construct_list_city():\n",
    "    #import csv\n",
    "    liste_ville =[]\n",
    "    with open('data/villes_france.csv') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            liste_ville.append(row[2])\n",
    "        for ville in liste_ville:\n",
    "            if len(ville) <4:\n",
    "                liste_ville.remove(ville)\n",
    "    return liste_ville\n",
    "\n",
    "def _find_right_time(question, Dict):\n",
    "    \n",
    "    list_ = ['?', '.', ' ', '\\n', '!']\n",
    "    for symbol in list_:\n",
    "        question = question.lower().strip(symbol)\n",
    "    list_word = question.split()\n",
    "    word_ = None\n",
    "    list_ = []\n",
    "    if len(list_word) < 2:\n",
    "        return None, None \n",
    "    for word in list_word:\n",
    "        if word_ is not None:\n",
    "            list_.append(str(word_)+' '+str(word))  \n",
    "        word_ = word\n",
    "    for key in Dict:\n",
    "        for word in  list_:\n",
    "            if key == word:\n",
    "                return Dict[key], key\n",
    "    for word in Dict['#cas_particulier#']:\n",
    "        for word2 in question.split():\n",
    "            if word2 == word:\n",
    "                return Dict['#cas_particulier#'][word], word       \n",
    "    return None, None\n",
    "\n",
    "\n",
    "def _find_right_geography(question, Dict):\n",
    "    \"\"\"\n",
    "    Nous cherchons une ville, un département dans le dictionnaire pour retourner soit\n",
    "    ce nom de ce lieu, soit ses coordonnées correspondance. Le retour de ce donnée dépend \n",
    "    de quel façon nous allons traiter avec cette information.\n",
    "    \n",
    "    \"\"\"\n",
    "    list_ = ['?', '.', '\\n', '!', ',']\n",
    "    for symbol in list_:\n",
    "        question = question.replace(symbol, '') \n",
    "    list_geography = []\n",
    "    for word in question.split():\n",
    "        if word.lower() !=word:\n",
    "            word1 = word.lower()\n",
    "            if word1 in Dict:\n",
    "                list_geography.append(word)\n",
    "    if len(list_geography) >0:\n",
    "        return list_geography\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def list_variable():\n",
    "    \"\"\"\n",
    "    list_var is to manually complete \"\"\"\n",
    "    list_var = []\n",
    "    if len(list_var) >0:\n",
    "        return list_var\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def _normalized_table():\n",
    "    \"\"\"\n",
    "    return a data frame with new name\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('fleet_donnees.csv', sep = ';')\n",
    "    variable_names = list_variable()\n",
    "    if variable_names ==None:\n",
    "        return df\n",
    "    else:\n",
    "        name = list(df)\n",
    "        dict_name = {name[i]: variable_names[i] for i in range(len(name))}\n",
    "        df = df.rename(index= str, columns = dict_name)\n",
    "        return df\n",
    "\n",
    "def find_right_time_from_table(time, df):\n",
    "    \"\"\"\n",
    "    given time found from a question, match it with the time given in table\n",
    "    This depend on format of time in table.\n",
    "    \n",
    "    \"\"\"\n",
    "    return None\n",
    "    \n",
    "    \n",
    "def clearing_word(word):\n",
    "    word = re.sub('\\x8e', 'é', word)\n",
    "    word = re.sub('\\x88', 'à', word)\n",
    "    word = re.sub('\\x9d', 'ù', word)\n",
    "    word = re.sub('\\x8f', 'è', word)\n",
    "    word = re.sub('\\x9e', 'û', word)\n",
    "    word = re.sub('\\x90', 'ê', word)\n",
    "    word = re.sub('\\x99', 'ô', word)\n",
    "    word = re.sub('\\x94', 'î', word)\n",
    "   # word = re.sub('\\x8f', 'è', word)\n",
    "    word = re.sub('\\x8d', 'ç', word)\n",
    "    word = re.sub('õ', '', word)\n",
    "    word = re.sub('Ê', '', word)\n",
    "    word = re.sub('[?,.,!, \\,,  %]', '', word)\n",
    "    if word == 'û' or word == 'v' or word == 'é':\n",
    "        word = ''\n",
    "    if word ==\"2017êles\":\n",
    "        word = \"2017\"\n",
    "    if \"ênox\" in word:\n",
    "        word =\"nox\"\n",
    "    return word\n",
    "\n",
    "\n",
    "def clear_line(pharse):\n",
    "    \"\"\"\n",
    "    Arg: string\n",
    "    Return: string\n",
    "    \"\"\"\n",
    "    dict_manuel = dict_manuelle()\n",
    "    pharse_ =[]\n",
    "    for words in pharse.strip().strip('?').strip('.').strip('!').lower().split(' '):\n",
    "        for word in words.split('-'):\n",
    "            for word_ in word.split('\\''):\n",
    "                word_ = clearing_word(word_)\n",
    "                word_ = stemmer.stem(word_)\n",
    "        #if word_ not in stop_word and len(word_) >1:       \n",
    "        pharse_.append(word_)  \n",
    "        for i in range(len(pharse_)):\n",
    "            for line in dict_manuel:\n",
    "                if pharse_[i] in line:\n",
    "                    pharse_[i] = line[0]\n",
    "    return ' '.join(pharse_)\n",
    "\n",
    "def stemmer_line(line):\n",
    "    return ' '.join([stemmer.stem(word) for word in line.split()])\n",
    "\n",
    "def prepareData(PAIRS):\n",
    "    pairs_trains, pairs_tests = [], []\n",
    "   # PAIRS.extend(pairs1)\n",
    "    index_train = random.sample(range(len(PAIRS)), int(len(PAIRS)*0.80))\n",
    "    for i in range(len(PAIRS)):\n",
    "        if i in index_train:\n",
    "            pairs_trains.append(PAIRS[i])\n",
    "        else:\n",
    "            pairs_tests.append(PAIRS[i])\n",
    "    print(\"Read %s sentence pairs of training set\" % len(pairs_trains))\n",
    "    print(\"Read %s sentence pairs of test set\" % len(pairs_tests))\n",
    "    return pairs_trains, pairs_tests\n",
    "\n",
    "def get_all_convos(stopwords, file):\n",
    "    \n",
    "    convos = []\n",
    "    questions_to_print = []\n",
    "    liste_file = [file]\n",
    "    list_of_word = []\n",
    "    for file in liste_file:\n",
    "        with open(file) as f:\n",
    "            i=0\n",
    "            for line in f:\n",
    "                if i%2==0:\n",
    "                    question = str(line)\n",
    "                    if '++++' in question:\n",
    "                         question = question[8:]\n",
    "                    question_ = question.strip().strip('!').strip('?').strip('.')\n",
    "                    questions_to_print.append(question_)\n",
    "                    question = clear_line(question)\n",
    "                else:\n",
    "                    answer = str(line)\n",
    "                    if '++++' in answer:\n",
    "                        answer = answer[8:].strip()\n",
    "                    convos.append([question, answer])\n",
    "                i+=1\n",
    "        f.close()\n",
    "        good_index = []\n",
    "        convos_ = []\n",
    "        for i in range(len(convos)):\n",
    "            if convos[i][0] not in convos_:\n",
    "                convos_.append(convos[i][0])\n",
    "                good_index.append(i)\n",
    "            \n",
    "    \n",
    "    return [convos[i] for i in good_index], [questions_to_print[i] for i in good_index]\n",
    "\n",
    "\n",
    "def get_questions_for_classification():\n",
    "    \n",
    "    file1 = 'data/trains_sujet.txt'\n",
    "    file2 = 'data/trains_hors_sujet.txt'\n",
    "    liste_file = [file1, file2]\n",
    "    index = 0\n",
    "    for file in liste_file:\n",
    "        questions = []\n",
    "        with open(file) as f:\n",
    "            i = 0 \n",
    "            for line in f:\n",
    "                if i%2 == 0:\n",
    "                    question = str(line).strip().strip('?').strip('.').strip('!')\n",
    "                    if '++++' in question:\n",
    "                         question = question[8:]\n",
    "                    questions.append(question)\n",
    "                i += 1\n",
    "        if index == 0:\n",
    "            questions_sujet = questions\n",
    "            index += 1\n",
    "        else:\n",
    "            questions_hors = questions\n",
    "        f.close()\n",
    "    return questions_sujet, questions_hors\n",
    "\n",
    "\n",
    "def get_all_questions_to_print(file):\n",
    "    \n",
    "    convos = []\n",
    "    liste_file = [file]\n",
    "    list_of_word = []\n",
    "    for file in liste_file:\n",
    "        with open(file) as f:\n",
    "            i=0\n",
    "            for line in f:\n",
    "                if i%2==0:\n",
    "                    question = str(line)\n",
    "                    if '++++' in question:\n",
    "                         question = question[8:]\n",
    "                    question = question.strip()\n",
    "                    convos.append(question)\n",
    "                i+=1\n",
    "        f.close()\n",
    "        indexes = []\n",
    "        index = 0\n",
    "    for question in convos:\n",
    "        question = clear_line(question)\n",
    "        if len(question) !=0:\n",
    "                indexes.append(index)\n",
    "        index +=1\n",
    "    return [convos[i] for i in indexes]\n",
    "\n",
    "def get_list_words(convos):\n",
    "    list_words =[]\n",
    "    for pair in convos:\n",
    "        for word in pair[0].split():\n",
    "            if word not in list_words:\n",
    "                list_words.append(word)\n",
    "    print('There are {} words in corpus:'.format(len(list_words)))\n",
    "    return list_words\n",
    "                \n",
    "\n",
    "def simulation_pairs():\n",
    "    \n",
    "    DIRECT_VARIABLE = ['vitesse', 'batterie', 'position', 'km']\n",
    "    BORDE = {'MAX': ['plus grand', 'plus grande', 'plus grands', \n",
    "         'plus grandes',\n",
    "         'plus vite', 'max', 'maximum', 'maximal', 'maximaux', 'maximale',\n",
    "        'plus haut', 'plus haute', 'plus hautes', 'plus hauts',  \n",
    "        'plus élevé', 'plus élevée', 'plus élevés', 'plus élevées'], \n",
    "         'MIN':['moins grand', 'moins grande', 'moins grands','moins grandes',\n",
    "        'plus petit', 'plus petite', 'plus petits', 'plus petites','plus faible', 'plus faibles', \n",
    "         'min', 'minimal', 'minimale', 'minimales', 'minimaux','moins vite', \n",
    "         'moins élevé', 'moins élevée', 'moins élevés', 'moins élevées'],\n",
    "        'MOYENNE': ['moyenne', 'moyen', 'moyennement']\n",
    "        }\n",
    "    COMPLEX_ANALYSIS = ['problème', 'problèmes', 'erreurs', 'erreur', 'danger']\n",
    "    PAIRS = []\n",
    "    question_for_simulation = ['quels véhicules ont', 'quel véhicule', 'quelle voiture', 'quelles voitures']\n",
    "    reponse_for_simulation = 'véhicule'\n",
    "    for borde in BORDE:\n",
    "        for word in BORDE[borde]:\n",
    "            for direct_variable in DIRECT_VARIABLE:\n",
    "                for question_f_s in question_for_simulation:\n",
    "                    if direct_variable !='position':\n",
    "                        question= question_f_s+' '+direct_variable + ' '+ word\n",
    "                        key0 = '#id#'\n",
    "                        key1 = '#'+direct_variable+'#'\n",
    "                        key2 = '#'+borde +'#'\n",
    "                        reponse = reponse_for_simulation +' '+key0+ ' '+ key1+ ' '+ key2\n",
    "                        PAIRS.append([question,reponse])\n",
    "\n",
    "    question_for_simulation = ['', 'quel véhicule a', 'quelle voiture a', 'quelles voitures ont', 'il y a']\n",
    "    reponse_for_simulation = 'véhicule' \n",
    "    for direct_variable in DIRECT_VARIABLE:\n",
    "        for complex_analysis in COMPLEX_ANALYSIS:\n",
    "            for question_f_s in question_for_simulation:\n",
    "                #if direct_variable !='position':\n",
    "                      question= question_f_s+' '+complex_analysis + ' '+ direct_variable\n",
    "                      key0 = '#id#'\n",
    "                      key1 = '#'+direct_variable+'#'\n",
    "                      key2 = '#'+ complex_analysis +'#'\n",
    "                      reponse = reponse_for_simulation +' '+key0+ ' '+ key2 +' '+ key1\n",
    "                      PAIRS.append([question,reponse])\n",
    "    return PAIRS\n",
    "\n",
    "def clear_pairs_trains(pairs_trains):\n",
    "    questions = []\n",
    "    index = []\n",
    "    for i in range(len(pairs_trains)):\n",
    "        if  pairs_trains[i][0] not in questions:\n",
    "            index.append(i)\n",
    "            questions.append(pairs_trains[i][0])\n",
    "    return [pairs_trains[i] for i in index]\n",
    "\n",
    "def tf_idf(word, doc):\n",
    "    \"\"\"\n",
    "    Nous avons utilisé une normalisation pour TF-IDF\"\"\"\n",
    "    tf, df = 0, 0\n",
    "    len_doc = len(split_words(doc))\n",
    "    value_word = 1/math.sqrt(len_doc)\n",
    "    value_word = math.sqrt(value_word)\n",
    "    if word in str(doc):\n",
    "        tf = value_word\n",
    "    for doc_ in DATA:\n",
    "        if word in str(doc_):\n",
    "            df+=1\n",
    "    if df>0:\n",
    "        return tf*math.log(len(DATA)/(df), 10)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def tf_idf_modified(word, doc, k):\n",
    "    \"\"\"\n",
    "    Nous avons utilisé une normalisation pour TF-IDF\"\"\"\n",
    "    tf, df = 0, 0\n",
    "    len_doc = len(split_words(doc))\n",
    "    value_word = 1/math.sqrt(len_doc)\n",
    "    value_word = math.sqrt(value_word)\n",
    "    len_word = len(word.split())\n",
    "    if word in str(doc):\n",
    "        tf = value_word*k/len_word\n",
    "    for doc_ in DATA:\n",
    "        if word in str(doc_):\n",
    "            df+=1\n",
    "    if df>0:\n",
    "        return tf*math.log(len(DATA)/(df), 10)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def dict_for_all_doc(data): \n",
    "    \"\"\"\n",
    "    return hold data's dictionary\"\"\"\n",
    "    dict_ = {}\n",
    "    for doc in data:\n",
    "        list_word_ = split_words(doc)    \n",
    "        dict_[doc] = {word: tf_idf_modified(word, doc, K) for word in list_word_}\n",
    "    return dict_\n",
    "    \n",
    "def dict_doc_score_for_classif(doc, sujet): \n",
    "    \"\"\"\n",
    "    We return score of all one words and all two consequent words\"\"\"\n",
    "\n",
    "    list_word_ = split_words(doc)    \n",
    "    return {word: tf_idf_for_classif(word, doc, sujet) for word in list_word_}\n",
    "\n",
    "   \n",
    "def split_words(doc):\n",
    "    \"\"\"\n",
    "    Return word and term, for example, if document of 5 words, \n",
    "    it will return 5+4+3 words and terms\"\"\"\n",
    "    list1 = doc.split()\n",
    "    list2 = []\n",
    "    for word in list1:\n",
    "        list2.append(word)\n",
    "    for i in range(len(list1)-1):\n",
    "        word = list1[i]+ ' '+list1[i+1]\n",
    "        list2.append(word)\n",
    "    if len(list1)>2:\n",
    "        for i in range(len(list1)-2):\n",
    "            word = list1[i]+' '+list1[i+1]+list1[i+2]\n",
    "            list2.append(word)\n",
    "    return list2\n",
    "        \n",
    "        \n",
    "def get_key_list(pairs_trains):\n",
    "    \n",
    "    dict_ = dict_manuelle()\n",
    "    KEY_LIST = []\n",
    "    KEY_LIST_ = []\n",
    "    for pair in pairs_trains:\n",
    "        for word in pair[1].split():\n",
    "            if '#' in word:\n",
    "                word = re.sub('#', '', word)\n",
    "                if word not in KEY_LIST:\n",
    "                    KEY_LIST.append(word)\n",
    "    for key in KEY_LIST:\n",
    "        key = stemmer.stem(key)\n",
    "        if key not in KEY_LIST_ and '_' not in key:\n",
    "            KEY_LIST_.append(key)\n",
    "    KEY_RETURN = []\n",
    "    for key in KEY_LIST_:\n",
    "        boolean = False\n",
    "        for list_ in dict_:\n",
    "            if key in list_:\n",
    "                KEY_RETURN.append(list_[0])\n",
    "                boolean = True\n",
    "                break\n",
    "        if not boolean:\n",
    "            KEY_RETURN.append(key)\n",
    "    #for list_ in dict_:\n",
    "       # if list_[0] not in KEY_RETURN:\n",
    "        #    KEY_RETURN.append(list_[0])       \n",
    "    return KEY_RETURN\n",
    "        \n",
    "\n",
    "def find_right_index(new_doc,DICT, méthode = 'normal'):\n",
    "    \n",
    "    index=0\n",
    "    biggest_score = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[0],DICT, méthode)\n",
    "    for i in range(len(QUESTION_TO_TRAINS)):\n",
    "        boolean1 = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[i], DICT, méthode) >biggest_score\n",
    "        boolean2 = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[i], DICT, méthode) == biggest_score\n",
    "        boolean3 = len(QUESTION_TO_TRAINS[index]) >len(QUESTION_TO_TRAINS[i])\n",
    "        if boolean1 or (boolean2 and boolean3):\n",
    "            biggest_score = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[i],DICT, méthode)\n",
    "            index = i\n",
    "    précision, rappel = precision_recall(new_doc, QUESTION_TO_TRAINS[index])\n",
    "    #if biggest_score ==0 or précision <0.2 or rappel<0.2:\n",
    "     #   for question in QUESTION_TO_TRAINS:\n",
    "      #      if '_return_' in question:\n",
    "       #         try:\n",
    "        #            index = QUESTION_TO_TRAINS.index(question)\n",
    "         #       except ValueError:\n",
    "          #          index = -1\n",
    "    return index\n",
    "\n",
    "def reformule_question_if_need(new_question, good_question):\n",
    "    \n",
    "    if 'to_return' in good_question:\n",
    "        return True\n",
    "    score1 = score_by_new_doc(new_question, good_question, DICT)\n",
    "    score2 = 0\n",
    "    for word in Dict_of_methode[good_question]:\n",
    "        score2 += Dict_of_methode[good_question][word]\n",
    "    if score1/score2 > 0.6:\n",
    "        return  True\n",
    "    else:\n",
    "        return  False\n",
    "\n",
    "\n",
    "def test(DICT, méthode, train =False):\n",
    "    \n",
    "    if not train:\n",
    "        index_to_print = random.sample(range(len(pairs_tests)), 20)\n",
    "        #loss_total = 0\n",
    "        for i in range(len(pairs_tests)):\n",
    "            index = find_right_index(pairs_tests[i][0], DICT, méthode)\n",
    "            #loss = _evaluate_by_right_word(pairs_trains[index][1], pairs_tests[i][1])\n",
    "            #loss_total +=loss\n",
    "            if i in index_to_print:\n",
    "                print(pairs_tests[i])\n",
    "                print(pairs_trains[index][1])\n",
    "        print('-'*80)\n",
    "       # print('ACCURACY=', 1-loss_total/len(pairs_tests))\n",
    "    if  train:\n",
    "        #loss_total = 0\n",
    "        #index_to_print = random.sample(range(len(pairs_trains)), 20)  \n",
    "        list_of_bad_prediction = []\n",
    "        i0 = 0\n",
    "        for i in range(len(pairs_trains)):\n",
    "            index = find_right_index(pairs_trains[i][0], DICT, méthode)\n",
    "            #loss = _evaluate_by_right_word(pairs_trains[index][1], pairs_trains[i][1])\n",
    "            #loss_total +=loss\n",
    "            if index != i :\n",
    "                i0 +=1\n",
    "                print(pairs_trains[i])\n",
    "                print(pairs_trains[index][1])\n",
    "        print('-'*80)\n",
    "        #print('ACCURACY=', 1-loss_total/len(pairs_trains))\n",
    "        print('Il y a {} erreurs d\\'indexes parmis {} prédictions'.format(i0, len(pairs_trains)))\n",
    "\n",
    "        \n",
    "def test_without_print(DICT, méthode, train =False):\n",
    "    \n",
    "    if not train:\n",
    "        loss_total = 0\n",
    "        for i in range(len(pairs_tests)):\n",
    "            index = find_right_index(pairs_tests[i][0], DICT, méthode)\n",
    "            loss = _evaluate_by_right_word(pairs_trains[index][1], pairs_tests[i][1])\n",
    "            loss_total +=loss\n",
    "        print('-'*80)\n",
    "        print('ACCURACY=', 1-loss_total/len(pairs_tests))\n",
    "    if  train:\n",
    "        loss_total = 0\n",
    "        index_to_print = random.sample(range(len(pairs_trains)), 20)   \n",
    "        for i in range(len(pairs_trains)):\n",
    "            index = find_right_index(pairs_trains[i][0], DICT, méthode)\n",
    "            loss = _evaluate_by_right_word(pairs_trains[index][1], pairs_trains[i][1])\n",
    "            loss_total +=loss\n",
    "        print('-'*80)\n",
    "        print('ACCURACY=', 1-loss_total/len(pairs_trains))\n",
    "\n",
    "def change_subjet_of_question(question):\n",
    "    dict_ = {'ton':'mon', 'ta':'ma', 'votre':'mon', 'tes':'mes', 'mon':'ton', \\\n",
    "            'ma':'ta', 'mes':'tes', 'tu': 'je', 'moi':'toi', 'je':'tu', 'toi':'moi',\\\n",
    "            'vous':'je'}\n",
    "    question_ = []\n",
    "    for word in question.lower().split():\n",
    "        if word in dict_:\n",
    "            word = dict_[word]\n",
    "        question_.append(word)\n",
    "    return ' '.join(question_)\n",
    "        \n",
    "def chat(méthode='normal'):\n",
    "    \n",
    "    print('Bonjour, C\\'est le bot d\\'Avicen, pose tes questions, s\\'il te plaît!')\n",
    "    path = 'processed/chat_tfidf.txt'\n",
    "    f =  open(path, 'a+') \n",
    "    while True:\n",
    "            line = str(input('Vous: '))\n",
    "            list_city = _find_right_geography(line, CITY_LIST)\n",
    "            line = line.lower().strip().strip('?').strip('.')\n",
    "            time, time_word = _find_right_time(line, COMPLET_DICT_TIME)\n",
    "            if time_word is not None:\n",
    "                line = line.replace(time_word, '')\n",
    "            if list_city is not None:\n",
    "                for city in list_city:\n",
    "                    line = line.replace(city, '')\n",
    "            LINE = clear_line(line)\n",
    "            unknown_word =0\n",
    "            for word in LINE.split():\n",
    "                if word not in LIST_OF_WORDS:\n",
    "                    unknown_word += 1\n",
    "            #if unknown_word > 1:\n",
    "             #   print('Désolé, je ne comprends pas ta question, peux tu la reformuler s\\'il te plaît?')\n",
    "              #  continue\n",
    "            if len(line) !=0:\n",
    "                index= find_right_index(LINE, DICT, méthode)\n",
    "                good_question = QUESTION_TO_TRAINS[index]\n",
    "                if not reformule_question_if_need(LINE, good_question):\n",
    "                    get_answer = str(input('Tu veux demander: {}?  |'.format(questions_sujet[index])))\n",
    "                    if 'non' in get_answer.lower():\n",
    "                        print('Peux tu reformuler ta question s\\'il te plaît?')\n",
    "                        continue\n",
    "                if time == None and list_city == None:\n",
    "                     print('bot: ', pairs_trains[index][1])\n",
    "                elif list_city ==None:\n",
    "                    print('Bot: {}, {}'.format(time_word, pairs_trains[index][1]))\n",
    "                elif time == None:\n",
    "                    cities = ' '.join(list_city)\n",
    "                    print('Bot: À {}, {}'.format(cities, pairs_trains[index][1]))\n",
    "                else:\n",
    "                    cities = ' '.join(list_city)\n",
    "                    print('Bot: À {}, {}, {}'.format(cities, time_word, pairs_trains[index][1]))\n",
    "                f.write('VOUS ++++ '+line+'\\n')\n",
    "                f.write('BOT ++++ '+pairs_trains[index][1]+'\\n')\n",
    "            \n",
    "            else:\n",
    "                f.close()\n",
    "                break \n",
    "\n",
    "def precision_recall(lstcomp, lstref):\n",
    "    \n",
    "    card_intersec = 0.0 # force à utiliser la division non entière\n",
    "    for t in set(lstcomp) :\n",
    "        card_intersec += min(lstref.count(t), lstcomp.count(t))\n",
    "    if len(lstcomp)==0:\n",
    "        precision =1\n",
    "    else:\n",
    "        precision = card_intersec/len(lstcomp)\n",
    "    if len(lstref)==0:\n",
    "        rappel = 1\n",
    "    else:\n",
    "        rappel = card_intersec/len(lstref)\n",
    "    return (precision, rappel)\n",
    "\n",
    "def answer_from_index(index, sujet):\n",
    "    if sujet:\n",
    "        convos = convos_sujet\n",
    "    else:\n",
    "        convos = convos_hors\n",
    "    return convos[index][1]\n",
    "\n",
    "def question_from_index(index, sujet):\n",
    "    if sujet:\n",
    "        convos = convos_sujet\n",
    "    else:\n",
    "        convos = convos_hors\n",
    "    return convos[index][0]\n",
    "\n",
    "def calcul_precision_recall_(train = False): \n",
    "    \n",
    "    if not train:\n",
    "        total_precision, total_recall = 0, 0\n",
    "        len_ = len(convos_test)\n",
    "        index_to_print = random.sample(range(len_), 30)\n",
    "        for i in range(len(questions_test)):\n",
    "            question = convos_test[i][0]\n",
    "            index = find_right_index_(question)\n",
    "            answer = convos_train[index][1]\n",
    "            good_answer = convos_test[i][1]\n",
    "            precision, recall = precision_recall\\\n",
    "            (answer, good_answer)\n",
    "            total_precision  += precision\n",
    "            total_recall     += recall\n",
    "            #if i in index_to_print:\n",
    "            #    print('raw questions: {}. precision {}'.format( questions_test[i], precision))\n",
    "             #   print('answer: {}. good answer: {} '.format(answer, good_answer))\n",
    "        #print('-'*80)\n",
    "        total_precision = total_precision/len_\n",
    "        total_recall = total_recall/len_      \n",
    "        F = 2*total_precision*total_recall/(total_precision+total_recall)\n",
    "        print('ON TEST, WE HAVE: PRECISION = {:.5f},  RECALL = {:.5f}, F_MESURE = {:.3f} '\\\n",
    "              .format(total_precision, total_recall,F))\n",
    "        print()\n",
    "    if  train:       \n",
    "        total_precision, total_recall = 0, 0\n",
    "        len_total = len(convos_train)\n",
    "        for i in range(len(convos_train)):\n",
    "            question = convos_train[i][0]\n",
    "            index = find_right_index_(question)\n",
    "            answer = convos_train[index][1]\n",
    "            good_answer = convos_train[i][1]\n",
    "            precision, recall = precision_recall\\\n",
    "            (answer, good_answer)\n",
    "            total_precision  += precision\n",
    "            total_recall     += recall\n",
    "        print('-'*80)\n",
    "        total_precision = total_precision/len_total\n",
    "        total_recall = total_recall/len_total     \n",
    "        F = 2*total_precision*total_recall/(total_precision+total_recall)\n",
    "        print('ON TRAINS, WE HAVE PRECISION = {:.5f},  RECALL = {:.5f}, F_MESURE = {:.3f} '\\\n",
    "              .format(total_precision, total_recall,F))\n",
    "        \n",
    "\n",
    "def return_F_score(): \n",
    "    \n",
    "        total_precision, total_recall = 0, 0\n",
    "        len_ = len(convos_test)\n",
    "        for i in range(len(questions_test)):\n",
    "            question = convos_test[i][0]\n",
    "            index = find_right_index_(question)\n",
    "            answer = convos_train[index][1]\n",
    "            good_answer = convos_test[i][1]\n",
    "            precision, recall = precision_recall\\\n",
    "            (answer, good_answer)\n",
    "            total_precision  += precision\n",
    "            total_recall     += recall\n",
    "        total_precision = total_precision/len_\n",
    "        total_recall = total_recall/len_     \n",
    "        F = 2*total_precision*total_recall/(total_precision+total_recall)\n",
    "        return F\n",
    " \n",
    "    \n",
    "def chatting_with_corpus():\n",
    "\n",
    "    path = 'processed/chat_tfidf.txt'\n",
    "    i = 0\n",
    "    questions = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            if i%2 ==0:\n",
    "                line = line[9:]\n",
    "                line = line.strip()\n",
    "                questions.append(line)\n",
    "            i +=1\n",
    "    f.close()\n",
    "    good_index = []\n",
    "    questions_ = []\n",
    "    index = 0\n",
    "    for question in questions:\n",
    "        question = clear_line(question)\n",
    "        if question not in questions_:\n",
    "            questions_.append(question)\n",
    "            good_index.append(index)\n",
    "        index += 1\n",
    "    questions_clean = [questions[i] for i in good_index]\n",
    "    for line in questions_clean:\n",
    "            print('Humaine: ', line)\n",
    "            time, time_word = _find_right_time(line, COMPLET_DICT_TIME)\n",
    "            list_city = _find_right_geography(line, CITY_LIST)\n",
    "            if time_word is not None:\n",
    "                line = line.replace(time_word, '')\n",
    "            if list_city is not None:\n",
    "                for city in list_city:\n",
    "                    line = line.replace(city, '')\n",
    "            LINE = clear_line(line)\n",
    "            unknown_word =0\n",
    "            for word in LINE.split():\n",
    "                if word not in LIST_OF_WORDS:\n",
    "                    unknown_word += 1\n",
    "            if unknown_word > 1:\n",
    "                print('Désolé, je ne comprends pas ta question, peux tu la reformuler s\\'il te plaît?')\n",
    "                print()\n",
    "                continue\n",
    "            if len(line) !=0:\n",
    "                index= find_right_index(LINE, DICT, méthode)\n",
    "                if time == None and list_city == None:\n",
    "                     print('Bot: ', pairs_trains[index][1])\n",
    "                elif list_city ==None:\n",
    "                    print('{}, {}'.format(time_word, pairs_trains[index][1]))\n",
    "                elif time == None:\n",
    "                    cities = ' '.join(list_city)\n",
    "                    print('À {}, {}'.format(cities, pairs_trains[index][1]))\n",
    "                else:\n",
    "                    cities = ' '.join(list_city)\n",
    "                    print('À {}, {}, {}'.format(cities, time_word, pairs_trains[index][1]))\n",
    "            print()\n",
    "               \n",
    "def dict_manuelle():\n",
    "    \"\"\"\n",
    "    return la liste des listes des synonymes\"\"\"\n",
    "    list_ = []\n",
    "    dict_ = {}\n",
    "    dict_['voiture'] = ['voiture', 'véhicule']\n",
    "    dict_['km'] = ['km', 'kilomètrage', 'kilométrage', 'distance', 'kilomètre']\n",
    "    dict_['essence'] = ['essence', 'carburant', 'énergie']\n",
    "    dict_['roule'] = ['roule', 'roulent', 'marche', 'marcher', 'circule', 'circulent', 'circulation']\n",
    "    dict_['bien'] = ['bien', 'bonne', 'good', 'excellent', 'parfait', 'beau', 'ok']\n",
    "    dict_['min']  = ['min', 'minimum', 'minimal']\n",
    "    dict_['pneu'] = ['pneumatique', 'pneu', 'pneus']\n",
    "    dict_['pouquoi'] = ['cause', 'pourquoi', 'raison', 'motif']\n",
    "    dict_['stupid'] = ['stupid', 'con', 'idiot', 'bête', 'imbécile']\n",
    "    dict_['connaître'] = ['connaître', 'connaitre', 'savoir', 'comprendre',\\\n",
    "                          'connaisance', 'connais', 'connaîs', 'sais', 'savez']\n",
    "    dict_['problème']  = ['problème', 'difficulté', 'danger', 'ennui', 'dangers']\n",
    "    dict_['erreur'] = ['faute', 'erreur']\n",
    "    dict_['arrêt'] = ['arrêt', 'arrêter', 'stopper', 'immobilisé', 'immobiliser', 'immobile', 'paralisé']\n",
    "    dict_['disponible'] = ['disponible', 'disponibilité', 'libre']\n",
    "    dict_['abimer'] = ['abîmer', 'hors service', 'cassé', 'endommager', 'abîmé']\n",
    "    dict_['boitier'] = ['boitier', 'boîtier', 'boîte']\n",
    "    dict_['frein'] = ['frein', 'freinage', 'freiner']\n",
    "    dict_['parcouru'] = ['parcouru', 'parcourus', 'parcourir']\n",
    "    dict_['peux'] = ['peux', 'pouvoir', 'pourrais']\n",
    "    dict_['veux'] = ['veux', 'vouloir', 'veut', 'voulais', 'voudrais', 'souhaiter', 'souhaite']\n",
    "    dict_['fait'] = ['fait', 'fais', 'faire', 'faites']\n",
    "    dict_['fort'] = ['fort', 'puissant', 'robuste', 'solide']\n",
    "    dict_['grand'] = ['grand', 'gross', 'élevé', 'haut', 'haute']\n",
    "    dict_['mal'] = ['mal', 'mauvais', 'souci']\n",
    "    dict_['changer'] = ['modifier', 'modification', 'changer', 'changement']\n",
    "    dict_['avoir'] = ['as', 'obtenir', 'avoir', 'posséder', 'disposer']\n",
    "    dict_['peur']  = ['peur', 'craint']\n",
    "    dict_['placer'] = ['placer','installer']\n",
    "    dict_['nombre'] = ['nombre', 'combien', 'quantité']\n",
    "    dict_['aider']  = ['aider', 'aide', 'soutien', 'soutenir']\n",
    "    dict_['question'] = ['question', 'demande']\n",
    "    dict_['information'] = ['information', 'infos', 'renseignement', 'indictation',\\\n",
    "                            'informer', 'renseigner','indiquer']\n",
    "    dict_['usé'] = ['usé', 'usure', 'vieux', 'vieille', 'fatigué']\n",
    "    dict_['réduire']  = ['réduire', 'réduction', 'abaisser', 'diminuer', 'diminution']\n",
    "    dict_['présent']  = ['présent', 'maitenant', 'actuel', 'actuellement']\n",
    "    dict_['suivre']   = ['suivre', 'observer', 'surveiller', 'poursuivre']\n",
    "    dict_['aller']    = ['aller', 'vas', 'vais', 'va']\n",
    "    dict_['échanger'] = ['échanger', 'estimer', 'échangement', 'estimation',\\\n",
    "                         'évaluer', 'calculer','évaluation'\\\n",
    "                        , 'mesurer']\n",
    "    dict_['taux']    = ['taux', 'pourcentage']\n",
    "    dict_['ampoule'] = ['ampoule', 'feux', 'feu']\n",
    "    for key in dict_:\n",
    "        l = []\n",
    "        for word in dict_[key]:\n",
    "            l.append(stemmer.stem(word))\n",
    "        list_.append(l)\n",
    "    return list_\n",
    "\n",
    "    \n",
    "                \n",
    "def chatting_with_test_corpus():\n",
    "    \n",
    "    path = 'test.txt'\n",
    "    questions = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "                line = line.strip()\n",
    "                questions.append(line)\n",
    "    f.close()\n",
    "    questions_clean = []\n",
    "    for question in questions:\n",
    "        if question not in questions_clean:\n",
    "            questions_clean.append(question)\n",
    "    for line in questions_clean:\n",
    "            line1 = line\n",
    "            time, time_word = _find_right_time(line, COMPLET_DICT_TIME)\n",
    "            list_city = _find_right_geography(line, CITY_LIST)\n",
    "            if time_word is not None:\n",
    "                line = line.replace(time_word, '')\n",
    "            if list_city is not None:\n",
    "                for city in list_city:\n",
    "                    line = line.replace(city, '')\n",
    "            LINE = clear_line(line)\n",
    "            unknown_word =0\n",
    "            print('Vous: ', line1)\n",
    "            for word in LINE.split():\n",
    "                if word not in LIST_OF_WORDS:\n",
    "                    unknown_word += 1\n",
    "            if unknown_word > 1:\n",
    "                print('Bot: Désolé, je ne comprends pas ta question, peux tu la reformuler s\\'il te plaît?')\n",
    "                print()\n",
    "                continue\n",
    "            if len(line) !=0:\n",
    "                index= find_right_index(LINE, DICT, méthode)\n",
    "                if time == None and list_city == None:\n",
    "                     print('Bot: ', pairs_trains[index][1])\n",
    "                elif list_city ==None:\n",
    "                    print('Bot: {}, {}'.format(time_word, pairs_trains[index][1]))\n",
    "                elif time == None:\n",
    "                    cities = ' '.join(list_city)\n",
    "                    print('Bot: À {}, {}'.format(cities, pairs_trains[index][1]))\n",
    "                else:\n",
    "                    cities = ' '.join(list_city)\n",
    "                    print('Bot: À {}, {}, {}'.format(cities, time_word, pairs_trains[index][1]))\n",
    "               \n",
    "                LINE = clear_line(line)   \n",
    "                index = find_right_index(LINE, DICT, METHODE[0])\n",
    "                #print('YOU: ', line)\n",
    "                #print('BOT: ', pairs_trains[index][1])\n",
    "                print()\n",
    "            \n",
    "\n",
    "def get_all_and_all_convos():\n",
    "    convos = []\n",
    "    file1 = 'data/convos27juin_test.txt'\n",
    "    file2 = 'data/convos27juin_train.txt'\n",
    "    files = [file1, file2]\n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "            i=0\n",
    "            for line in f:\n",
    "                if i%2==0:\n",
    "                    question = line.strip()\n",
    "                    if '++++' in question:\n",
    "                         question = question[9:]\n",
    "                else:\n",
    "                    answer = line.strip()\n",
    "                    if '++++' in answer:\n",
    "                        answer = answer[9:]\n",
    "                    convos.append([question, answer])\n",
    "                i+=1\n",
    "        f.close()\n",
    "    return convos\n",
    "\n",
    "\n",
    "def get_all_convos_in_movies():\n",
    "    convos = []\n",
    "    raw_questions = []\n",
    "    raw_convos = []\n",
    "    for root, dirs, files in os.walk(\"soustitre\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                path = os.path.join(root, file)\n",
    "                i = 0\n",
    "                with open(path, 'r') as f:\n",
    "                    get_ = False\n",
    "                    for line in f.readlines():\n",
    "                        line = line.strip('-')\n",
    "                        if i > 3:\n",
    "                            if '?' in line and get_ == False:\n",
    "                                question = line.strip()\n",
    "                                get_ = True\n",
    "                            else:\n",
    "                                if get_ == True:\n",
    "                                    answer = line.strip()\n",
    "                                    convos.append([clear_line(question), answer])\n",
    "                                    raw_convos.append([question, answer])\n",
    "                                    raw_questions.append(question)\n",
    "                                    get_ = False\n",
    "                          \n",
    "                        i +=1\n",
    "    index_of_train = random.sample(range(len(convos)), int(.8*len(convos)))\n",
    "    raw_questions = [raw_questions[i] for i in index_of_train]\n",
    "    pairs_trains = [convos[i] for i in index_of_train]\n",
    "    pairs_tests = [convos[i] for i in range(len(convos)) if i not in index_of_train]\n",
    "    return pairs_trains, pairs_tests, raw_questions, raw_convos\n",
    "\n",
    "\n",
    "    \n",
    "def dict_of_all_score_(data, KEY_LIST, sujet):\n",
    "    \"\"\"\n",
    "    return score of all word in all doc\"\"\"\n",
    "    DICT = {}\n",
    "    for doc in data:\n",
    "        DICT[doc]=dict_doc_score_(doc,KEY_LIST, sujet)\n",
    "    return DICT \n",
    "\n",
    "\n",
    "\n",
    "def find_right_index_(new_doc):\n",
    "    \n",
    "\n",
    "    index=0\n",
    "    biggest_score = score_by_new_doc_(new_doc, DATA[0],dictionary)\n",
    "    for i in range(len(DATA)):\n",
    "        boolean1 = score_by_new_doc_(new_doc, DATA[i], dictionary) > biggest_score\n",
    "        boolean2 = score_by_new_doc_(new_doc, DATA[i], dictionary) == biggest_score\n",
    "        boolean3 = len(DATA[index]) >len(DATA[i])\n",
    "        if boolean1 or (boolean2 and boolean3):\n",
    "            biggest_score = score_by_new_doc_(new_doc, DATA[i], dictionary)\n",
    "            index = i\n",
    "    if biggest_score == 0:\n",
    "        index = random.choice([i for i in range(len(DATA))])\n",
    "    return index\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def request_missing_infos(new_question, good_question, dict_):\n",
    "    \n",
    "    if 'to_return' in good_question:\n",
    "        return True\n",
    "    score1 = score_by_new_doc_(new_question, good_question, dict_)\n",
    "    score2 = 0\n",
    "    for word in dict_[good_question]:\n",
    "        score2 += dict_[good_question][word]\n",
    "    if score1/score2 > 0.6:\n",
    "        return  True\n",
    "    else:\n",
    "        return  False\n",
    "    \n",
    "def to_print_answer(line):\n",
    "    line = str(line)\n",
    "    first = line[0]\n",
    "    line = first.upper()+ line[1:]\n",
    "    if line[-1] not in ['?','.','!']:\n",
    "        line = line+'.'\n",
    "    line = line.strip(' ')\n",
    "    return line\n",
    "    \n",
    "def chat_(): \n",
    "    print('Bonjour, le bot d\\'Avicen à ton écoute')\n",
    "    path = 'processed/chat_tfidf.txt'\n",
    "    f =  open(path, 'a+') \n",
    "    while True:\n",
    "            raw_question = str(input('You: '))\n",
    "            f.write('YOU++++ '+raw_question + '\\n')\n",
    "            if len(raw_question) < 2:\n",
    "                break\n",
    "            sujet = classification(raw_question, dict_classif_sujet, dict_classif_hors)\n",
    "            answer, index, line = chat_with_each_subjet(raw_question, sujet)\n",
    "            if sujet:\n",
    "                line = clear_line(line)\n",
    "                boolean = request_missing_infos(line, convos_sujet[index][0], dict_sujet)\n",
    "                if not boolean:\n",
    "                    str_ = 'Tu veux demander: '+ questions_sujet[index] +'?'+'|'\n",
    "                    request_more = str(input(str_))\n",
    "                    if 'non' in request_more:\n",
    "                        print('Peux tu reformuler ta question, s\\'il te plaît?')\n",
    "                        continue\n",
    "                    else:\n",
    "                        print('Bot: ', to_print_answer(answer))\n",
    "                else:\n",
    "                    print('Bot: ',to_print_answer(answer))\n",
    "            else:\n",
    "                print('Bot: ' ,to_print_answer(answer)) \n",
    "                \n",
    "    \n",
    "def dict_doc_score_(doc, KEY_LIST, sujet): \n",
    "    \"\"\"\n",
    "    We return score of all one words and all two consequent words\"\"\"\n",
    "\n",
    "    list_word_ = split_words(doc)    \n",
    "    return {word: tf_idf_(word, doc, KEY_LIST, sujet) for word in list_word_}\n",
    "   \n",
    "\n",
    "    \n",
    "def score_by_new_doc_(new_doc, doc, DICT):\n",
    "    \n",
    "    list_word_in_doc = split_words(new_doc)\n",
    "    score = 0\n",
    "    for word in list_word_in_doc:\n",
    "            if word in DICT[doc]:\n",
    "                 score += DICT[doc][word]\n",
    "    return score\n",
    "\n",
    "\n",
    "def tf_idf_standard(word, doc):\n",
    "    \n",
    "    df = 0\n",
    "    doc_split = split_words(doc)\n",
    "    if word in doc_split:\n",
    "        tf = 1\n",
    "    else:\n",
    "        tf = 0\n",
    "    for doc_ in DATA:\n",
    "        if word in doc_:\n",
    "            df+=1\n",
    "    if df >0:\n",
    "        return tf*math.log(len(DATA)/df, 10)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def dict_of_entropy_for_all_terms(terms, K):\n",
    "    \"\"\"\n",
    "    Nous utilisons la méthode donné dans Class Specific TF-IDF Boosting 2018\n",
    "    K is a tuning parameter of method\"\"\"\n",
    "    dictionnary_terms ={}\n",
    "    H_max =0\n",
    "    for term in terms:\n",
    "        H = 0\n",
    "        df = 0\n",
    "        for data2 in DATA:\n",
    "            if term in data2:\n",
    "                df+=1\n",
    "        for data in DATA:\n",
    "            if term in data:\n",
    "                tf_idf = - 1/df*math.log(1/df, 2)\n",
    "            else:\n",
    "                tf_idf = 0\n",
    "            H += tf_idf\n",
    "        if H > H_max:\n",
    "            H_max = H\n",
    "        dictionnary_terms[term] = H\n",
    "    for term in terms:\n",
    "        dictionnary_terms[term] = (H_max - dictionnary_terms[term])/(H_max*K)\n",
    "    return dictionnary_terms\n",
    "\n",
    "def dict_of_all_doc_by_new_method(K):\n",
    "    \n",
    "    \"\"\"\n",
    "    This will be the dictionnary which is the heart of method\"\"\"\n",
    "    dict_of_new_method = {}\n",
    "    terms = get_all_terms()\n",
    "    dictionnary_terms = dict_of_entropy_for_all_terms(terms, K)\n",
    "    for doc in DATA:\n",
    "        terms_of_this_doc = split_words(doc)\n",
    "        dict_term_for_this_doc = {term: tf_idf_standard(term, doc)+dictionnary_terms[term]\\\n",
    "                                  if tf_idf_standard(term, doc) >0 else 0\\\n",
    "                                  for term in terms_of_this_doc}\n",
    "        dict_of_new_method[doc] = dict_term_for_this_doc\n",
    "    return dict_of_new_method\n",
    "\n",
    "def get_all_terms():\n",
    "    \"\"\"\n",
    "    return all terms for training\n",
    "    \"\"\"\n",
    "    all_terms = []\n",
    "    for data in DATA:\n",
    "        all_terms.extend(split_words(data))\n",
    "    return all_terms\n",
    "        \n",
    "    \n",
    "    \n",
    "def get_best_parameter():\n",
    "    \n",
    "    start = time.time()\n",
    "    K = [1/4000, 1/1000, 1/256, 1/64]\n",
    "    k_best = 1\n",
    "    F_best = 0\n",
    "    for k in K:      \n",
    "        dictionary =  dict_of_all_doc_by_new_method(k)\n",
    "        F_score = return_F_score()\n",
    "        print('k= {}, F score = {}'.format(k, F_score))\n",
    "        if F_score >F_best:\n",
    "            F_best = F_score\n",
    "            k_best = k\n",
    "    print('best score is {} and best k is {}'.format(F_best, k_best))\n",
    "    print('running time is ', int(time.time()-start), 's.')\n",
    "    return k_best, F_best\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def data_processed():\n",
    "    \"\"\"\n",
    "    Traiter et retourner les conversations avec les questions bien nettoyées\n",
    "    les questions sans nettoyer et le couple pour test\n",
    "    \"\"\"\n",
    "    convos1, questions1 = get_all_convos(STOPWORDS,'data/trains_sujet.txt')\n",
    "    convos2, questions2  = get_all_convos(STOPWORDS, 'data/trains_hors_sujet.txt')\n",
    "    convos3, questions3 = get_all_convos(STOPWORDS, 'data/convos3septembre_train.txt')\n",
    "    convos1.extend(convos2)\n",
    "    convos1.extend(convos3)\n",
    "    questions1.extend(questions2)\n",
    "    questions1.extend(questions3)\n",
    "    convos_test1, questions_test1 = get_all_convos(STOPWORDS, 'data/tests_16juillet.txt')\n",
    "    convos_test2, questions_test2 = get_all_convos(STOPWORDS, 'data/convos3septembre_test.txt')\n",
    "    convos_test1.extend(convos_test2)\n",
    "    questions_test1.extend(questions_test2)\n",
    "    index_suff = [i for i in range(len(convos1))]\n",
    "    random.shuffle(index_suff)\n",
    "    convos, questions = [], []\n",
    "    for i in index_suff:\n",
    "        convos.append(convos1[i])\n",
    "        questions.append(questions1[i])\n",
    "    index_suff_ = [i for i in range(len(convos_test1))]\n",
    "    random.shuffle(index_suff_)\n",
    "    convos_test, questions_test = [], []\n",
    "    for i in index_suff_:\n",
    "        convos_test.append(convos_test1[i])\n",
    "        questions_test.append(questions_test1[i])    \n",
    "    return convos, questions, convos_test, questions_test\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "def convos_to_questions(convos):\n",
    "    \"\"\"\n",
    "    prend tous les conversations dans corpus et renvoie un array de documents avec\n",
    "    des vocabulaires séparés\"\"\"\n",
    "    \n",
    "    data = []\n",
    "    for convo in convos:\n",
    "        data.append(convo[0])\n",
    "    return data\n",
    "\n",
    "def get_answer(index):\n",
    "    if index != None:\n",
    "        return convos_train[index][1]\n",
    "    else:\n",
    "        return 'Désolé, je ne comprends pas ta question'\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    try:\n",
    "        convos_train_\n",
    "    except NameError:\n",
    "        list_K = [1/10,1,10, 100]\n",
    "        convos_train, questions, convos_test, questions_test = data_processed()\n",
    "        DATA = convos_to_questions(convos_train)\n",
    "        start = time.time()\n",
    "        #dictionary =  dict_for_all_doc(DATA)\n",
    "        #KEY_LIST_  = get_key_list(convos_sujet)\n",
    "        #COMPLET_DICT_TIME = date_time_()\n",
    "        #CITY_LIST = construct_list_city()\n",
    "        print('Training on {} couples and test on {} couple'\\\n",
    "              .format(len(convos_train), len(convos_test)))\n",
    "        for K in list_K:\n",
    "            dictionary = dict_for_all_doc(DATA)\n",
    "            calcul_precision_recall_(False)\n",
    "            calcul_precision_recall_(True)\n",
    "        print('RUNNING TIME IS {:.2f} seconds '.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ça vous dit rien \n",
      "il était comment \n",
      "mais est pas en été ça \n",
      "quel voitur vitess plus pet\n",
      "vous veux pas le aid pour rendr servic \n",
      "est pas si grav \n",
      "quoi \"ça\" \n",
      "vous ête accord avec moi que tout fout le camp \n",
      "comment vous trouv le rougeaud \n",
      "ai don mon accord pour ça \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(random.choice(DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, le bot d'Avicen à ton écoute\n",
      "You: hello\n",
      "Bot:  Bonjour.\n",
      "You: how are you?\n",
      "Bot:  Je suis là pour tes questions concernants tes voitures.\n",
      "You: how do you do?\n",
      "Bot:  Je suis là pour tes questions concernants tes voitures.\n",
      "You: comment tu vas?\n",
      "Bot:  Je vais bien merci.\n",
      "You: j'ai des questions pour toi\n",
      "Bot:  Oui pose ta question.\n",
      "You: combien voitures au parc\n",
      "Bot:  Il y a #nb_véhicule#.\n",
      "You: tu as une copine?\n",
      "Bot:  Je suis là pour tes questions concernants tes voitures.\n",
      "You: es tu une fille?\n",
      "Bot:  Madenn.\n",
      "You: es tu un gars\n",
      "Bot:  J'en sais rien.\n",
      "You: comment ton prénom\n",
      "Bot:  Je m'appelle Emmet, je suis une création d'AVICEN.\n",
      "You: qui est avicen\n",
      "Tu veux demander: tvs?|non\n",
      "Peux tu reformuler ta question, s'il te plaît?\n",
      "You: c'est quoi avicen\n",
      "Tu veux demander: le tco c'est quoi?|non\n",
      "Peux tu reformuler ta question, s'il te plaît?\n",
      "You: je ne comprends rien\n",
      "Bot:  Au bûcher !\n",
      "You: bye\n",
      "Bot:  Au revoir.\n",
      "You: à très bien tôt\n",
      "Bot:  À bien tôt.\n",
      ".\n",
      "You: \n"
     ]
    }
   ],
   "source": [
    "chat_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, le bot d'Avicen à ton écoute\n",
      "You: hello\n",
      "Bonjour.\n",
      "You: how are you\n",
      "Je suis là pour tes questions concernants tes voitures.\n",
      "You: quelle voiture\n",
      "Bot:  La liste des véhicule est #listing_vin#.\n",
      "You: t'es rigolo\n",
      "Merci\n",
      ".\n",
      "You: t'es con\n",
      "Pourquoi des mots méchants.\n",
      "You: je cherche ma voiture\n",
      "Bot:  #ask_id# #position#.\n",
      "You: où est ma femme\n",
      "Tu veux demander: où est mon véhicule?|oui\n",
      "Bot:  Ton véhicule est à #position#.\n",
      "You: je cherche mon véhicule\n",
      "Bot:  #ask_id# #position#.\n",
      "You: je cherche la voiture qui roule plus vite\n",
      "Tu veux demander: quels véhicules ont batterie plus vite?|non, ce sera la voiture plus rapide\n",
      "Peux tu reformuler ta question, s'il te plaît?\n",
      "You: quelle voiture plus rapide\n",
      "Tu veux demander: trouvez le véhicule le plus proche?|non\n",
      "Peux tu reformuler ta question, s'il te plaît?\n",
      "You: quelle voiture vitesse plus raide\n",
      "Bot:  Véhicule #id# #vitesse# #MIN#.\n",
      "You: quelle voiture vitesse plus rapide\n",
      "Bot:  Véhicule #id# #vitesse# #MIN#.\n",
      "You: quelle voiture vitesse maximale\n",
      "Bot:  Véhicule #id# #vitesse# #MAX#.\n",
      "You: quelle est la voiture vitesse plus rapide\n",
      "Bot:  Véhicule #id# #vitesse# #MIN#.\n",
      "You: moins rapide\n",
      "Tu veux demander: quelle voiture km moins vite?|oui\n",
      "Bot:  Véhicule #id# #km# #MIN#.\n",
      "You: \n"
     ]
    }
   ],
   "source": [
    "chat_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, le bot d'Avicen à ton écoute\n",
      "You: salut\n",
      "Au revoir.\n",
      "You: bien\n",
      "Quoi ?.\n",
      "You: comment tu vas?\n",
      "Je vais bien merci.\n",
      "You: très bien\n",
      "Au revoir.\n",
      "You: bon, bonne nuit\n",
      "Qu'en faites-vous, de l'esprit ?.\n",
      "You: je ne fais rien\n",
      "Expliquez-moi ce que vous faites là..\n",
      "You: je cherche ma voiture\n",
      "Bot:  #ask_id# #position#.\n",
      "You: je veux ma femme\n",
      "Ça m'arrangerait..\n",
      "You: comment tu vas\n",
      "Je vais bien merci.\n",
      "You: comment tu t'appelles\n",
      "Je m'appelle Emmet, je suis une création d'AVICEN.\n",
      "You: bon, je suis très content de parler avec toi\n",
      "Les choses avancent petit à petit..\n",
      "You: qui es tu\n",
      "Je suis là pour tes questions concernants tes voitures.\n",
      "You: combien de voitures en route\n",
      "Ah ! Hé !.\n",
      "You: combien de voitures à l'arrêt?\n",
      "Arrêtez !.\n",
      "You: combien de voitures nous avons?\n",
      "Bot:  Il y a #nb_veh#.\n",
      "You: combien de véhicules en circulation\n",
      "Bot:  #total_veh_movement#.\n",
      "You: où sont les voitures\n",
      "Non..\n",
      "You: où est la voiture\n",
      "Non..\n",
      "You: où est ma voiture\n",
      "Non..\n",
      "You: je cherche ma voiture\n",
      "Bot:  #ask_id# #position#.\n",
      "You: la voiture avec vitesse maximale\n",
      "Non..\n",
      "You: tu dis de con\n",
      "Pourquoi des mots méchants.\n",
      "You: mais tu ne comprends pas bien ce que je dis\n",
      "Au bûcher !.\n",
      "You: bon\n",
      "Quoi ?.\n",
      "You: combien de voitures en marche\n",
      "Ah ! Hé !.\n",
      "You: oh, je ne comprends pas\n",
      "Au bûcher !.\n",
      "You: problème de vitesse\n",
      "Je pense bien !.\n",
      "You: problème de flotte\n",
      "Je pense bien !.\n",
      "You: problème de batterie\n",
      "Je pense bien !.\n",
      "You: il y a de problème de pneu\n",
      "Je pense bien !.\n",
      "You: t'es con\n",
      "Pourquoi des mots méchants.\n",
      "You: bon, on parle d'autre chose\n",
      "Non..\n",
      "You: tu veux quoi alors\n",
      "Le gars, il était toujours en rogne, gueulant du soir au matin, alors difficile de s'approcher de lui..\n",
      "You: on parle de lui alors\n",
      "Je suis d'accord..\n",
      "You: bon, comment il s'appelle\n",
      "Je m'appelle Emmet, je suis une création d'AVICEN.\n",
      "You: non, pas toi, lui\n",
      "Non..\n",
      "You: tui ne comprends pas\n",
      "Au bûcher !.\n",
      "You: je cherche mes voitures\n",
      "Bot:  #ask_id# #position#.\n",
      "You: bon, d'accord\n",
      "Inversez tout, et vous vous y retrouverez..\n",
      "You: c'est pas évident de comprendre ce que tu dis\n",
      "Tout à fait..\n",
      "You: qui es tu\n",
      "Je suis là pour tes questions concernants tes voitures.\n",
      "You: c'est quoi ton prénom\n",
      "Je m'appelles Emmet.\n",
      "You: c'est quoi ton métier\n",
      "Ben, militaire. Mais en ce moment, je ne fais pas grand-chose..\n",
      "You: tu travaille pour avice\n",
      "Pour personne. Pour bibi !.\n",
      "You: tu travailles pour avicen\n",
      "Pour personne. Pour bibi !.\n",
      "You: sois poli\n",
      "Non, mais c'est drôle..\n",
      "You: non, je suis sérieux\n",
      "Non..\n",
      "You: c'est quoi ta date de naissance\n",
      "Je m'appelle Emmet, je suis une création d'AVICEN.\n",
      "You: quel age tu as\n",
      "Plus que d'habitude..\n",
      "You: tu as quel âge\n",
      "4 ans..\n",
      "You: juste ça\n",
      "Les giboulées ?.\n",
      "You: \n"
     ]
    }
   ],
   "source": [
    "chat_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, le bot d'Avicen à ton écoute\n",
      "You: hello\n",
      "Bonjour.\n",
      "You: ça va\n",
      "Ça va et toi.\n",
      "You: tout va bien?\n",
      "Ça va.\n",
      "You: je cherche ma voiture\n",
      "Bot:  #ask_id# #position#.\n",
      "You: combien de voitures nous avons dans notre parc\n",
      "Ah ! Hé !\n",
      "You: combien de véhicules nous avons\n",
      "Bot:  Il y a #nb_veh#.\n",
      "You: quelle voiture de vitesse maximale\n",
      "Non.\n",
      "You: quel véhicule de vitesse minimale\n",
      "C'est tout con, comme jeu.\n",
      "You: combien de véhicule en circulation?\n",
      "Ah ! Hé !\n",
      "You: combien\n",
      "Ah ! Hé !\n",
      "You: je ne comprend rien\n",
      "Au bûcher !\n",
      "You: \n"
     ]
    }
   ],
   "source": [
    "chat_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, le bot d'Avicen à ton écoute\n",
      "You: hello\n",
      "Bot:  Bonjour.\n",
      "You: ça va\n",
      "Bot:  Ça va et toi.\n",
      "You: quelle voiture de vitesse maximale\n",
      "Bot:  Véhicule #id# #vitesse# #MAX#.\n",
      "You: quelle voiture de baisse baterie\n",
      "Bot:  La liste des véhicule est #listing_vin#.\n",
      "You: quelle voiture de baisse batterie\n",
      "Tu veux demander: quelle voiture batterie max?|non\n",
      "Peux tu reformuler ta question, s'il te plaît?\n",
      "You: quelle voiture qui a le problème de batterie\n",
      "Bot:  Véhicule #id# #problèmes# #batterie#.\n",
      "You: demain on fait quoi\n",
      "Tu veux demander: je veux faire réviser mon véhicule demain?|non\n",
      "Peux tu reformuler ta question, s'il te plaît?\n",
      "You: il y a des véhicules à Lyon\n",
      "Tu veux demander: où est mon véhicule?|non\n",
      "Peux tu reformuler ta question, s'il te plaît?\n",
      "You: tu es un gars ou une fille\n",
      "Bot:  Madenn.\n",
      "You: qui es tu\n",
      "Bot:  Je suis là pour tes questions concernants tes voitures.\n",
      "You: comment tu t'appelles\n",
      "Bot:  Je m'appelle Emmet, je suis une création d'AVICEN.\n",
      "You: combien de véhicules dans notre parc\n",
      "Bot:  Il y a #nb_véhicule#.\n",
      "You: combien en circulation\n",
      "Bot:  #total_veh_movement#.\n",
      "You: quelle est ton rôle dans l'entreprise?\n",
      "Tu veux demander: quelles sont les coordonnées de ton entreprise?|oui\n",
      "Bot:  Avicen se trouve à 92 cours lafayette 69003 lyon.\n",
      "You: qui est ton patron\n",
      "Bot:  Je suis là pour tes questions concernants tes voitures.\n",
      "You: quel âge tu as\n",
      "Bot:  4 ans.\n",
      "You: tu as quel âge\n",
      "Bot:  4 ans.\n",
      "You: tu parle anglais?\n",
      "Bot:  Je suis d'accord.\n",
      "You: quelle est ton origine\n",
      "Bot:  L'ensemble des modules disponibles sont sur le store.\n",
      "You: combien de véhicules en arrêt\n",
      "Bot:  #combien# #arrêt#.\n",
      "You: je cherche mon copain\n",
      "Tu veux demander: je cherche une voiture?|non\n",
      "Peux tu reformuler ta question, s'il te plaît?\n",
      "You: où est mon copain\n",
      "Tu veux demander: où est mon véhicule?|non\n",
      "Peux tu reformuler ta question, s'il te plaît?\n",
      "You: peut on parler d'autre chose?\n",
      "Bot:  C'est votre allié.\n",
      "You: quoi de neuf\n",
      "Tu veux demander: le tco c'est quoi?|non\n",
      "Peux tu reformuler ta question, s'il te plaît?\n",
      "You: tu ne comprend rien\n",
      "Bot:  Au bûcher !\n",
      "You: c'est quoi\n",
      "Bot:  Exactement.\n",
      "You: mais t'es stupid\n",
      "Bot:  Pourquoi des mots méchants.\n",
      "You: femme\n",
      "Bot:  Oh ! Ça va !\n",
      "You: enfants\n",
      "Bot:  Peut-être, mais j'arrive pas à les trouver.\n",
      "You: femmes\n",
      "Bot:  Oh ! Ça va !\n",
      "You: hommes\n",
      "Bot:  J'ai encore des obligations envers Arthur.\n",
      "You: roi\n",
      "Bot:  Il est chez lui, alors il va pas se gêner pour visiter un camp qu'il a payé.\n",
      "You: qui est le roi\n",
      "Tu veux demander: tvs?|non\n",
      "Peux tu reformuler ta question, s'il te plaît?\n",
      "You: qui est le plus fort\n",
      "Tu veux demander: qui est le plus fort du monde?|oui\n",
      "Bot:  Je l'ignore. peut être moi :).\n",
      "You: qui est le plus con\n",
      "Tu veux demander: qui est le plus fort du monde?|non\n",
      "Peux tu reformuler ta question, s'il te plaît?\n",
      "You: \n"
     ]
    }
   ],
   "source": [
    "chat_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
