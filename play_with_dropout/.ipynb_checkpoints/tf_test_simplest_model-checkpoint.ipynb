{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modèle n'est pas bon, ce peut être la faute de quelque fonction comme sampled_softmax_loss() dans model.\n",
    "De toute façon, le modèle est plus lourd que ce lui de Torch\n",
    "Tester pour:\n",
    "hidden_size = 40, layer =3, sample_size = 200 accuracy = 17%\n",
    "hidden_size = 40, layer =3, sample_size = DEC_VOCAB-1, accuracy = 27%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucketing conversation number 100\n",
      "Bucketing conversation number 200\n",
      "Bucketing conversation number 300\n",
      "Bucketing conversation number 400\n",
      "Bucketing conversation number 500\n",
      "Bucketing conversation number 100\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from model_70_1 import ChatBotModel\n",
    "import config_tf as config\n",
    "import data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def run_step(sess, model, encoder_inputs, decoder_inputs,\n",
    "             decoder_masks, bucket_id, forward_only):\n",
    "    encoder_size, decoder_size = config.BUCKETS[bucket_id]\n",
    "    input_feed = {}\n",
    "    for step in range(encoder_size):\n",
    "        input_feed[model.encoder_inputs[step].name] = encoder_inputs[step]\n",
    "    for step in range(decoder_size):\n",
    "        input_feed[model.decoder_inputs[step].name] = decoder_inputs[step]\n",
    "        input_feed[model.decoder_masks[step].name] = decoder_masks[step]\n",
    "    \n",
    "    last_target = model.decoder_inputs[decoder_size].name\n",
    "    input_feed[last_target] = np.zeros([model.batch_size], dtype=np.int32)\n",
    "    if not forward_only:\n",
    "        output_feed = [model.train_ops[bucket_id],  # update op that does SGD.\n",
    "                       model.gradient_norms[bucket_id],  # gradient norm.\n",
    "                       model.losses[bucket_id]]  # loss for this batch.\n",
    "    else:\n",
    "        output_feed = [model.losses[bucket_id]]  # loss for this batch.\n",
    "        for step in range(decoder_size):  # output logits.\n",
    "            output_feed.append(model.outputs[bucket_id][step])\n",
    "    outputs = sess.run(output_feed, input_feed)\n",
    "    if not forward_only:\n",
    "        return outputs[1], outputs[2], None  # Gradient norm, loss, no outputs.\n",
    "    else:\n",
    "        return None, outputs[0], outputs[1:]  # No gradient norm, loss, outputs.\n",
    "\n",
    "def _get_data(train=True):\n",
    "    \n",
    "    #enc_vocab, dec_vocab, inv_enc_vocab, inv_dec_vocab = build_vocab()\n",
    "    if train:\n",
    "          DATA = data.load_data('question_train2id.txt', 'answer_train2id.txt')\n",
    "    else:\n",
    "          DATA = data.load_data('question_test2id.txt', 'answer_test2id.txt')                              \n",
    "    return  DATA\n",
    "\n",
    "def _get_skip_step(n_iters):\n",
    "    \"\"\" How many steps should the model train before it saves all the weights. \"\"\"\n",
    "\n",
    "    return int(n_iters/10)\n",
    "\n",
    "def _check_restore_parameters(sess, saver):\n",
    "    \"\"\" Restore the previously trained parameters if there are any. \"\"\"\n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname(config.CPT_PATH_70_1 + '/checkpoint'))\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        print(\"Loading parameters for the Chatbot\")\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        print(\"Initializing fresh parameters for the Chatbot\")\n",
    "\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def train(n_iters, lr = config.LR):\n",
    "    \"\"\" Train the bot \"\"\"\n",
    "    data_buckets = training_data[0]\n",
    "    tf.reset_default_graph() \n",
    "    model = ChatBotModel(False, config.BATCH_SIZE, lr = lr)\n",
    "    model.build_graph()\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        print('Running session')\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        _check_restore_parameters(sess, saver)\n",
    "\n",
    "        iteration = model.global_step.eval()\n",
    "        total_loss = 0\n",
    "        step =0\n",
    "        loss_print = []\n",
    "        bucket_id = 0\n",
    "        start = time.time()\n",
    "        while step < n_iters:\n",
    "            step+=1\n",
    "            skip_step = _get_skip_step(n_iters)\n",
    "            encoder_inputs, decoder_inputs, decoder_masks = data.get_batch(data_buckets, \n",
    "                                                                           bucket_id,\n",
    "                                                                           batch_size=config.BATCH_SIZE)\n",
    "            \n",
    "            _, step_loss, _ = run_step(sess, model, encoder_inputs, \n",
    "                                       decoder_inputs, decoder_masks, bucket_id, False)\n",
    "            total_loss += step_loss\n",
    "            iteration += 1\n",
    "            if iteration % skip_step == 0:  \n",
    "                print_loss_avg = total_loss / skip_step\n",
    "                total_loss = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, step / n_iters),\n",
    "                                         iteration, step / n_iters * 100, print_loss_avg))\n",
    "                total_loss = 0\n",
    "                loss_print.append(step_loss)\n",
    "        saver.save(sess, os.path.join(config.CPT_PATH_70_1, 'chatbot'), global_step=model.global_step)\n",
    "        sys.stdout.flush()\n",
    "        plt.plot(loss_print)\n",
    "        plt.show()\n",
    "\n",
    "def _get_user_input():\n",
    "    t = input('Vous:  ')\n",
    "    return t\n",
    "\n",
    "def _construct_reponse(output_logits, dec_vocab):\n",
    "    outputs = [int(np.argmax(logit, axis=1)) for logit in output_logits]\n",
    "    if 3 in outputs:\n",
    "        outputs = outputs[1:outputs.index(3)]\n",
    "    else:\n",
    "        outputs = outputs[1:]\n",
    "\n",
    "    return \" \".join([tf.compat.as_str(dec_vocab[output]) for output in outputs])\n",
    "\n",
    "def chat():\n",
    "    _, enc_vocab = data.load_vocab(os.path.join(config.PROCESSED_PATH, 'encoder_vocab.txt'))\n",
    "    inv_dec_vocab, _= data.load_vocab(os.path.join(config.PROCESSED_PATH, 'decoder_vocab.txt'))\n",
    "    tf.reset_default_graph() \n",
    "    model = ChatBotModel(True, batch_size=1)\n",
    "    model.build_graph()\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        _check_restore_parameters(sess, saver)\n",
    "        output_file = open(os.path.join(config.PROCESSED_PATH, config.OUTPUT_FILE), 'a+')\n",
    "        max_length = config.BUCKETS[-1][0]\n",
    "        print('Bonjour, dites moi ce que vous voulez: ')\n",
    "        while True:\n",
    "            line = _get_user_input()\n",
    "            if len(line) > 0 and line[-1] == '\\n':\n",
    "                line = line[:-1]\n",
    "            if line == '':\n",
    "                break\n",
    "            output_file.write('VOUS ++++ ' + line + '\\n')\n",
    "            token_ids = data.sentence2id(enc_vocab, str(line))\n",
    "            if (len(token_ids) > max_length):\n",
    "                print('La longueur maximale est:', max_length)\n",
    "                continue\n",
    "            bucket_id = _find_right_bucket(len(token_ids))\n",
    "            encoder_inputs, decoder_inputs, decoder_masks = data.get_batch([(token_ids, [])], \n",
    "                                                                            bucket_id,\n",
    "                                                                            batch_size=1)\n",
    "            _, _, output_logits = run_step(sess, model, encoder_inputs, decoder_inputs,\n",
    "                                           decoder_masks, bucket_id, True)\n",
    "            response = _construct_reponse(output_logits, dec_vocab)\n",
    "            \n",
    "            print('Bot de AVICEN:  ', response)\n",
    "            output_file.write('BOT ++++ ' + response + '\\n')\n",
    "        output_file.write('=============================================\\n')\n",
    "        output_file.close()\n",
    "        \n",
    "def dictionnary_for_chat():\n",
    "    out_file = open(os.path.join(config.PROCESSED_PATH, 'dictionnary.txt'), 'w')\n",
    "    with open('thes_fr.txt') as f:\n",
    "        for line in f:\n",
    "            line = re.split(\"[()]\",line)[-1]\n",
    "            line = line.strip('|').strip('1').strip().split('|')\n",
    "            line = [i for i in line if i != '1']\n",
    "            out_file.write('|'.join(str(id_) for id_ in line) + '\\n')\n",
    "    out_file.close() \n",
    "    \n",
    "def construct_dict(lang):\n",
    "    \"\"\"\n",
    "    return list des vocabulaire\"\"\"\n",
    "    in_file = open(os.path.join(config.PROCESSED_PATH, 'dictionnary.txt'), 'r')\n",
    "    lines = []\n",
    "    for word in lang.word2index:\n",
    "        for line in in_file:\n",
    "            line = line.strip().split('|')\n",
    "            if word in line:\n",
    "                line.insert(word,0)\n",
    "                lines.append(line)\n",
    "                break\n",
    "    return lines\n",
    "        \n",
    "def evaluate_randomly(n_iters=300, test=True):\n",
    "    if not test:\n",
    "        tf.reset_default_graph() \n",
    "        model = ChatBotModel(True, batch_size=1)\n",
    "        model.build_graph()\n",
    "        saver = tf.train.Saver()\n",
    "        list_print_random = random.sample(range(n_iters), 20)\n",
    "        total_loss = 0\n",
    "        training_data = _get_data(True)\n",
    "        training_data = training_data[0]\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            _check_restore_parameters(sess, saver)\n",
    "            for i in range(n_iters):\n",
    "                random_index = random.choice(range(len(training_data)))\n",
    "                bucket_id = 0  \n",
    "                question = training_data[random_index][0]\n",
    "                answer = training_data[random_index][1]\n",
    "                encoder_inputs, decoder_inputs, decoder_masks = \\\n",
    "                    data.get_batch([(question, [])], \\\n",
    "                    bucket_id, batch_size=1)\n",
    "                _, _, output_logits = run_step(sess, model, encoder_inputs, decoder_inputs,\n",
    "                                           decoder_masks, bucket_id, True)\n",
    "                reponse = _construct_reponse(output_logits, dec_vocab)\n",
    "                bonne_reponse = \" \".join([str(dec_vocab[id]) for id in answer])\n",
    "                question = \" \".join([str(enc_vocab[id]) for id in question])\n",
    "                loss = _evaluate_by_right_word(reponse, bonne_reponse)\n",
    "                total_loss +=loss\n",
    "                if i in list_print_random:\n",
    "                    print('--------------------------------------------------')\n",
    "                    print('Question:  ',  question)\n",
    "                    print('Bot     :  ', reponse)\n",
    "                    print('Réponse: {}  ACCURACY {}'.format(bonne_reponse, 1-loss))\n",
    "        print('Test on {} sentences in train set with accuracy {}'.format(n_iters,1- total_loss/n_iters))\n",
    "    else:\n",
    "        tf.reset_default_graph() \n",
    "        model = ChatBotModel(True, batch_size=1)\n",
    "        model.build_graph()\n",
    "        saver = tf.train.Saver()\n",
    "        total_loss = 0\n",
    "        test_data = _get_data(False)\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            _check_restore_parameters(sess, saver)\n",
    "            n_iters = len(test_data[0])\n",
    "            test_data = test_data[0]\n",
    "            print_random_index = random.sample(range(n_iters), 20)\n",
    "            bucket_id = 0\n",
    "            for i in range(n_iters):\n",
    "                question = test_data[i][0]\n",
    "                answer = test_data[i][1]\n",
    "                encoder_inputs, decoder_inputs, decoder_masks = data.get_batch([(question, [])], \n",
    "                                                                            bucket_id,\n",
    "                                                                            batch_size=1)\n",
    "                _, _, output_logits = run_step(sess, model, encoder_inputs, decoder_inputs,\n",
    "                                           decoder_masks, bucket_id, True)\n",
    "                reponse = _construct_reponse(output_logits, dec_vocab)\n",
    "                bonne_reponse = \" \".join([str(dec_vocab[id]) for id in answer[1:-1]])\n",
    "                loss = _evaluate_by_right_word(reponse, bonne_reponse)\n",
    "                total_loss +=loss\n",
    "                if i in print_random_index:\n",
    "                    question = \" \".join([str(enc_vocab[id]) for id in question])\n",
    "                    print('Question: ', question)\n",
    "                    print('Reponse: ', reponse)\n",
    "                    print('Bonne Reponse: {}. ACCURACY {:.1f} '.format(bonne_reponse,1-loss))\n",
    "                    print('-'*50)\n",
    "        print('Test on {} sentences'.format(n_iters))\n",
    "        print('Accuracy by percent of true words {}'.format(1-total_loss/n_iters))\n",
    "        #return loss/n_iters\n",
    "\n",
    "def _evaluate_by_right_word(reponse, bonne_reponse):\n",
    "    reponse = reponse.split()\n",
    "    bonne_reponse = bonne_reponse.split()\n",
    "    min_length = min(len(reponse), len(bonne_reponse))\n",
    "    max_length = max(len(reponse), len(bonne_reponse))\n",
    "    error = max_length-min_length\n",
    "    for i in range(min_length):\n",
    "        if reponse[i] != bonne_reponse[i]:\n",
    "            error +=1\n",
    "    return error/max_length\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    try:\n",
    "        training_data\n",
    "    except NameError:\n",
    "        enc_vocab_file = os.path.join(config.PROCESSED_PATH, 'encoder_vocab.txt')\n",
    "        dec_vocab_file = os.path.join(config.PROCESSED_PATH, 'decoder_vocab.txt')\n",
    "        enc_vocab, inv_enc_vocab = data.load_vocab(enc_vocab_file)\n",
    "        dec_vocab, inv_dec_vocab = data.load_vocab(dec_vocab_file)\n",
    "        training_data = _get_data(True)\n",
    "        test_data = _get_data(False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize new model\n",
      "Time: 15.649794816970825\n",
      "Bucketing conversation number 100\n",
      "Loading parameters for the Chatbot\n",
      "INFO:tensorflow:Restoring parameters from checkpoints_70_1/chatbot-4100\n",
      "Question:  des véhicules hors périmètre\n",
      "Reponse:  je informations cela tout en disposons du dehors de la zone définie semble définie\n",
      "Bonne Reponse: #oui/non#. ACCURACY 0.0 \n",
      "--------------------------------------------------\n",
      "Question:  où est ma facture\n",
      "Reponse:  elle est votre disponible client\n",
      "Bonne Reponse: votre facture est disponible dans votre espace client. ACCURACY 0.1 \n",
      "--------------------------------------------------\n",
      "Question:  est-ce que la consommation de carburant est excessive\n",
      "Reponse:  je\n",
      "Bonne Reponse: la consommation est de #consumptionr#. ACCURACY 0.0 \n",
      "--------------------------------------------------\n",
      "Question:  quel est le kilomètrage moyen de ce véhicule\n",
      "Reponse:  le constructeur de ce est de #km#\n",
      "Bonne Reponse: en moyenne ce véhicule a roulé #km#. ACCURACY 0.1 \n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules ont roulés\n",
      "Reponse:  #total_veh_movement#\n",
      "Bonne Reponse: #total_veh_movement#. ACCURACY 1.0 \n",
      "--------------------------------------------------\n",
      "Question:  puis-je avoir le contact du sav\n",
      "Reponse:  quel module le demande\n",
      "Bonne Reponse: voici le numéro #tel_sav#. ACCURACY 0.0 \n",
      "--------------------------------------------------\n",
      "Question:  quel véhicule puis-je utiliser aujourd'hui\n",
      "Reponse:  vous\n",
      "Bonne Reponse: vous pouvez vous servir du #list_vin_free#. ACCURACY 0.2 \n",
      "--------------------------------------------------\n",
      "Question:  quel véhicule est disponible cet après-midi\n",
      "Reponse:  vous pouvez vous servir du #list_vin_immediat#\n",
      "Bonne Reponse: vous pouvez vous servir du #list_vin_afternoon#. ACCURACY 0.8 \n",
      "--------------------------------------------------\n",
      "Question:  quelles sont les alertes\n",
      "Reponse:  les sont sont sont sont\n",
      "Bonne Reponse: les alertes sont #list_alert#. ACCURACY 0.4 \n",
      "--------------------------------------------------\n",
      "Question:  nom de l'interlocuteur\n",
      "Reponse:  bancaire\n",
      "Bonne Reponse: votre interlocuteur est #list_contact#. ACCURACY 0.0 \n",
      "--------------------------------------------------\n",
      "Question:  durée de location\n",
      "Reponse:  la durée de votre location du #vin# du mois\n",
      "Bonne Reponse: le contrat indique une durée de location égale à #duree_lld# mois. ACCURACY 0.0 \n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicule composent ma flotte\n",
      "Reponse:  il a parcouru #km#\n",
      "Bonne Reponse: #nb_vehicule#. ACCURACY 0.0 \n",
      "--------------------------------------------------\n",
      "Question:  vous vous appelez comment\n",
      "Reponse:  il faut faire vous bot vous inscrire\n",
      "Bonne Reponse: je suis le bot de avicen tu peux m'appeler charlie. ACCURACY 0.0 \n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules sont roulés\n",
      "Reponse:  #total_veh_movement#\n",
      "Bonne Reponse: #total_veh_movement#. ACCURACY 1.0 \n",
      "--------------------------------------------------\n",
      "Question:  combien de voitures circulent\n",
      "Reponse:  il y a #nb_véhicules#\n",
      "Bonne Reponse: #total_veh_movement# véhicules de la société roulent actuellement. ACCURACY 0.0 \n",
      "--------------------------------------------------\n",
      "Question:  bonsoir\n",
      "Reponse:  bonsoir\n",
      "Bonne Reponse: bonsoir. ACCURACY 1.0 \n",
      "--------------------------------------------------\n",
      "Question:  bonsoir\n",
      "Reponse:  bonsoir\n",
      "Bonne Reponse: bonsoir. ACCURACY 1.0 \n",
      "--------------------------------------------------\n",
      "Question:  y a t-il des problèmes\n",
      "Reponse:  #oui/non#\n",
      "Bonne Reponse: oui. ACCURACY 0.0 \n",
      "--------------------------------------------------\n",
      "Question:  la voiture est opérationnelle\n",
      "Reponse:  quelle vais cela plus à #position#\n",
      "Bonne Reponse: je le vérifie. ACCURACY 0.0 \n",
      "--------------------------------------------------\n",
      "Question:  quelle est la pression des pneus\n",
      "Reponse:  la marque des pneus\n",
      "Bonne Reponse: la pression des pneus est #tpms# bar. ACCURACY 0.4 \n",
      "--------------------------------------------------\n",
      "Test on 131 sentences\n",
      "Accuracy by percent of true words 0.23232350770518717\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize new model\n",
      "Time: 1.6999356746673584\n",
      "Bucketing conversation number 100\n",
      "Bucketing conversation number 200\n",
      "Bucketing conversation number 300\n",
      "Bucketing conversation number 400\n",
      "Bucketing conversation number 500\n",
      "Loading parameters for the Chatbot\n",
      "INFO:tensorflow:Restoring parameters from checkpoints_70_1/chatbot-56000\n",
      "--------------------------------------------------\n",
      "Question:   quel carburant\n",
      "Bot     :   \n",
      "Réponse: <s> #carburant# <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   j'ai fais un remplacement de véhicule\n",
      "Bot     :   faut mettre à jour la base de données véhicules\n",
      "Réponse: <s> il faut mettre à jour la base de données véhicules <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   est-ce que des véhicules ont roulés ce week-end\n",
      "Bot     :   véhicules #vin# ont roulés ce week-end\n",
      "Réponse: <s> les véhicules #vin# ont roulés ce week-end <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   quel est le mode de transmission de ce véhicule\n",
      "Bot     :   \n",
      "Réponse: <s> #transmission#vin# <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   coût d'usage de ce véhicule\n",
      "Bot     :   tco de ce véhicule est de #tco_vehicule#\n",
      "Réponse: <s> le tco de ce véhicule est de #tco_vehicule# <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   je voudrais un véhicule\n",
      "Bot     :   véhicule plus proche est #position#\n",
      "Réponse: <s> ton véhicule plus proche est #position# <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   je veux bien mes contrats\n",
      "Bot     :   préciser votre demande\n",
      "Réponse: <s> pouvez-vous préciser votre demande <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   quelles sont les urgences\n",
      "Bot     :   urgences sont #priorité#\n",
      "Réponse: <s> vos urgences sont #priorité# <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   dernier passage en atelier\n",
      "Bot     :   \n",
      "Réponse: <s> #date_last_entretien# <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   quelle est la marque des pneus\n",
      "Bot     :   marque des pneus est #brand_tyre#\n",
      "Réponse: <s> la marque des pneus est #brand_tyre# <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   bonjour madame\n",
      "Bot     :   \n",
      "Réponse: <s> bonjour madame #lastname# <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   est ce que j'ai des problèmes de frein\n",
      "Bot     :   \n",
      "Réponse: <s> #oui/non# <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   merci beaucoup\n",
      "Bot     :   rien\n",
      "Réponse: <s> de rien <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   bonjour\n",
      "Bot     :   \n",
      "Réponse: <s> bonjour <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   je veux comparer l usage des véhicules pour comparer d'utilisation du parc\n",
      "Bot     :   votre dashboard\n",
      "Réponse: <s> consultez votre dashboard <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   bonjour\n",
      "Bot     :   \n",
      "Réponse: <s> bonjour <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   combien de voitures\n",
      "Bot     :   y a #nb_véhicules#\n",
      "Réponse: <s> il y a #nb_véhicules# <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   je souhaite avoir des données de maintenance\n",
      "Bot     :   \n",
      "Réponse: <s> oui <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   j'ai besoin de renseignements\n",
      "Bot     :   suis là pour vous renseigner\n",
      "Réponse: <s> je suis là pour vous renseigner <\\s>  ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   bonjour monsieur\n",
      "Bot     :   \n",
      "Réponse: <s> j'en #nb_véhicules# prends note plus voici pros procédure <\\s>  ACCURACY 0.0\n",
      "Test on 300 sentences in train set with accuracy 0.002210437710437718\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly(test = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 11, 6, 14, 15], [2, 11, 12, 13, 14, 15, 16, 9, 17, 18, 19, 3]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize new model\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:1344: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "Time: 4.851210355758667\n",
      "Running session\n",
      "Loading parameters for the Chatbot\n",
      "INFO:tensorflow:Restoring parameters from checkpoints_70_1/chatbot-50000\n",
      "1m 29s (- 20m 59s) (50400 6%) 1.2606\n",
      "3m 29s (- 17m 28s) (51000 16%) 0.2252\n",
      "5m 29s (- 15m 5s) (51600 26%) 0.0745\n",
      "7m 25s (- 12m 50s) (52200 36%) 0.0494\n",
      "9m 33s (- 10m 55s) (52800 46%) 0.0415\n",
      "11m 53s (- 9m 5s) (53400 56%) 0.0375\n",
      "13m 54s (- 6m 57s) (54000 66%) 0.0331\n",
      "15m 53s (- 4m 50s) (54600 76%) 0.0338\n",
      "17m 53s (- 2m 45s) (55200 86%) 0.0302\n",
      "19m 55s (- 0m 41s) (55800 96%) 0.0308\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(6000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
