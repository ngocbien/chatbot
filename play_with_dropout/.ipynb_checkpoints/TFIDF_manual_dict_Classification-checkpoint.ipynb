{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'anwser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-f8b85329bced>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1264\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m         \u001b[0mconvos_sujet_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1266\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'convos_sujet_' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-f8b85329bced>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1272\u001b[0m         \u001b[0mdict_sujet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_of_all_score_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvos_sujet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mKEY_LIST_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0mdict_hors\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdict_of_all_score_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvos_hors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKEY_LIST_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m         \u001b[0mcalcul_precision_recall_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m         \u001b[0mcalcul_precision_recall_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-f8b85329bced>\u001b[0m in \u001b[0;36mcalcul_precision_recall_\u001b[0;34m(train)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0msujet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_classif_sujet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_classif_hors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0manswer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_with_each_subjet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msujet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0manwser\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0mgood_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvos_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'anwser' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "les symboles particulières comme ? ! et . sont supprimé dans la question.\n",
    "Il faut peut être returner une réponse spécifique si il rencontre plus 1 mot qu'il existe pas dans le corpus\n",
    "Nous suprimmons également:\n",
    "  1. Mot qui contient une seule lettre(qui sont suivante des erreurs)\n",
    "  2. Une fonction unique pour nettoyage tous les données dans train-test et chat\n",
    "Nous allons traiter tous les mots clés suivant :\n",
    "km, vitesse, carburant, huile, position, batterie, pression_pneu. Il reste trajet et vin\n",
    "  \n",
    "\"\"\"\n",
    "#import sys\n",
    "#!{sys.executable} -m pip uninstall gtts\n",
    "\n",
    "#from gtts import gTTS\n",
    "#from playsound import playsound\n",
    "#import speech_recognition\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = stopwords.words('french')\n",
    "from nltk.stem import *\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"french\", ignore_stopwords = False)\n",
    "import csv\n",
    "import re\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from dateparser.search import search_dates\n",
    "import pandas as pd\n",
    "\n",
    "def date_time_():\n",
    "    \n",
    "    DICT_NUMERO = {'ce':1, 'cette':1, 'un':1, 'une':1, 'deux':2, 'trois':3,\\\n",
    "                   'quatre':4, 'cinq':5, 'six':6, 'sept':7,\\\n",
    "              'huit':8, 'neuf':9, 'dix':10, 'onze':11, 'douze':12, 'treize':13,'quartoze':14,\\\n",
    "               'quinze':15, 'seize':16, 'dix-sept':17,'dix sept':17, 'dix huit':18, \\\n",
    "               'dix-huit':18, 'dix-neuf':19, 'vingt':20, 'ving et un':21, 'trente':30, 'quarante':40,\\\n",
    "                  'quarante cinq':45, 'soixante':60}\n",
    "    DICT_TEMPS = {'heure':1, 'matin':4, 'après-midi':2,  'journée':24,  'jour':24, \\\n",
    "              'mois':30*24, 'semaine':7*24, \\\n",
    "              'an':24*365, 'année':24*365, 'minute': 1/60}\n",
    "    DICT_COMPLET_TEMPS = {}\n",
    "    for temps in DICT_TEMPS:\n",
    "        for numéro in DICT_NUMERO:\n",
    "            key1 = numéro + ' '+temps\n",
    "            key2 = str(DICT_NUMERO[numéro]) + ' ' +temps\n",
    "            value = DICT_NUMERO[numéro]*DICT_TEMPS[temps]\n",
    "            DICT_COMPLET_TEMPS[key1] = value\n",
    "            DICT_COMPLET_TEMPS[key2] = value\n",
    "    DICT_FOR_SPECIAL_CASE = {'aujourd\\'hui':8, 'hébdomadaire':7*24, 'annuel': 365*24, \\\n",
    "                           'hier': 24, 'avant-hier': 48, 'annuelle': 365*24 , 'actuellement':1/2,\\\n",
    "                            'maintenant':1/2}\n",
    "    DICT_COMPLET_TEMPS['#cas_particulier#'] = DICT_FOR_SPECIAL_CASE\n",
    "    DICT_COMPLET_TEMPS['avant hier'] = 72\n",
    "    DICT_COMPLET_TEMPS['semaine dernière'] = 24*7\n",
    "    return DICT_COMPLET_TEMPS\n",
    "\n",
    "def construct_list_city():\n",
    "    #import csv\n",
    "    liste_ville =[]\n",
    "    with open('villes_france.csv') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            liste_ville.append(row[2])\n",
    "        for ville in liste_ville:\n",
    "            if len(ville) <4:\n",
    "                liste_ville.remove(ville)\n",
    "    return liste_ville\n",
    "\n",
    "def _find_right_time(question, Dict):\n",
    "    \n",
    "    list_ = ['?', '.', ' ', '\\n', '!']\n",
    "    for symbol in list_:\n",
    "        question = question.lower().strip(symbol)\n",
    "    list_word = question.split()\n",
    "    word_ = None\n",
    "    list_ = []\n",
    "    if len(list_word) < 2:\n",
    "        return None, None \n",
    "    for word in list_word:\n",
    "        if word_ is not None:\n",
    "            list_.append(str(word_)+' '+str(word))  \n",
    "        word_ = word\n",
    "    for key in Dict:\n",
    "        for word in  list_:\n",
    "            if key == word:\n",
    "                return Dict[key], key\n",
    "    for word in Dict['#cas_particulier#']:\n",
    "        for word2 in question.split():\n",
    "            if word2 == word:\n",
    "                return Dict['#cas_particulier#'][word], word       \n",
    "    return None, None\n",
    "\n",
    "\n",
    "def _find_right_geography(question, Dict):\n",
    "    \"\"\"\n",
    "    Nous cherchons une ville, un département dans le dictionnaire pour retourner soit\n",
    "    ce nom de ce lieu, soit ses coordonnées correspondance. Le retour de ce donnée dépend \n",
    "    de quel façon nous allons traiter avec cette information.\n",
    "    \n",
    "    \"\"\"\n",
    "    list_ = ['?', '.', '\\n', '!', ',']\n",
    "    for symbol in list_:\n",
    "        question = question.replace(symbol, '') \n",
    "    list_geography = []\n",
    "    for word in question.split():\n",
    "        if word.lower() !=word:\n",
    "            word1 = word.lower()\n",
    "            if word1 in Dict:\n",
    "                list_geography.append(word)\n",
    "    if len(list_geography) >0:\n",
    "        return list_geography\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def list_variable():\n",
    "    \"\"\"\n",
    "    list_var is to manually complete \"\"\"\n",
    "    list_var = []\n",
    "    if len(list_var) >0:\n",
    "        return list_var\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def _normalized_table():\n",
    "    \"\"\"\n",
    "    return a data frame with new name\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('fleet_donnees.csv', sep = ';')\n",
    "    variable_names = list_variable()\n",
    "    if variable_names ==None:\n",
    "        return df\n",
    "    else:\n",
    "        name = list(df)\n",
    "        dict_name = {name[i]: variable_names[i] for i in range(len(name))}\n",
    "        df = df.rename(index= str, columns = dict_name)\n",
    "        return df\n",
    "\n",
    "def find_right_time_from_table(time, df):\n",
    "    \"\"\"\n",
    "    given time found from a question, match it with the time given in table\n",
    "    This depend on format of time in table.\n",
    "    \n",
    "    \"\"\"\n",
    "    return None\n",
    "    \n",
    "    \n",
    "def clearing_word(word):\n",
    "    word = re.sub('\\x8e', 'é', word)\n",
    "    word = re.sub('\\x88', 'à', word)\n",
    "    word = re.sub('\\x9d', 'ù', word)\n",
    "    word = re.sub('\\x8f', 'è', word)\n",
    "    word = re.sub('\\x9e', 'û', word)\n",
    "    word = re.sub('\\x90', 'ê', word)\n",
    "    word = re.sub('\\x99', 'ô', word)\n",
    "    word = re.sub('\\x94', 'î', word)\n",
    "   # word = re.sub('\\x8f', 'è', word)\n",
    "    word = re.sub('\\x8d', 'ç', word)\n",
    "    word = re.sub('õ', '', word)\n",
    "    word = re.sub('Ê', '', word)\n",
    "    word = re.sub('[?,.,!, \\,,  %]', '', word)\n",
    "    if word == 'û' or word == 'v' or word == 'é':\n",
    "        word = ''\n",
    "    if word ==\"2017êles\":\n",
    "        word = \"2017\"\n",
    "    if \"ênox\" in word:\n",
    "        word =\"nox\"\n",
    "    return word\n",
    "\n",
    "\n",
    "def clear_line(pharse, stop_word):\n",
    "    \"\"\"\n",
    "    Arg: string\n",
    "    Return: string\n",
    "    \"\"\"\n",
    "    dict_manuel = dict_manuelle()\n",
    "    pharse_ =[]\n",
    "    for words in pharse.strip().strip('?').strip('.').strip('!').lower().split(' '):\n",
    "        for word in words.split('-'):\n",
    "            for word_ in word.split('\\''):\n",
    "                word_ = clearing_word(word_)\n",
    "                word_ = stemmer.stem(word_)\n",
    "        if word_ not in stop_word and len(word_) >1:       \n",
    "            pharse_.append(word_)  \n",
    "        for i in range(len(pharse_)):\n",
    "            for line in dict_manuel:\n",
    "                if pharse_[i] in line:\n",
    "                    pharse_[i] = line[0]\n",
    "    return ' '.join(pharse_)\n",
    "\n",
    "def stemmer_line(line):\n",
    "    return ' '.join([stemmer.stem(word) for word in line.split()])\n",
    "\n",
    "def prepareData(PAIRS):\n",
    "    pairs_trains, pairs_tests = [], []\n",
    "   # PAIRS.extend(pairs1)\n",
    "    index_train = random.sample(range(len(PAIRS)), int(len(PAIRS)*0.80))\n",
    "    for i in range(len(PAIRS)):\n",
    "        if i in index_train:\n",
    "            pairs_trains.append(PAIRS[i])\n",
    "        else:\n",
    "            pairs_tests.append(PAIRS[i])\n",
    "    print(\"Read %s sentence pairs of training set\" % len(pairs_trains))\n",
    "    print(\"Read %s sentence pairs of test set\" % len(pairs_tests))\n",
    "    return pairs_trains, pairs_tests\n",
    "\n",
    "def get_all_convos(stopwords, file):\n",
    "    \n",
    "    convos = []\n",
    "    questions_to_print = []\n",
    "    liste_file = [file]\n",
    "    list_of_word = []\n",
    "    for file in liste_file:\n",
    "        with open(file) as f:\n",
    "            i=0\n",
    "            for line in f:\n",
    "                if i%2==0:\n",
    "                    question = str(line)\n",
    "                    if '++++' in question:\n",
    "                         question = question[8:]\n",
    "                    question_ = question.strip().strip('!').strip('?').strip('.')\n",
    "                    questions_to_print.append(question_)\n",
    "                    question = clear_line(question, stopwords)\n",
    "                else:\n",
    "                    answer = str(line)\n",
    "                    if '++++' in answer:\n",
    "                        answer = answer[8:].strip()\n",
    "                    convos.append([question, answer])\n",
    "                i+=1\n",
    "        f.close()\n",
    "    \n",
    "    return convos, questions_to_print\n",
    "\n",
    "\n",
    "def get_questions_for_classification():\n",
    "    \n",
    "    file1 = 'trains_sujet.txt'\n",
    "    file2 = 'trains_hors_sujet.txt'\n",
    "    liste_file = [file1, file2]\n",
    "    index = 0\n",
    "    for file in liste_file:\n",
    "        questions = []\n",
    "        with open(file) as f:\n",
    "            i = 0 \n",
    "            for line in f:\n",
    "                if i%2 == 0:\n",
    "                    question = str(line).strip().strip('?').strip('.').strip('!')\n",
    "                    if '++++' in question:\n",
    "                         question = question[8:]\n",
    "                    questions.append(question)\n",
    "                i += 1\n",
    "        if index == 0:\n",
    "            questions_sujet = questions\n",
    "            index += 1\n",
    "        else:\n",
    "            questions_hors = questions\n",
    "        f.close()\n",
    "    return questions_sujet, questions_hors\n",
    "\n",
    "\n",
    "def get_all_questions_to_print(file):\n",
    "    \n",
    "    convos = []\n",
    "    liste_file = [file]\n",
    "    list_of_word = []\n",
    "    for file in liste_file:\n",
    "        with open(file) as f:\n",
    "            i=0\n",
    "            for line in f:\n",
    "                if i%2==0:\n",
    "                    question = str(line)\n",
    "                    if '++++' in question:\n",
    "                         question = question[8:]\n",
    "                    question = question.strip()\n",
    "                    convos.append(question)\n",
    "                i+=1\n",
    "        f.close()\n",
    "        indexes = []\n",
    "        index = 0\n",
    "    for question in convos:\n",
    "        question = clear_line(question, STOPWORDS)\n",
    "        if len(question) !=0:\n",
    "                indexes.append(index)\n",
    "        index +=1\n",
    "    return [convos[i] for i in indexes]\n",
    "\n",
    "def get_list_words(convos):\n",
    "    list_words =[]\n",
    "    for pair in convos:\n",
    "        for word in pair[0].split():\n",
    "            if word not in list_words:\n",
    "                list_words.append(word)\n",
    "    print('There are {} words in corpus:'.format(len(list_words)))\n",
    "    return list_words\n",
    "                \n",
    "\n",
    "def simulation_pairs():\n",
    "    \n",
    "    DIRECT_VARIABLE = ['vitesse', 'batterie', 'position', 'km']\n",
    "    BORDE = {'MAX': ['plus grand', 'plus grande', 'plus grands', \n",
    "         'plus grandes',\n",
    "         'plus vite', 'max', 'maximum', 'maximal', 'maximaux', 'maximale',\n",
    "        'plus haut', 'plus haute', 'plus hautes', 'plus hauts',  \n",
    "        'plus élevé', 'plus élevée', 'plus élevés', 'plus élevées'], \n",
    "         'MIN':['moins grand', 'moins grande', 'moins grands','moins grandes',\n",
    "        'plus petit', 'plus petite', 'plus petits', 'plus petites','plus faible', 'plus faibles', \n",
    "         'min', 'minimal', 'minimale', 'minimales', 'minimaux','moins vite', \n",
    "         'moins élevé', 'moins élevée', 'moins élevés', 'moins élevées'],\n",
    "        'MOYENNE': ['moyenne', 'moyen', 'moyennement']\n",
    "        }\n",
    "    COMPLEX_ANALYSIS = ['problème', 'problèmes', 'erreurs', 'erreur', 'danger']\n",
    "    PAIRS = []\n",
    "    question_for_simulation = ['quels véhicules ont', 'quel véhicule', 'quelle voiture', 'quelles voitures']\n",
    "    reponse_for_simulation = 'véhicule'\n",
    "    for borde in BORDE:\n",
    "        for word in BORDE[borde]:\n",
    "            for direct_variable in DIRECT_VARIABLE:\n",
    "                for question_f_s in question_for_simulation:\n",
    "                    if direct_variable !='position':\n",
    "                        question= question_f_s+' '+direct_variable + ' '+ word\n",
    "                        key0 = '#id#'\n",
    "                        key1 = '#'+direct_variable+'#'\n",
    "                        key2 = '#'+borde +'#'\n",
    "                        reponse = reponse_for_simulation +' '+key0+ ' '+ key1+ ' '+ key2\n",
    "                        PAIRS.append([question,reponse])\n",
    "\n",
    "    question_for_simulation = ['', 'quel véhicule a', 'quelle voiture a', 'quelles voitures ont', 'il y a']\n",
    "    reponse_for_simulation = 'véhicule' \n",
    "    for direct_variable in DIRECT_VARIABLE:\n",
    "        for complex_analysis in COMPLEX_ANALYSIS:\n",
    "            for question_f_s in question_for_simulation:\n",
    "                #if direct_variable !='position':\n",
    "                      question= question_f_s+' '+complex_analysis + ' '+ direct_variable\n",
    "                      key0 = '#id#'\n",
    "                      key1 = '#'+direct_variable+'#'\n",
    "                      key2 = '#'+ complex_analysis +'#'\n",
    "                      reponse = reponse_for_simulation +' '+key0+ ' '+ key2 +' '+ key1\n",
    "                      PAIRS.append([question,reponse])\n",
    "    return PAIRS\n",
    "\n",
    "def clear_pairs_trains(pairs_trains):\n",
    "    questions = []\n",
    "    index = []\n",
    "    for i in range(len(pairs_trains)):\n",
    "        if  pairs_trains[i][0] not in questions:\n",
    "            index.append(i)\n",
    "            questions.append(pairs_trains[i][0])\n",
    "    return [pairs_trains[i] for i in index]\n",
    "\n",
    "def tf_idf(word, doc, méthode):\n",
    "    tf, df = 0, 0\n",
    "    len_doc = len(doc.split())\n",
    "    value_doc = 1/math.sqrt(len_doc)\n",
    "    value_doc = math.sqrt(value_doc)\n",
    "    if méthode !='Lucene':\n",
    "        value_doc = 1\n",
    "    if word in KEY_LIST:\n",
    "        value_word = 10*value_doc\n",
    "    else:\n",
    "        value_word = 1*value_doc\n",
    "    if word in str(doc):\n",
    "        tf = value_word\n",
    "    for doc_ex in QUESTION_TO_TRAINS:\n",
    "        if word in str(doc_ex):\n",
    "            df+=1\n",
    "    if méthode  == 'normal':\n",
    "        if df>0:\n",
    "            return tf*math.log(len(QUESTION_TO_TRAINS)/(df), 10)\n",
    "        else:\n",
    "            return 0\n",
    "    if méthode == 'probabiliste':\n",
    "        if df>0:\n",
    "            return tf*math.log((len(QUESTION_TO_TRAINS)-df)/(df), 10)\n",
    "        else:\n",
    "            return 0\n",
    "    if méthode == 'lissé':\n",
    "        if df>0:\n",
    "            return tf*(1+math.log(len(QUESTION_TO_TRAINS)/df, 10))\n",
    "        else:\n",
    "            return tf\n",
    "    if méthode == 'probabiliste_lissé':\n",
    "        if df>0:\n",
    "            return tf*(1+math.log((len(QUESTION_TO_TRAINS)-df)/(df), 10))\n",
    "        else:\n",
    "            return tf\n",
    "\n",
    "def dict_doc_score(doc, méthode = 'normal'): \n",
    "    \"\"\"\n",
    "    We return score of all one words and all two consequent words\"\"\"\n",
    "\n",
    "    list_word_ = split_words(doc)    \n",
    "    return {word: tf_idf(word, doc, méthode) for word in list_word_}\n",
    "    \n",
    "def dict_doc_score_for_classif(doc, sujet): \n",
    "    \"\"\"\n",
    "    We return score of all one words and all two consequent words\"\"\"\n",
    "\n",
    "    list_word_ = split_words(doc)    \n",
    "    return {word: tf_idf_for_classif(word, doc, sujet) for word in list_word_}\n",
    "   \n",
    "    \n",
    "def score_by_new_doc(new_doc, doc, DICT, méthode='normal'):\n",
    "    \n",
    "    list_word_in_doc = split_words(new_doc)\n",
    "    if méthode != 'Lucene':\n",
    "        DICT_of_methode = DICT[méthode]\n",
    "        score = 0\n",
    "        for word in list_word_in_doc:\n",
    "            if word in DICT_of_methode[doc]:\n",
    "                 score += DICT_of_methode[doc][word]\n",
    "        return score\n",
    "    else:\n",
    "        DICT_of_methode = DICT[méthode]\n",
    "        score = 0\n",
    "        for word in list_word_in_doc:\n",
    "            if word in DICT_of_methode[doc]:\n",
    "                 score += DICT_of_methode[doc][word]\n",
    "        coord = 1.5*len([word for word in new_doc if word in doc])\n",
    "        return  coord*score\n",
    "    \n",
    "def find_right_index(new_doc,DICT, méthode = 'normal'):\n",
    "    \n",
    "    index=0\n",
    "    biggest_score = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[0],DICT, méthode)\n",
    "    for i in range(len(QUESTION_TO_TRAINS)):\n",
    "        boolean1 = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[i], DICT, méthode) >biggest_score\n",
    "        boolean2 = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[i], DICT, méthode) == biggest_score\n",
    "        boolean3 = len(QUESTION_TO_TRAINS[index]) >len(QUESTION_TO_TRAINS[i])\n",
    "        if boolean1 or (boolean2 and boolean3):\n",
    "            biggest_score = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[i],DICT, méthode)\n",
    "            index = i\n",
    "    précision, rappel = precision_recall(new_doc, QUESTION_TO_TRAINS[index])\n",
    "    #if biggest_score ==0 or précision <0.2 or rappel<0.2:\n",
    "     #   for question in QUESTION_TO_TRAINS:\n",
    "      #      if '_return_' in question:\n",
    "       #         try:\n",
    "        #            index = QUESTION_TO_TRAINS.index(question)\n",
    "         #       except ValueError:\n",
    "          #          index = -1\n",
    "    return index\n",
    "\n",
    "def split_words(doc):\n",
    "    \n",
    "    list1 = doc.split()\n",
    "    list2 = []\n",
    "    for i in range(len(list1)-1):\n",
    "        word = list1[i]+ ' '+list1[i+1]\n",
    "        list2.append(word)\n",
    "    for word in list1:\n",
    "        list2.append(word)\n",
    "    return list2\n",
    "        \n",
    "        \n",
    "def get_key_list(pairs_trains):\n",
    "    \n",
    "    dict_ = dict_manuelle()\n",
    "    KEY_LIST = []\n",
    "    KEY_LIST_ = []\n",
    "    for pair in pairs_trains:\n",
    "        for word in pair[1].split():\n",
    "            if '#' in word:\n",
    "                word = re.sub('#', '', word)\n",
    "                if word not in KEY_LIST:\n",
    "                    KEY_LIST.append(word)\n",
    "    for key in KEY_LIST:\n",
    "        key = stemmer.stem(key)\n",
    "        if key not in KEY_LIST_ and '_' not in key:\n",
    "            KEY_LIST_.append(key)\n",
    "    KEY_RETURN = []\n",
    "    for key in KEY_LIST_:\n",
    "        boolean = False\n",
    "        for list_ in dict_:\n",
    "            if key in list_:\n",
    "                KEY_RETURN.append(list_[0])\n",
    "                boolean = True\n",
    "                break\n",
    "        if not boolean:\n",
    "            KEY_RETURN.append(key)\n",
    "    #for list_ in dict_:\n",
    "       # if list_[0] not in KEY_RETURN:\n",
    "        #    KEY_RETURN.append(list_[0])       \n",
    "    return KEY_RETURN\n",
    "        \n",
    "\n",
    "def find_right_index(new_doc,DICT, méthode = 'normal'):\n",
    "    \n",
    "    index=0\n",
    "    biggest_score = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[0],DICT, méthode)\n",
    "    for i in range(len(QUESTION_TO_TRAINS)):\n",
    "        boolean1 = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[i], DICT, méthode) >biggest_score\n",
    "        boolean2 = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[i], DICT, méthode) == biggest_score\n",
    "        boolean3 = len(QUESTION_TO_TRAINS[index]) >len(QUESTION_TO_TRAINS[i])\n",
    "        if boolean1 or (boolean2 and boolean3):\n",
    "            biggest_score = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[i],DICT, méthode)\n",
    "            index = i\n",
    "    précision, rappel = precision_recall(new_doc, QUESTION_TO_TRAINS[index])\n",
    "    #if biggest_score ==0 or précision <0.2 or rappel<0.2:\n",
    "     #   for question in QUESTION_TO_TRAINS:\n",
    "      #      if '_return_' in question:\n",
    "       #         try:\n",
    "        #            index = QUESTION_TO_TRAINS.index(question)\n",
    "         #       except ValueError:\n",
    "          #          index = -1\n",
    "    return index\n",
    "\n",
    "def reformule_question_if_need(new_question, good_question):\n",
    "    \n",
    "    if 'to_return' in good_question:\n",
    "        return True\n",
    "    score1 = score_by_new_doc(new_question, good_question, DICT)\n",
    "    score2 = 0\n",
    "    Dict_of_methode = DICT['normal']\n",
    "    for word in Dict_of_methode[good_question]:\n",
    "        score2 += Dict_of_methode[good_question][word]\n",
    "    if score1/score2 > 0.6:\n",
    "        return  True\n",
    "    else:\n",
    "        return  False\n",
    "\n",
    "\n",
    "def test(DICT, méthode, train =False):\n",
    "    \n",
    "    if not train:\n",
    "        index_to_print = random.sample(range(len(pairs_tests)), 20)\n",
    "        #loss_total = 0\n",
    "        for i in range(len(pairs_tests)):\n",
    "            index = find_right_index(pairs_tests[i][0], DICT, méthode)\n",
    "            #loss = _evaluate_by_right_word(pairs_trains[index][1], pairs_tests[i][1])\n",
    "            #loss_total +=loss\n",
    "            if i in index_to_print:\n",
    "                print(pairs_tests[i])\n",
    "                print(pairs_trains[index][1])\n",
    "        print('-'*80)\n",
    "       # print('ACCURACY=', 1-loss_total/len(pairs_tests))\n",
    "    if  train:\n",
    "        #loss_total = 0\n",
    "        #index_to_print = random.sample(range(len(pairs_trains)), 20)  \n",
    "        list_of_bad_prediction = []\n",
    "        i0 = 0\n",
    "        for i in range(len(pairs_trains)):\n",
    "            index = find_right_index(pairs_trains[i][0], DICT, méthode)\n",
    "            #loss = _evaluate_by_right_word(pairs_trains[index][1], pairs_trains[i][1])\n",
    "            #loss_total +=loss\n",
    "            if index != i :\n",
    "                i0 +=1\n",
    "                print(pairs_trains[i])\n",
    "                print(pairs_trains[index][1])\n",
    "        print('-'*80)\n",
    "        #print('ACCURACY=', 1-loss_total/len(pairs_trains))\n",
    "        print('Il y a {} erreurs d\\'indexes parmis {} prédictions'.format(i0, len(pairs_trains)))\n",
    "\n",
    "        \n",
    "def test_without_print(DICT, méthode, train =False):\n",
    "    \n",
    "    if not train:\n",
    "        loss_total = 0\n",
    "        for i in range(len(pairs_tests)):\n",
    "            index = find_right_index(pairs_tests[i][0], DICT, méthode)\n",
    "            loss = _evaluate_by_right_word(pairs_trains[index][1], pairs_tests[i][1])\n",
    "            loss_total +=loss\n",
    "        print('-'*80)\n",
    "        print('ACCURACY=', 1-loss_total/len(pairs_tests))\n",
    "    if  train:\n",
    "        loss_total = 0\n",
    "        index_to_print = random.sample(range(len(pairs_trains)), 20)   \n",
    "        for i in range(len(pairs_trains)):\n",
    "            index = find_right_index(pairs_trains[i][0], DICT, méthode)\n",
    "            loss = _evaluate_by_right_word(pairs_trains[index][1], pairs_trains[i][1])\n",
    "            loss_total +=loss\n",
    "        print('-'*80)\n",
    "        print('ACCURACY=', 1-loss_total/len(pairs_trains))\n",
    "\n",
    "def change_subjet_of_question(question):\n",
    "    dict_ = {'ton':'mon', 'ta':'ma', 'votre':'mon', 'tes':'mes', 'mon':'ton', \\\n",
    "            'ma':'ta', 'mes':'tes', 'tu': 'je', 'moi':'toi', 'je':'tu', 'toi':'moi',\\\n",
    "            'vous':'je'}\n",
    "    question_ = []\n",
    "    for word in question.lower().split():\n",
    "        if word in dict_:\n",
    "            word = dict_[word]\n",
    "        question_.append(word)\n",
    "    return ' '.join(question_)\n",
    "        \n",
    "def chat(méthode='normal'):\n",
    "    \n",
    "    print('Bonjour, C\\'est le bot d\\'Avicen, pose tes questions, s\\'il te plaît!')\n",
    "    path = 'processed/chat_tfidf.txt'\n",
    "    f =  open(path, 'a+') \n",
    "    while True:\n",
    "            line = str(input('Vous: '))\n",
    "            list_city = _find_right_geography(line, CITY_LIST)\n",
    "            line = line.lower().strip().strip('?').strip('.')\n",
    "            time, time_word = _find_right_time(line, COMPLET_DICT_TIME)\n",
    "            if time_word is not None:\n",
    "                line = line.replace(time_word, '')\n",
    "            if list_city is not None:\n",
    "                for city in list_city:\n",
    "                    line = line.replace(city, '')\n",
    "            LINE = clear_line(line, STOPWORDS)\n",
    "            unknown_word =0\n",
    "            for word in LINE.split():\n",
    "                if word not in LIST_OF_WORDS:\n",
    "                    unknown_word += 1\n",
    "            #if unknown_word > 1:\n",
    "             #   print('Désolé, je ne comprends pas ta question, peux tu la reformuler s\\'il te plaît?')\n",
    "              #  continue\n",
    "            if len(line) !=0:\n",
    "                index= find_right_index(LINE, DICT, méthode)\n",
    "                good_question = QUESTION_TO_TRAINS[index]\n",
    "                if not reformule_question_if_need(LINE, good_question):\n",
    "                    get_answer = str(input('Tu veux demander: {}?  |'.format(questions_to_print[index])))\n",
    "                    if 'non' in get_answer.lower():\n",
    "                        print('Peux tu reformuler ta question s\\'il te plaît?')\n",
    "                        continue\n",
    "                if time == None and list_city == None:\n",
    "                     print('bot: ', pairs_trains[index][1])\n",
    "                elif list_city ==None:\n",
    "                    print('Bot: {}, {}'.format(time_word, pairs_trains[index][1]))\n",
    "                elif time == None:\n",
    "                    cities = ' '.join(list_city)\n",
    "                    print('Bot: À {}, {}'.format(cities, pairs_trains[index][1]))\n",
    "                else:\n",
    "                    cities = ' '.join(list_city)\n",
    "                    print('Bot: À {}, {}, {}'.format(cities, time_word, pairs_trains[index][1]))\n",
    "                f.write('VOUS ++++ '+line+'\\n')\n",
    "                f.write('BOT ++++ '+pairs_trains[index][1]+'\\n')\n",
    "            \n",
    "            else:\n",
    "                f.close()\n",
    "                break \n",
    "\n",
    "def precision_recall(lstcomp, lstref):\n",
    "    \n",
    "    card_intersec = 0.0 # force à utiliser la division non entière\n",
    "    for t in set(lstcomp) :\n",
    "        card_intersec += min(lstref.count(t), lstcomp.count(t))\n",
    "    if len(lstcomp)==0:\n",
    "        precision =1\n",
    "    else:\n",
    "        precision = card_intersec/len(lstcomp)\n",
    "    if len(lstref)==0:\n",
    "        rappel = 1\n",
    "    else:\n",
    "        rappel = card_intersec/len(lstref)\n",
    "    return (precision, rappel)\n",
    "\n",
    "\n",
    "def calcul_precision_recall_(train = False):\n",
    "    \n",
    "    if not train:\n",
    "        total_precision, total_recall = 0, 0\n",
    "        for i in range(len(convos_test)):\n",
    "            question = convos_test[i][0]\n",
    "            sujet = classification(question, dict_classif_sujet, dict_classif_hors)\n",
    "            answer, index, _ = chat_with_each_subjet(question, sujet)\n",
    "            if anwser == None:\n",
    "                answer = ''\n",
    "            good_answer = convos_test[i][1]\n",
    "            precision, recall = precision_recall\\\n",
    "            (answer, good_answer)\n",
    "            total_precision  += precision\n",
    "            total_recall     += recall\n",
    "        print('-'*80)\n",
    "        total_precision = total_precision/len(convos_test)\n",
    "        total_recall = total_recall/len(convos_test)      \n",
    "        F = 2*total_precision*total_recall/(total_precision+total_recall)\n",
    "        print('PRECISION = {:.5f},  RECALL = {:.5f}, F_MESURE = {:.3f} '\\\n",
    "              .format(total_precision, total_recall,F))\n",
    "    if  train:       \n",
    "        total_precision, total_recall = 0, 0\n",
    "        for i in range(len(convos_sujet)):\n",
    "            question = convos_sujet[i][0]\n",
    "            sujet = classification(question, dict_classif_sujet, dict_classif_hors)\n",
    "            answer, index, _ = chat_with_each_subjet(question, sujet)\n",
    "            if answer == None:\n",
    "                answer = ''\n",
    "            good_answer = convos_sujet[i][1]\n",
    "            precision, recall = precision_recall\\\n",
    "            (answer, good_answer)\n",
    "            total_precision  += precision\n",
    "            total_recall     += recall\n",
    "        for i in range(len(convos_hors)):\n",
    "            question = convos_hors[i][0]\n",
    "            sujet = classification(question, dict_classif_sujet, dict_classif_hors)\n",
    "            answer, index, _ = chat_with_each_subjet(question, sujet)\n",
    "            if answer == None:\n",
    "                answer = ''\n",
    "            good_answer = convos_hors[i][1]\n",
    "            precision, recall = precision_recall\\\n",
    "            (answer, good_answer)\n",
    "            total_precision  += precision\n",
    "            total_recall     += recall\n",
    "        print('-'*80)\n",
    "        len_total = len(convos_sujet)+ len(convos_hors)\n",
    "        total_precision = total_precision/len_total\n",
    "        total_recall = total_recall/len_total     \n",
    "        F = 2*total_precision*total_recall/(total_precision+total_recall)\n",
    "        print('PRECISION = {:.5f},  RECALL = {:.5f}, F_MESURE = {:.3f} '\\\n",
    "              .format(total_precision, total_recall,F))\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "def dict_of_all_score(METHODE):\n",
    "    \"\"\"\n",
    "    return score of all word in all doc\"\"\"\n",
    "    DICT = {}\n",
    "    for méthode in METHODE:\n",
    "        dict_for_this_method ={}\n",
    "        for doc in QUESTION_TO_TRAINS:\n",
    "            dict_for_this_method[doc]=dict_doc_score(doc, méthode)\n",
    "        DICT[méthode] = dict_for_this_method\n",
    "    return DICT\n",
    " \n",
    "    \n",
    "def chatting_with_corpus():\n",
    "\n",
    "    path = 'processed/chat_tfidf.txt'\n",
    "    i = 0\n",
    "    questions = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            if i%2 ==0:\n",
    "                line = line[9:]\n",
    "                line = line.strip()\n",
    "                questions.append(line)\n",
    "            i +=1\n",
    "    f.close()\n",
    "    good_index = []\n",
    "    questions_ = []\n",
    "    index = 0\n",
    "    for question in questions:\n",
    "        question = clear_line(question, STOPWORDS)\n",
    "        if question not in questions_:\n",
    "            questions_.append(question)\n",
    "            good_index.append(index)\n",
    "        index += 1\n",
    "    questions_clean = [questions[i] for i in good_index]\n",
    "    for line in questions_clean:\n",
    "            print('Humaine: ', line)\n",
    "            time, time_word = _find_right_time(line, COMPLET_DICT_TIME)\n",
    "            list_city = _find_right_geography(line, CITY_LIST)\n",
    "            if time_word is not None:\n",
    "                line = line.replace(time_word, '')\n",
    "            if list_city is not None:\n",
    "                for city in list_city:\n",
    "                    line = line.replace(city, '')\n",
    "            LINE = clear_line(line, STOPWORDS)\n",
    "            unknown_word =0\n",
    "            for word in LINE.split():\n",
    "                if word not in LIST_OF_WORDS:\n",
    "                    unknown_word += 1\n",
    "            if unknown_word > 1:\n",
    "                print('Désolé, je ne comprends pas ta question, peux tu la reformuler s\\'il te plaît?')\n",
    "                print()\n",
    "                continue\n",
    "            if len(line) !=0:\n",
    "                index= find_right_index(LINE, DICT, méthode)\n",
    "                if time == None and list_city == None:\n",
    "                     print('Bot: ', pairs_trains[index][1])\n",
    "                elif list_city ==None:\n",
    "                    print('{}, {}'.format(time_word, pairs_trains[index][1]))\n",
    "                elif time == None:\n",
    "                    cities = ' '.join(list_city)\n",
    "                    print('À {}, {}'.format(cities, pairs_trains[index][1]))\n",
    "                else:\n",
    "                    cities = ' '.join(list_city)\n",
    "                    print('À {}, {}, {}'.format(cities, time_word, pairs_trains[index][1]))\n",
    "            print()\n",
    "               \n",
    "def dict_manuelle():\n",
    "    \"\"\"\n",
    "    return la liste des listes des synonymes\"\"\"\n",
    "    list_ = []\n",
    "    dict_ = {}\n",
    "    dict_['voiture'] = ['voiture', 'véhicule']\n",
    "    dict_['km'] = ['km', 'kilomètrage', 'kilométrage', 'distance', 'kilomètre']\n",
    "    dict_['essence'] = ['essence', 'carburant', 'énergie']\n",
    "    dict_['roule'] = ['roule', 'roulent', 'marche', 'marcher', 'circule', 'circulent', 'circulation']\n",
    "    dict_['bien'] = ['bien', 'bonne', 'good', 'excellent', 'parfait', 'beau', 'ok']\n",
    "    dict_['min']  = ['min', 'minimum', 'minimal']\n",
    "    dict_['pneu'] = ['pneumatique', 'pneu', 'pneus']\n",
    "    dict_['pouquoi'] = ['cause', 'pourquoi', 'raison', 'motif']\n",
    "    dict_['stupid'] = ['stupid', 'con', 'idiot', 'bête', 'imbécile']\n",
    "    dict_['connaître'] = ['connaître', 'connaitre', 'savoir', 'comprendre',\\\n",
    "                          'connaisance', 'connais', 'connaîs', 'sais', 'savez']\n",
    "    dict_['problème']  = ['problème', 'difficulté', 'danger', 'ennui', 'dangers']\n",
    "    dict_['erreur'] = ['faute', 'erreur']\n",
    "    dict_['arrêt'] = ['arrêt', 'arrêter', 'stopper', 'immobilisé', 'immobiliser', 'immobile', 'paralisé']\n",
    "    dict_['disponible'] = ['disponible', 'disponibilité', 'libre']\n",
    "    dict_['abimer'] = ['abîmer', 'hors service', 'cassé', 'endommager', 'abîmé']\n",
    "    dict_['boitier'] = ['boitier', 'boîtier', 'boîte']\n",
    "    dict_['frein'] = ['frein', 'freinage', 'freiner']\n",
    "    dict_['parcouru'] = ['parcouru', 'parcourus', 'parcourir']\n",
    "    dict_['peux'] = ['peux', 'pouvoir', 'pourrais']\n",
    "    dict_['veux'] = ['veux', 'vouloir', 'veut', 'voulais', 'voudrais', 'souhaiter', 'souhaite']\n",
    "    dict_['fait'] = ['fait', 'fais', 'faire', 'faites']\n",
    "    dict_['fort'] = ['fort', 'puissant', 'robuste', 'solide']\n",
    "    dict_['grand'] = ['grand', 'gross', 'élevé', 'haut', 'haute']\n",
    "    dict_['mal'] = ['mal', 'mauvais', 'souci']\n",
    "    dict_['changer'] = ['modifier', 'modification', 'changer', 'changement']\n",
    "    dict_['avoir'] = ['as', 'obtenir', 'avoir', 'posséder', 'disposer']\n",
    "    dict_['peur']  = ['peur', 'craint']\n",
    "    dict_['placer'] = ['placer','installer']\n",
    "    dict_['nombre'] = ['nombre', 'combien', 'quantité']\n",
    "    dict_['aider']  = ['aider', 'aide', 'soutien', 'soutenir']\n",
    "    dict_['question'] = ['question', 'demande']\n",
    "    dict_['information'] = ['information', 'infos', 'renseignement', 'indictation',\\\n",
    "                            'informer', 'renseigner','indiquer']\n",
    "    dict_['usé'] = ['usé', 'usure', 'vieux', 'vieille', 'fatigué']\n",
    "    dict_['réduire']  = ['réduire', 'réduction', 'abaisser', 'diminuer', 'diminution']\n",
    "    dict_['présent']  = ['présent', 'maitenant', 'actuel', 'actuellement']\n",
    "    dict_['suivre']   = ['suivre', 'observer', 'surveiller', 'poursuivre']\n",
    "    dict_['aller']    = ['aller', 'vas', 'vais', 'va']\n",
    "    dict_['échanger'] = ['échanger', 'estimer', 'échangement', 'estimation',\\\n",
    "                         'évaluer', 'calculer','évaluation'\\\n",
    "                        , 'mesurer']\n",
    "    dict_['taux']    = ['taux', 'pourcentage']\n",
    "    dict_['ampoule'] = ['ampoule', 'feux', 'feu']\n",
    "    for key in dict_:\n",
    "        l = []\n",
    "        for word in dict_[key]:\n",
    "            l.append(stemmer.stem(word))\n",
    "        list_.append(l)\n",
    "    return list_\n",
    "\n",
    "    \n",
    "                \n",
    "def chatting_with_test_corpus():\n",
    "    \n",
    "    path = 'test.txt'\n",
    "    questions = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "                line = line.strip()\n",
    "                questions.append(line)\n",
    "    f.close()\n",
    "    questions_clean = []\n",
    "    for question in questions:\n",
    "        if question not in questions_clean:\n",
    "            questions_clean.append(question)\n",
    "    for line in questions_clean:\n",
    "            line1 = line\n",
    "            time, time_word = _find_right_time(line, COMPLET_DICT_TIME)\n",
    "            list_city = _find_right_geography(line, CITY_LIST)\n",
    "            if time_word is not None:\n",
    "                line = line.replace(time_word, '')\n",
    "            if list_city is not None:\n",
    "                for city in list_city:\n",
    "                    line = line.replace(city, '')\n",
    "            LINE = clear_line(line, STOPWORDS)\n",
    "            unknown_word =0\n",
    "            print('Vous: ', line1)\n",
    "            for word in LINE.split():\n",
    "                if word not in LIST_OF_WORDS:\n",
    "                    unknown_word += 1\n",
    "            if unknown_word > 1:\n",
    "                print('Bot: Désolé, je ne comprends pas ta question, peux tu la reformuler s\\'il te plaît?')\n",
    "                print()\n",
    "                continue\n",
    "            if len(line) !=0:\n",
    "                index= find_right_index(LINE, DICT, méthode)\n",
    "                if time == None and list_city == None:\n",
    "                     print('Bot: ', pairs_trains[index][1])\n",
    "                elif list_city ==None:\n",
    "                    print('Bot: {}, {}'.format(time_word, pairs_trains[index][1]))\n",
    "                elif time == None:\n",
    "                    cities = ' '.join(list_city)\n",
    "                    print('Bot: À {}, {}'.format(cities, pairs_trains[index][1]))\n",
    "                else:\n",
    "                    cities = ' '.join(list_city)\n",
    "                    print('Bot: À {}, {}, {}'.format(cities, time_word, pairs_trains[index][1]))\n",
    "               \n",
    "                LINE = clear_line(line, STOPWORDS)   \n",
    "                index = find_right_index(LINE, DICT, METHODE[0])\n",
    "                #print('YOU: ', line)\n",
    "                #print('BOT: ', pairs_trains[index][1])\n",
    "                print()\n",
    "            \n",
    "\n",
    "def get_all_and_all_convos():\n",
    "    convos = []\n",
    "    file1 = 'convos27juin_test.txt'\n",
    "    file2 = 'convos27juin_train.txt'\n",
    "    files = [file1, file2]\n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "            i=0\n",
    "            for line in f:\n",
    "                if i%2==0:\n",
    "                    question = line.strip()\n",
    "                    if '++++' in question:\n",
    "                         question = question[9:]\n",
    "                else:\n",
    "                    answer = line.strip()\n",
    "                    if '++++' in answer:\n",
    "                        answer = answer[9:]\n",
    "                    convos.append([question, answer])\n",
    "                i+=1\n",
    "        f.close()\n",
    "    return convos\n",
    "\n",
    "\n",
    "def clear_all_convos(all_convos, name):\n",
    "    \"\"\"\n",
    "    Supprimer tous les couples où les questions sont les mêmes\"\"\"\n",
    "    index_of_convos = []\n",
    "    question = []\n",
    "    index =0\n",
    "    for pair in all_convos:\n",
    "        if pair[0] not in question:\n",
    "            index_of_convos.append(index)\n",
    "            question.append(pair[0])\n",
    "        index +=1\n",
    "    convos = [all_convos[index] for index in index_of_convos]\n",
    "    print('Il y a {} de couples de  {}'.format(len(convos), name))\n",
    "    return convos\n",
    "\n",
    "def save_convos_in_file(all_convos):\n",
    "    \n",
    "    index_of_train = random.sample(range(len(all_convos)), int(len(all_convos)*0.80))\n",
    "    with open('convos6juillet_train.txt', 'w') as f:\n",
    "        for index in index_of_train:\n",
    "            pair = all_convos[index]\n",
    "            f.write('YOU ++++ '+ pair[0]+'\\n')\n",
    "            f.write('BOT ++++ '+ pair[1]+'\\n')\n",
    "    f.close()\n",
    "    with open('convos6juillet_test.txt', 'w') as f:\n",
    "        for index in range(len(all_convos)):\n",
    "            if index not in index_of_train:\n",
    "                pair = all_convos[index]\n",
    "                f.write('YOU ++++ '+ pair[0]+'\\n')\n",
    "                f.write('BOT ++++ '+ pair[1]+'\\n')\n",
    "    f.close()\n",
    "    len_test = len(all_convos)- len(index_of_train)\n",
    "    print('save {} convos in train and {} convos in test'.format(len(index_of_train), len_test))\n",
    "    \n",
    "def test_to_find_error(dict):\n",
    "    \n",
    "    index_of_error_prediction = []\n",
    "    index_of_true_pair = []\n",
    "    i = 0\n",
    "    for pair in pairs_trains:\n",
    "        index = find_right_index(pair[0],dict,  'normal')\n",
    "        if index != i:\n",
    "            index_of_error_prediction.append(index)\n",
    "            index_of_true_pair.append(i)\n",
    "        i +=1\n",
    "    for i in range(len(index_of_error_prediction)):\n",
    "        index1 = index_of_error_prediction[i]\n",
    "        index2 = index_of_true_pair[i]\n",
    "        score1 = score_by_new_doc(pairs_trains[index1][0], pairs_trains[index2][0],dict, 'normal')\n",
    "        score2 = score_by_new_doc(pairs_trains[index2][0], pairs_trains[index2][0],dict, 'normal')\n",
    "        print('False return question--- {} ---with score {}'.format(pairs_trains[index1][0], score1))\n",
    "        print('True return question--- {} ---with score {}'.format(pairs_trains[index2][0], score2))\n",
    "\n",
    "def print_all_errors_on_test(dict):\n",
    "    for pair in pairs_tests:\n",
    "        question = clear_line(pair[0], STOPWORDS)\n",
    "        index = find_right_index(question, dict, 'normal')\n",
    "        print(pair)\n",
    "        print(pairs_trains[index])\n",
    "        print()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def mean_score(doc, dict_):\n",
    "    if len(doc) == 0:\n",
    "        return 0\n",
    "    total_score = 0\n",
    "    doc_ =  doc.lower().strip().strip('?').strip('.').strip('!').split()\n",
    "    for pharse in dict_:\n",
    "        score = 0\n",
    "        for word in doc_:\n",
    "            if word in dict_[pharse]:\n",
    "                score +=dict_[pharse][word]\n",
    "        total_score += score/len(doc_)\n",
    "    return total_score/len(dict_)\n",
    "\n",
    "def find_right_index_for_classif(q, questions,  dict_):\n",
    "\n",
    "    index=0\n",
    "    biggest_score = score_by_new_doc_(q, questions[0], dict_)\n",
    "    for i in range(len(questions)):\n",
    "        boolean1 = score_by_new_doc_(q, questions[i], dict_) >  biggest_score\n",
    "        boolean2 = score_by_new_doc_(q, questions[i], dict_) == biggest_score\n",
    "        boolean3 = len(questions[index]) >len(questions[i])\n",
    "        if boolean1 or (boolean2 and boolean3):\n",
    "            biggest_score = score_by_new_doc_(q, questions[i], dict_)\n",
    "            index = i\n",
    "    return index\n",
    "    \n",
    "    \n",
    "\n",
    "def classification(question, dict_sujet_, dict_hors_):\n",
    "    \n",
    "    Q1, Q2 = get_questions_for_classification()\n",
    "    index_sujet = find_right_index_for_classif(question, Q1, dict_sujet_)\n",
    "    index_hors  = find_right_index_for_classif(question, Q2, dict_hors_)\n",
    "    score_sujet = score_by_new_doc_(question, Q1[index_sujet], dict_sujet_)\n",
    "    score_hors  = score_by_new_doc_(question, Q2[index_hors], dict_hors_)\n",
    "    test = score_sujet > score_hors\n",
    "    précision_sujet, rappel_sujet = precision_recall(question, Q1[index_sujet])\n",
    "    précision_hors, rappel_hors = precision_recall(question, Q2[index_hors])\n",
    "    if test and précision_sujet >0.8 and rappel_sujet >0.8:\n",
    "        return True\n",
    "    elif not test and précision_hors >0.8 and rappel_hors >0.8:\n",
    "        return False\n",
    "    else:\n",
    "        if mean_score(question, dict_sujet_) > mean_score(question, dict_hors_):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    \n",
    "def test_classification_by_corpus(dict_sujet, dict_hors):\n",
    "    \n",
    "\n",
    "    path = 'processed/chat_tfidf.txt'\n",
    "    i = 0\n",
    "    questions = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            if i%2 ==0:\n",
    "                if '++++' in line:\n",
    "                    line = line[8:]\n",
    "                line = line.strip('+').strip()\n",
    "                questions.append(line)\n",
    "            i +=1\n",
    "    f.close()\n",
    "    total_value = 0\n",
    "    for question in questions:\n",
    "        value = classification(question, dict_sujet, dict_hors)\n",
    "        total_value +=value\n",
    "        print(question,'---------',value)\n",
    "    print('Le pourcentage des sujets sont {}'.format(total_value/len(questions)))\n",
    "\n",
    "    \n",
    "def question_processing(question):\n",
    "    question_ = question.strip().split()\n",
    "    if len(question_) == 1:\n",
    "        return question\n",
    "    else:\n",
    "        index = random.sample(range(len(question_)), len(question_)-1)\n",
    "    return ' '.join([question_[i] for i in sorted(index)])\n",
    "\n",
    "def test_classification_in_trains(dict_sujet, dict_hors):\n",
    "    \n",
    "\n",
    "    questions_sujet, questions_hors = get_questions_for_classification()\n",
    "    total_value = 0\n",
    "    for question in questions_sujet:\n",
    "        question = question_processing(question)\n",
    "        value = classification(question, dict_sujet, dict_hors)\n",
    "        if value == False:\n",
    "            total_value +=1\n",
    "            print(question,'  : est mal classée')\n",
    "    print('Le pourcentage des fautes sur sujets sont {}'.format(total_value/len(questions_sujet)))\n",
    "    print('-'*80)\n",
    "    total_value = 0\n",
    "    for question in questions_hors:\n",
    "        question = question_processing(question)\n",
    "        value = classification(question, dict_sujet, dict_hors)\n",
    "        if value == True:\n",
    "            total_value +=1\n",
    "            print(question,'  : est mal classée')\n",
    "    print('Le pourcentage des fautes hors sujets sont {}'.format(total_value/len(questions_hors)))\n",
    "\n",
    "def test_with_classification(dict_sujet, dict_hors):\n",
    "    \n",
    "    while True:\n",
    "        question = str(input('Question: '))\n",
    "        if len(question) <2:\n",
    "            break\n",
    "        classe = classification(question, dict_sujet, dict_hors)\n",
    "        if classe ==1:\n",
    "            print('Ta question est dans le sujet')\n",
    "        else:\n",
    "            print('Ta question est hors sujet')\n",
    "    \n",
    "def dict_of_all_score_(convos,KEY_LIST, sujet):\n",
    "    \"\"\"\n",
    "    return score of all word in all doc\"\"\"\n",
    "    DICT = {}\n",
    "    for doc_ in convos:\n",
    "        doc = doc_[0]\n",
    "        DICT[doc]=dict_doc_score_(doc,KEY_LIST, sujet)\n",
    "    return DICT \n",
    "\n",
    "def dict_of_all_score_for_classification():\n",
    "    \"\"\"\n",
    "    Return dict on sujet and dict hors sujet\n",
    "    These dicts are not use stemmer stem, to be distinguish with dict_sujet and dict_hors\n",
    "    which  are using stopwords and stemmer for theirs words\"\"\"\n",
    "    dict_classif_sujet, dict_classif_hors = {}, {}\n",
    "    questions_classif_sujet, questions_classif_hors = get_questions_for_classification()  \n",
    "    for doc in questions_classif_sujet:\n",
    "        dict_classif_sujet[doc]=dict_doc_score_for_classif(doc, True)\n",
    "    for doc in questions_classif_hors:\n",
    "        dict_classif_hors[doc] = dict_doc_score_for_classif(doc, False)\n",
    "    return dict_classif_sujet, dict_classif_hors \n",
    "\n",
    "\n",
    "def find_right_index_(new_doc, sujet = True):\n",
    "    \n",
    "    if sujet:\n",
    "        DICT = dict_sujet\n",
    "        convos = convos_sujet\n",
    "    else:\n",
    "        DICT = dict_hors\n",
    "        convos = convos_hors\n",
    "    index=0\n",
    "    biggest_score = score_by_new_doc_(new_doc, convos[0][0],DICT)\n",
    "    for i in range(len(convos)):\n",
    "        boolean1 = score_by_new_doc_(new_doc, convos[i][0], DICT) > biggest_score\n",
    "        boolean2 = score_by_new_doc_(new_doc, convos[i][0], DICT) == biggest_score\n",
    "        boolean3 = len(convos[index]) >len(convos[i])\n",
    "        if boolean1 or (boolean2 and boolean3):\n",
    "            biggest_score = score_by_new_doc_(new_doc, convos[i][0], DICT)\n",
    "            index = i\n",
    "    return index\n",
    "\n",
    "def tf_idf_(word, doc, KEY_LIST, sujet = True):\n",
    "    \n",
    "    if sujet:\n",
    "        convos = convos_sujet\n",
    "    else:\n",
    "        convos = convos_hors\n",
    "    \n",
    "    tf, df = 0, 0\n",
    "    words = split_words(doc)\n",
    "    len_doc = len(words)\n",
    "    value_doc = 1/math.sqrt(len_doc)\n",
    "    value_doc = math.sqrt(value_doc)\n",
    "    if word in KEY_LIST:\n",
    "        value_word = 10*value_doc\n",
    "    else:\n",
    "        value_word = 1*value_doc\n",
    "    if word in str(doc):\n",
    "        tf = value_word\n",
    "    for doc_ in convos:\n",
    "        if word in str(doc_[0]):\n",
    "            df+=1\n",
    "    if df>0:\n",
    "            return tf*math.log(len(convos)/(df), 10)\n",
    "    else:\n",
    "            return 0\n",
    "        \n",
    "def tf_idf_for_classif(word, doc, sujet = True):\n",
    "    \n",
    "    convos1, convos2 = get_questions_for_classification()\n",
    "    if sujet:\n",
    "        convos = convos1\n",
    "    else:\n",
    "        convos = convos2\n",
    "    \n",
    "    tf, df = 0, 0\n",
    "    if word in str(doc):\n",
    "        tf = 1\n",
    "    for doc_ in convos:\n",
    "        if word in str(doc_):\n",
    "            df+=1\n",
    "    if df>0:\n",
    "            return tf*math.log(len(convos)/(df), 10)\n",
    "    else:\n",
    "            return 0\n",
    "\n",
    "def chat_with_each_subjet(raw_question, sujet = True):\n",
    "    \n",
    "    if sujet:\n",
    "        DICT = dict_sujet\n",
    "        convos = convos_sujet\n",
    "    else:\n",
    "        DICT = dict_hors\n",
    "        convos = convos_hors\n",
    "    list_city = _find_right_geography(raw_question, CITY_LIST)\n",
    "    line = raw_question.lower().strip().strip('?').strip('.')\n",
    "    time, time_word = _find_right_time(line, COMPLET_DICT_TIME)\n",
    "    if time_word is not None:\n",
    "                line = line.replace(time_word, '')\n",
    "    if list_city is not None:\n",
    "                for city in list_city:\n",
    "                    line = line.replace(city, '')\n",
    "    LINE = clear_line(line, STOPWORDS)\n",
    "    unknown_word =0\n",
    "    for word in LINE.split():\n",
    "            if word not in LIST_OF_WORDS:\n",
    "                unknown_word += 1\n",
    "    if len(line) !=0:\n",
    "            index= find_right_index_(LINE, sujet)\n",
    "            good_question = convos[index][0]\n",
    "           # if not reformule_question_if_need(LINE, good_question):\n",
    "                   # get_answer = str(input('Tu veux demander: {}?  |'.format(questions_to_print[index])))\n",
    "                   # if 'non' in get_answer.lower():\n",
    "                    #    print('Peux tu reformuler ta question s\\'il te plaît?')\n",
    "                     #   continue\n",
    "            if time == None and list_city == None:\n",
    "                     answer= convos[index][1]\n",
    "            elif list_city ==None:\n",
    "                    answer = time_word + ' '+ convos[index][1]\n",
    "            elif time == None:\n",
    "                    cities = ' '.join(list_city)\n",
    "                    answer = 'À ' + cities +' '+ convos[index][1]\n",
    "            else:\n",
    "                    cities = ' '.join(list_city)\n",
    "                    answer = 'À ' + cities +' '+ time_word+ ' '+ convos[index][1]\n",
    "            return answer, index, line\n",
    "    else:\n",
    "        return None, None, line\n",
    "    \n",
    "\n",
    "def request_missing_infos(new_question, good_question, dict_):\n",
    "    \n",
    "    if 'to_return' in good_question:\n",
    "        return True\n",
    "    score1 = score_by_new_doc_(new_question, good_question, dict_)\n",
    "    score2 = 0\n",
    "    for word in dict_[good_question]:\n",
    "        score2 += dict_[good_question][word]\n",
    "    if score1/score2 > 0.6:\n",
    "        return  True\n",
    "    else:\n",
    "        return  False\n",
    "    \n",
    "def chat_(): \n",
    "    print('Bonjour, le bot d\\'Avicen à ton écoute')\n",
    "    path = 'processed/chat_tfidf.txt'\n",
    "    f =  open(path, 'a+') \n",
    "    while True:\n",
    "            raw_question = str(input('You: '))\n",
    "            f.write('YOU++++ '+raw_question + '\\n')\n",
    "            if len(raw_question) < 2:\n",
    "                break\n",
    "            sujet = classification(raw_question, dict_classif_sujet, dict_classif_hors)\n",
    "            answer, index, line = chat_with_each_subjet(raw_question, sujet)\n",
    "            if sujet:\n",
    "                boolean = request_missing_infos(line, convos_sujet[index][0], dict_sujet)\n",
    "                if not boolean:\n",
    "                    str_ = 'Tu veux demander: '+ questions_to_print[index] +'?'+'|'\n",
    "                    request_more = str(input(str_))\n",
    "                    if 'non' in request_more:\n",
    "                        print('Peux tu reformuler ta question, s\\'il te plaît?')\n",
    "                        continue\n",
    "                    else:\n",
    "                        print('Bot: ', answer)\n",
    "            else:\n",
    "                print(answer) \n",
    "                \n",
    "    \n",
    "def dict_doc_score_(doc, KEY_LIST, sujet): \n",
    "    \"\"\"\n",
    "    We return score of all one words and all two consequent words\"\"\"\n",
    "\n",
    "    list_word_ = split_words(doc)    \n",
    "    return {word: tf_idf_(word, doc, KEY_LIST, sujet) for word in list_word_}\n",
    "   \n",
    "\n",
    "def dict_doc_score_for_classif(doc, sujet): \n",
    "    \"\"\"\n",
    "    We return score of all one words and all two consequent words\"\"\"\n",
    "\n",
    "    list_word_ = split_words(doc)    \n",
    "    return {word: tf_idf_for_classif(word, doc, sujet) for word in list_word_}\n",
    "    \n",
    "def score_by_new_doc_(new_doc, doc, DICT):\n",
    "    \n",
    "    list_word_in_doc = split_words(new_doc)\n",
    "    score = 0\n",
    "    for word in list_word_in_doc:\n",
    "            if word in DICT[doc]:\n",
    "                 score += DICT[doc][word]\n",
    "    return score\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        convos_sujet_\n",
    "    except NameError:\n",
    "        convos_sujet, questions_to_print = get_all_convos(STOPWORDS,'trains_sujet.txt')\n",
    "        convos_hors, _  = get_all_convos(STOPWORDS, 'trains_hors_sujet.txt')\n",
    "        convos_test, _ = get_all_convos(STOPWORDS, 'tests_16juillet.txt')\n",
    "        dict_classif_sujet, dict_classif_hors = dict_of_all_score_for_classification()\n",
    "        KEY_LIST_  = get_key_list(convos_sujet)\n",
    "        dict_sujet = dict_of_all_score_(convos_sujet,KEY_LIST_, True)\n",
    "        dict_hors  = dict_of_all_score_(convos_hors, KEY_LIST_, False) \n",
    "        calcul_precision_recall_(False)\n",
    "        calcul_precision_recall_(True)\n",
    "        \n",
    "if __name__=='__main__':\n",
    "    try:\n",
    "        pairs_trains\n",
    "    except NameError :\n",
    "        pairs_trains, _ = get_all_convos(STOPWORDS, 'trains_sujet.txt')\n",
    "        pairs_tests, _ = get_all_convos(STOPWORDS, 'tests_16juillet.txt')\n",
    "        pairs_trains = clear_all_convos(pairs_trains, 'train')\n",
    "        pairs_tests = clear_all_convos(pairs_tests, 'test')\n",
    "        questions_to_print = get_all_questions_to_print('trains_16juillet.txt')\n",
    "        #pairs_trains.extend(pairs_tests)\n",
    "        LIST_OF_WORDS = get_list_words(pairs_trains)\n",
    "        KEY_LIST = get_key_list(pairs_trains)\n",
    "        QUESTION_TO_TRAINS = []\n",
    "        for pairs in pairs_trains:\n",
    "            QUESTION_TO_TRAINS.append(pairs[0])\n",
    "        METHODE = ['normal']\n",
    "        DICT = dict_of_all_score(METHODE)   \n",
    "        COMPLET_DICT_TIME = date_time_()\n",
    "        CITY_LIST = construct_list_city()\n",
    "        print('on train:')\n",
    "        for méthode in METHODE:\n",
    "            test_with_precision_recall(DICT, méthode, train = True)\n",
    "        print('On test:')\n",
    "        for méthode in METHODE:\n",
    "            test_with_precision_recall(DICT, méthode, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quelle est ton professionnelle   : est mal classée\n",
      "suis planté   : est mal classée\n",
      "je planté   : est mal classée\n",
      "peux m'aider   : est mal classée\n",
      "je bloqué   : est mal classée\n",
      "suis bloqué   : est mal classée\n",
      "je un rapport   : est mal classée\n",
      "je voudrais un   : est mal classée\n",
      "si je suis   : est mal classée\n",
      "si je pressé   : est mal classée\n",
      "je coincé   : est mal classée\n",
      "je suis   : est mal classée\n",
      "comment réagit le   : est mal classée\n",
      "comment le conducteur   : est mal classée\n",
      "je souhaiterais un benchmark   : est mal classée\n",
      "Le pourcentage des fautes sur sujets sont 0.015991471215351813\n",
      "--------------------------------------------------------------------------------\n",
      "quelles sont tes   : est mal classée\n",
      "pour les renseignements   : est mal classée\n",
      "j'ai besoin de   : est mal classée\n",
      "plus   : est mal classée\n",
      "Le pourcentage des fautes hors sujets sont 0.05063291139240506\n"
     ]
    }
   ],
   "source": [
    "test_classification_in_trains(dict_classif_sujet, dict_classif_hors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classification_in_trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, le bot d'Avicen à ton écoute\n",
      "You: hello\n",
      "bonjour\n",
      "You: voiture\n",
      "Tu veux demander: je demande une voiture?|oui\n",
      "Bot:  #ask_id# #position#\n",
      "You: combien\n",
      "Tu veux demander: nombre de voiture?|oui\n",
      "Bot:  il y a #nb_veh#\n",
      "You: allez les bleus\n",
      "Tu veux demander: je veux réduire les consommations?|non\n",
      "Peux tu reformuler ta question, s'il te plaît?\n",
      "You: allez \n",
      "ça va\n",
      "You: cool\n",
      "ça va\n",
      "You: combien de temps j'aurai avec toi\n",
      "Tu veux demander: combien de temps pour installer le boîtier?|non\n",
      "Peux tu reformuler ta question, s'il te plaît?\n",
      "You: bien\n",
      "ça va\n",
      "You: je suis content de toi\n",
      "Tu veux demander: je veux réduire les consommations?|non\n",
      "Peux tu reformuler ta question, s'il te plaît?\n",
      "You: t'es con\n",
      "pourquoi des mots méchants\n",
      "You: tes réponses ne sont pas correctes\n",
      "Tu veux demander: le pneu est-il correct?|non, t'es con\n",
      "Peux tu reformuler ta question, s'il te plaît?\n",
      "You: yes\n",
      "ça va\n",
      "You: oui\n",
      "ça va\n",
      "You: bon, je m'arrête là\n",
      "je suis là pour tes questions concernants tes voitures\n",
      "You: \n"
     ]
    }
   ],
   "source": [
    "chat_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938 79\n"
     ]
    }
   ],
   "source": [
    "q1, q2 = get_questions_for_classification()\n",
    "print(len(q1), len(q2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: voiture\n",
      "Ta question est hors sujet\n",
      "Question: véhicule\n",
      "Ta question est hors sujet\n",
      "Question: batterie\n",
      "Ta question est hors sujet\n",
      "Question: vitesse\n",
      "Ta question est hors sujet\n",
      "Question: \n"
     ]
    }
   ],
   "source": [
    "test_with_classification(dict_classif_sujet, dict_classif_hors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, C'est le bot d'Avicen, pose tes questions, s'il te plaît!\n",
      "Vous: salut\n",
      "bot:  au revoir\n",
      "Vous: combien\n",
      "bot:  il y a #nb_veh#\n",
      "Vous: voiture\n",
      "Tu veux demander: où est mon véhicule?  |oui\n",
      "bot:  ton véhicule est à #position#\n",
      "Vous: batterie\n",
      "bot:  véhicule #id# #problème# #batterie#\n",
      "Vous: vitesse\n",
      "Tu veux demander: il y a erreurs vitesse?  |non\n",
      "Peux tu reformuler ta question s'il te plaît?\n",
      "Vous: position\n",
      "Tu veux demander: il y a danger position?  |non\n",
      "Peux tu reformuler ta question s'il te plaît?\n",
      "Vous: peut on savoir la position de voiture\n",
      "Tu veux demander: quelle voiture a erreur position?  |non\n",
      "Peux tu reformuler ta question s'il te plaît?\n",
      "Vous: frein\n",
      "bot:  #ask_id# #problème# #frein#\n",
      "Vous: pneu\n",
      "bot:  #problème# #pneu#\n",
      "Vous: Est-ce qu'on a des problème de pneu\n",
      "bot:  #problème#\n",
      "Vous: où est \n",
      "Tu veux demander: quelles sont les voitures qui roulent?  |oui\n",
      "bot:  je suis un bot donc je suis dans la machine\n",
      "Vous: b\n",
      "Tu veux demander: tvs?  |\n",
      "bot:  co2 ou air\n",
      "Vous: \n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quel voitur roul', '#total_veh_movement#']\n"
     ]
    }
   ],
   "source": [
    "line = 'quelles sont les voitures qui roulent'\n",
    "line = clear_line(line, STOPWORDS)\n",
    "for pair in pairs_trains:\n",
    "    if line in pair[0]:\n",
    "        print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, C'est le bot d'Avicen, pose tes questions, s'il te plaît!\n",
      "Vous: salut\n",
      "bot:  au revoir\n",
      "Vous: bonjour\n",
      "Tu veux demander: bonjour madame?  |bonjour\n",
      "bot:  bonjour\n",
      "Vous: je veux une\n",
      "Tu veux demander: je voudrais une solution?  |oui\n",
      "bot:  je suis là pour t'aider\n",
      "Vous: qui\n",
      "Tu veux demander: tvs?  |non\n",
      "Peux tu reformuler ta question s'il te plaît?\n",
      "Vous: combien\n",
      "bot:  il y a #nb_veh#\n",
      "Vous: véhicule\n",
      "Tu veux demander: où est mon véhicule?  |oui\n",
      "bot:  ton véhicule est à #position#\n",
      "Vous: souhaiter\n",
      "Tu veux demander: je voudrais une solution?  |\n",
      "bot:  je suis là pour t'aider\n",
      "Vous: solution\n",
      "Tu veux demander: je voudrais une solution?  |\n",
      "bot:  je suis là pour t'aider\n",
      "Vous: entreprise\n",
      "Tu veux demander: où est situé ton entreprise?  |oui\n",
      "bot:  avicen se trouve à 92 cours lafayette 69003 lyon\n",
      "Vous: comment\n",
      "bot:  je m'appelle Emmet, je suis une création d'AVICEN\n",
      "Vous: appelles\n",
      "Tu veux demander: comment tu t'appelles?  |oui\n",
      "bot:  je m'appelle Emmet, je suis une création d'AVICEN\n",
      "Vous: je veux \n",
      "Tu veux demander: je voudrais une solution?  |non\n",
      "Peux tu reformuler ta question s'il te plaît?\n",
      "Vous: batterie\n",
      "bot:  véhicule #id# #problème# #batterie#\n",
      "Vous: con\n",
      "bot:  pourquoi des mots méchants\n",
      "Vous: stupid\n",
      "bot:  pourquoi des mots méchants\n",
      "Vous: tu es\n",
      "Tu veux demander: tvs?  |non\n",
      "Peux tu reformuler ta question s'il te plaît?\n",
      "Vous: coincé\n",
      "bot:  contactez-nous lien l'accès au est #brand_tyre#\n",
      "Vous: qui\n",
      "Tu veux demander: tvs?  |que\n",
      "bot:  co2 ou air\n",
      "Vous: question\n",
      "bot:  oui pose ta question\n",
      "Vous: demande\n",
      "bot:  oui pose ta question\n",
      "Vous: voudrais\n",
      "Tu veux demander: je voudrais une solution?  |combien de\n",
      "bot:  je suis là pour t'aider\n",
      "Vous: combien\n",
      "bot:  il y a #nb_veh#\n",
      "Vous: \n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quelles sont tes coordonnées professionnelles\n",
      "où est localisée la voiture\n",
      "y a t-il un risque de panne du moteur ou d'un organe de transmission\n",
      "j'ai prêté un véhicule\n",
      "est-ce que le moteur ne tourne plus\n",
      "quel nombre de place\n",
      "je veux une voiture\n",
      "je veux trouver un véhicule le plus proche\n",
      "je suis indécise\n",
      "quels véhicules ont batterie moins grand\n",
      "quel est le véhicule avoisinant\n",
      "je veux améliorer mon bilan carbone\n",
      "les véhicules sont-ils dans un état correct\n",
      "est-ce que les conditions climatiques sont propices à un déplacement\n",
      "quel véhicule km maximum\n",
      "apparement la batterie fonctionne mal\n",
      "quel est le niveau de dégradation des pneus\n",
      "je souhaiterais avoir un éclaircissement\n",
      "la tournée est-elle optimisée\n",
      "eco-conduite\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    question = random.choice(questions_to_print)\n",
    "    print(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
