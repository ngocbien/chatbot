{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 426 de couples de  train\n",
      "Il y a 151 de couples de  test\n",
      "There are 314 words in corpus:\n",
      "on train:\n",
      "--------------------------------------------------------------------------------\n",
      "PRECISION = 0.99990,  RECALL = 0.99990, F_MESURE = 1.000 METHODE = normal\n",
      "On test:\n",
      "--------------------------------------------------------------------------------\n",
      "PRECISION = 0.88586,  RECALL = 0.85504, F_MESURE = 0.870 METHODE = normal\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "les symboles particulières comme ? ! et . sont supprimé dans la question.\n",
    "Il faut peut être returner une réponse spécifique si il rencontre plus 1 mot qu'il existe pas dans le corpus\n",
    "Nous suprimmons également:\n",
    "  1. Mot qui contient une seule lettre(qui sont suivante des erreurs)\n",
    "  2. Une fonction unique pour nettoyage tous les données dans train-test et chat\n",
    "Nous allons traiter tous les mots clés suivant :\n",
    "km, vitesse, carburant, huile, position, batterie, pression_pneu. Il reste trajet et vin\n",
    "  \n",
    "\"\"\"\n",
    "#import sys\n",
    "#!{sys.executable} -m pip uninstall gtts\n",
    "\n",
    "#from gtts import gTTS\n",
    "#from playsound import playsound\n",
    "#import speech_recognition\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = stopwords.words('french')\n",
    "from nltk.stem import *\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"french\", ignore_stopwords = False)\n",
    "\n",
    "import re\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from dateparser.search import search_dates\n",
    "import pandas as pd\n",
    "\n",
    "def clearing_word(word):\n",
    "    word = re.sub('\\x8e', 'é', word)\n",
    "    word = re.sub('\\x88', 'à', word)\n",
    "    word = re.sub('\\x9d', 'ù', word)\n",
    "    word = re.sub('\\x8f', 'è', word)\n",
    "    word = re.sub('\\x9e', 'û', word)\n",
    "    word = re.sub('\\x90', 'ê', word)\n",
    "    word = re.sub('\\x99', 'ô', word)\n",
    "    word = re.sub('\\x94', 'î', word)\n",
    "   # word = re.sub('\\x8f', 'è', word)\n",
    "    word = re.sub('\\x8d', 'ç', word)\n",
    "    word = re.sub('õ', '', word)\n",
    "    word = re.sub('Ê', '', word)\n",
    "    word = re.sub('[?,.,!, \\,,  %]', '', word)\n",
    "    if word == 'û' or word == 'v' or word == 'é':\n",
    "        word = ''\n",
    "    if word ==\"2017êles\":\n",
    "        word = \"2017\"\n",
    "    if \"ênox\" in word:\n",
    "        word =\"nox\"\n",
    "    return word\n",
    "\n",
    "def clear_line(pharse, stop_word):\n",
    "    \"\"\"\n",
    "    Arg: string\n",
    "    Return: string\n",
    "    \"\"\"\n",
    "    #clean_data = []\n",
    "    pharse_ =[]\n",
    "    for words in pharse.strip().strip('?').strip('.').strip('!').lower().split(' '):\n",
    "        for word in words.split('-'):\n",
    "            for word_ in word.split('\\''):\n",
    "                word_ = clearing_word(word_)\n",
    "                word_ = stemmer.stem(word_)\n",
    "        if word_ not in stop_word and len(word_) >1:       \n",
    "            pharse_.append(word_)        \n",
    "    return ' '.join(pharse_)\n",
    "\n",
    "def transformed_line(line, dicts):\n",
    "    \n",
    "    line_to_return = []\n",
    "    for word in line.split():\n",
    "        for Line in dicts:\n",
    "            if word in Line and word not in line_to_return:\n",
    "                line_to_return.append(Line[0])\n",
    "                break\n",
    "    return ' '.join(line_to_return), len(line.split())-len(line_to_return)\n",
    "\n",
    "def prepareData(PAIRS):\n",
    "    pairs_trains, pairs_tests = [], []\n",
    "   # PAIRS.extend(pairs1)\n",
    "    index_train = random.sample(range(len(PAIRS)), int(len(PAIRS)*0.80))\n",
    "    for i in range(len(PAIRS)):\n",
    "        if i in index_train:\n",
    "            pairs_trains.append(PAIRS[i])\n",
    "        else:\n",
    "            pairs_tests.append(PAIRS[i])\n",
    "    print(\"Read %s sentence pairs of training set\" % len(pairs_trains))\n",
    "    print(\"Read %s sentence pairs of test set\" % len(pairs_tests))\n",
    "    return pairs_trains, pairs_tests\n",
    "\n",
    "def get_all_convos(stopwords, file):\n",
    "    \n",
    "    convos = []\n",
    "    #file = 'convos27juin.txt'\n",
    "    #file1 = 'chatbot_tout_corpus.txt'\n",
    "    #file2 = 'chatbot_tout_corpus_13juin.txt'\n",
    "    #file3 = 'convos_120_nettoye.txt' # cette fichier viens d'etre ajouter\n",
    "    liste_file = [file]\n",
    "    list_of_word = []\n",
    "    for file in liste_file:\n",
    "        with open(file) as f:\n",
    "            i=0\n",
    "            for line in f:\n",
    "                if i%2==0:\n",
    "                    question = str(line)\n",
    "                    if '++++' in question:\n",
    "                         question = question[9:]\n",
    "                    question = clear_line(question, stopwords)\n",
    "                else:\n",
    "                    answer = str(line)\n",
    "                    if '++++' in answer:\n",
    "                        answer = answer[9:].strip()\n",
    "                    convos.append([question, answer])\n",
    "                i+=1\n",
    "        convos_to_return = []\n",
    "        for pair in convos:\n",
    "            if len(pair[0]) !=0:\n",
    "                convos_to_return.append(pair)\n",
    "        f.close()\n",
    "    return convos_to_return\n",
    "\n",
    "def get_list_words(convos):\n",
    "    list_words =[]\n",
    "    for pair in convos:\n",
    "        for word in pair[0].split():\n",
    "            if word not in list_words:\n",
    "                list_words.append(word)\n",
    "    print('There are {} words in corpus:'.format(len(list_words)))\n",
    "    return list_words\n",
    "                \n",
    "\n",
    "def simulation_pairs():\n",
    "    \n",
    "    DIRECT_VARIABLE = ['vitesse', 'batterie', 'position', 'km']\n",
    "    TIME = []\n",
    "    GEOGRAPHY = ['Lyon', 'hors lyon', 'paris', 'l\\'étranger','france' , 'hors la france']\n",
    "    BORDE = {'MAX': ['plus grand', 'plus grande', 'plus grands', \n",
    "         'plus grandes',\n",
    "         'plus vite', 'max', 'maximum', 'maximal', 'maximaux', 'maximale',\n",
    "        'plus haut', 'plus haute', 'plus hautes', 'plus hauts',  \n",
    "        'plus élevé', 'plus élevée', 'plus élevés', 'plus élevées'], \n",
    "         'MIN':['moins grand', 'moins grande', 'moins grands','moins grandes',\n",
    "        'plus petit', 'plus petite', 'plus petits', 'plus petites','plus faible', 'plus faibles', \n",
    "         'min', 'minimal', 'minimale', 'minimales', 'minimaux','moins vite', \n",
    "         'moins élevé', 'moins élevée', 'moins élevés', 'moins élevées'],\n",
    "        'MOYENNE': ['moyenne', 'moyen', 'moyennement']\n",
    "        }\n",
    "    COMPLEX_ANALYSIS = ['problème', 'problèmes', 'erreurs', 'erreur', 'danger']\n",
    "    PAIRS = []\n",
    "    question_for_simulation = ['quels véhicules ont', 'quel véhicule', 'quelle voiture', 'quelles voitures']\n",
    "    reponse_for_simulation = 'véhicule'\n",
    "    for borde in BORDE:\n",
    "        for word in BORDE[borde]:\n",
    "            for direct_variable in DIRECT_VARIABLE:\n",
    "                for question_f_s in question_for_simulation:\n",
    "                    if direct_variable !='position':\n",
    "                        question= question_f_s+' '+direct_variable + ' '+ word\n",
    "                        key0 = '#id#'\n",
    "                        key1 = '#'+direct_variable+'#'\n",
    "                        key2 = '#'+borde +'#'\n",
    "                        reponse = reponse_for_simulation +' '+key0+ ' '+ key1+ ' '+ key2\n",
    "                        PAIRS.append([question,reponse])\n",
    "\n",
    "    question_for_simulation = ['', 'quel véhicule a', 'quelle voiture a', 'quelles voitures ont', 'il y a']\n",
    "    reponse_for_simulation = 'véhicule' \n",
    "    for direct_variable in DIRECT_VARIABLE:\n",
    "        for complex_analysis in COMPLEX_ANALYSIS:\n",
    "            for question_f_s in question_for_simulation:\n",
    "                #if direct_variable !='position':\n",
    "                      question= question_f_s+' '+complex_analysis + ' '+ direct_variable\n",
    "                      key0 = '#id#'\n",
    "                      key1 = '#'+direct_variable+'#'\n",
    "                      key2 = '#'+ complex_analysis +'#'\n",
    "                      reponse = reponse_for_simulation +' '+key0+ ' '+ key2 +' '+ key1\n",
    "                      PAIRS.append([question,reponse])\n",
    "    return PAIRS\n",
    "\n",
    "def clear_pairs_trains(pairs_trains):\n",
    "    questions = []\n",
    "    index = []\n",
    "    for i in range(len(pairs_trains)):\n",
    "        if  pairs_trains[i][0] not in questions:\n",
    "            index.append(i)\n",
    "            questions.append(pairs_trains[i][0])\n",
    "    return [pairs_trains[i] for i in index]\n",
    "\n",
    "def tf_idf(word, doc, méthode):\n",
    "    tf, df = 0, 0\n",
    "    if word in str(doc):\n",
    "        tf = 1\n",
    "    for doc_ex in QUESTION_TO_TRAINS:\n",
    "        if word in str(doc_ex):\n",
    "            df+=1\n",
    "    if méthode  == 'normal':\n",
    "        if df>0:\n",
    "            return tf*math.log(len(QUESTION_TO_TRAINS)/(df), 10)\n",
    "        else:\n",
    "            return 0\n",
    "    if méthode == 'probabiliste':\n",
    "        if df>0:\n",
    "            return tf*math.log((len(QUESTION_TO_TRAINS)-df)/(df), 10)\n",
    "        else:\n",
    "            return 0\n",
    "    if méthode == 'lissé':\n",
    "        if df>0:\n",
    "            return tf*(1+math.log(len(QUESTION_TO_TRAINS)/df, 10))\n",
    "        else:\n",
    "            return tf\n",
    "    if méthode == 'probabiliste_lissé':\n",
    "        if df>0:\n",
    "            return tf*(1+math.log((len(QUESTION_TO_TRAINS)-df)/(df), 10))\n",
    "        else:\n",
    "            return tf\n",
    "    \n",
    "    \n",
    "def dict_doc_score(doc, méthode = 'normal'):   \n",
    "    return {word: tf_idf(word, doc, méthode) for word in doc.split()}\n",
    "   \n",
    "    \n",
    "def score_by_new_doc(new_doc, doc, DICT, méthode):\n",
    "    \n",
    "    if méthode != 'Lucene':\n",
    "        DICT_of_methode = DICT[méthode]\n",
    "        score = 0\n",
    "        for word in new_doc.split():\n",
    "            if word in DICT_of_methode[doc]:\n",
    "                 score += DICT_of_methode[doc][word]\n",
    "        return score\n",
    "    else:\n",
    "        DICT_of_methode = DICT[méthode]\n",
    "        score = 0\n",
    "        for word in new_doc.split():\n",
    "            if word in DICT_of_methode[doc]:\n",
    "                 score += DICT_of_methode[doc][word]\n",
    "        coord = 1.5*len([word for word in new_doc if word in doc])\n",
    "        return  coord*score\n",
    "    \n",
    "def get_key_list(pairs_trains):\n",
    "    \n",
    "    KEY_LIST = []\n",
    "    for pair in pairs_trains:\n",
    "        for word in pair[1].split():\n",
    "            if '#' in word and word not in KEY_LIST:\n",
    "                word = re.sub('#', '', word)\n",
    "                KEY_LIST.append(word)\n",
    "    return KEY_LIST\n",
    "        \n",
    "\n",
    "def find_right_index(new_doc,DICT, méthode = 'normal'):\n",
    "    \n",
    "    index=0\n",
    "    biggest_score = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[0],DICT, méthode)\n",
    "    for i in range(len(QUESTION_TO_TRAINS)):\n",
    "        boolean1 = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[i], DICT, méthode) >biggest_score\n",
    "        boolean2 = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[i], DICT, méthode) == biggest_score\n",
    "        boolean3 = len(QUESTION_TO_TRAINS[index]) >len(QUESTION_TO_TRAINS[i])\n",
    "        if boolean1 or (boolean2 and boolean3):\n",
    "            biggest_score = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[i],DICT, méthode)\n",
    "            index = i\n",
    "    précision, rappel = precision_recall(new_doc, QUESTION_TO_TRAINS[index])\n",
    "    if biggest_score ==0 or précision <0.3 or rappel<0.3:\n",
    "        index = len(QUESTION_TO_TRAINS)-1\n",
    "    return index\n",
    "\n",
    "def test(DICT, méthode, train =False):\n",
    "    \n",
    "    if not train:\n",
    "        index_to_print = random.sample(range(len(pairs_tests)), 20)\n",
    "        #loss_total = 0\n",
    "        for i in range(len(pairs_tests)):\n",
    "            index = find_right_index(pairs_tests[i][0], DICT, méthode)\n",
    "            #loss = _evaluate_by_right_word(pairs_trains[index][1], pairs_tests[i][1])\n",
    "            #loss_total +=loss\n",
    "            if i in index_to_print:\n",
    "                print(pairs_tests[i])\n",
    "                print(pairs_trains[index][1])\n",
    "        print('-'*80)\n",
    "       # print('ACCURACY=', 1-loss_total/len(pairs_tests))\n",
    "    if  train:\n",
    "        #loss_total = 0\n",
    "        #index_to_print = random.sample(range(len(pairs_trains)), 20)  \n",
    "        list_of_bad_prediction = []\n",
    "        i0 = 0\n",
    "        for i in range(len(pairs_trains)):\n",
    "            index = find_right_index(pairs_trains[i][0], DICT, méthode)\n",
    "            #loss = _evaluate_by_right_word(pairs_trains[index][1], pairs_trains[i][1])\n",
    "            #loss_total +=loss\n",
    "            if index != i :\n",
    "                i0 +=1\n",
    "                print(pairs_trains[i])\n",
    "                print(pairs_trains[index][1])\n",
    "        print('-'*80)\n",
    "        #print('ACCURACY=', 1-loss_total/len(pairs_trains))\n",
    "        print('Il y a {} erreurs d\\'indexes parmis {} prédictions'.format(i0, len(pairs_trains)))\n",
    "\n",
    "def test_without_print(DICT, méthode, train =False):\n",
    "    \n",
    "    if not train:\n",
    "        loss_total = 0\n",
    "        for i in range(len(pairs_tests)):\n",
    "            index = find_right_index(pairs_tests[i][0], DICT, méthode)\n",
    "            loss = _evaluate_by_right_word(pairs_trains[index][1], pairs_tests[i][1])\n",
    "            loss_total +=loss\n",
    "        print('-'*80)\n",
    "        print('ACCURACY=', 1-loss_total/len(pairs_tests))\n",
    "    if  train:\n",
    "        loss_total = 0\n",
    "        index_to_print = random.sample(range(len(pairs_trains)), 20)   \n",
    "        for i in range(len(pairs_trains)):\n",
    "            index = find_right_index(pairs_trains[i][0], DICT, méthode)\n",
    "            loss = _evaluate_by_right_word(pairs_trains[index][1], pairs_trains[i][1])\n",
    "            loss_total +=loss\n",
    "        print('-'*80)\n",
    "        print('ACCURACY=', 1-loss_total/len(pairs_trains))\n",
    "        \n",
    "        \n",
    "def chat(méthode):\n",
    "    \n",
    "    print('Bonjour, C\\'est le bot d\\'Avicen, pose tes questions, s\\'il te plaît!')\n",
    "    path = 'processed/chat_tfidf.txt'\n",
    "    f =  open(path, 'a+') \n",
    "    while True:\n",
    "            line = str(input('Vous: '))\n",
    "            LINE = clear_line(line, STOPWORDS)\n",
    "            LINE, unknown_word = transformed_line(LINE, DICTIONNARY)\n",
    "            print('Ligne tranformée: ',LINE)\n",
    "            if unknown_word > 0:\n",
    "                print('Désolé, je ne comprends pas ta question, peux tu la reformuler s\\'il te plaît?')\n",
    "                continue\n",
    "            if len(line) !=0:\n",
    "                index= find_right_index(LINE, DICT, méthode)\n",
    "                print('bot: ', pairs_trains[index][1])\n",
    "                f.write('VOUS ++++ '+line+'\\n')\n",
    "                f.write('BOT ++++ '+pairs_trains[index][1]+'\\n')\n",
    "            \n",
    "            else:\n",
    "                f.close()\n",
    "                break \n",
    "\n",
    "def precision_recall(lstcomp, lstref):\n",
    "    \n",
    "    card_intersec = 0.0 # force à utiliser la division non entière\n",
    "    for t in set(lstcomp) :\n",
    "        card_intersec += min(lstref.count(t), lstcomp.count(t))\n",
    "    if len(lstcomp)==0:\n",
    "        precision =1\n",
    "    else:\n",
    "        precision = card_intersec/len(lstcomp)\n",
    "    if len(lstref)==0:\n",
    "        rappel = 1\n",
    "    else:\n",
    "        rappel = card_intersec/len(lstref)\n",
    "    return (precision, rappel)\n",
    "\n",
    "\n",
    "def test_with_precision_recall(DICT, méthode, train = False):\n",
    "    \n",
    "    if not train:\n",
    "        total_precision, total_recall = 0, 0\n",
    "        for i in range(len(pairs_tests)):\n",
    "            index = find_right_index(pairs_tests[i][0], DICT, méthode)\n",
    "            precision, recall = precision_recall\\\n",
    "            (pairs_tests[i][1], pairs_trains[index][1])\n",
    "            total_precision  += precision\n",
    "            total_recall     += recall\n",
    "        print('-'*80)\n",
    "        total_precision = total_precision/len(pairs_tests)\n",
    "        total_recall = total_recall/len(pairs_tests)      \n",
    "        F = 2*total_precision*total_recall/(total_precision+total_recall)\n",
    "        print('PRECISION = {:.5f},  RECALL = {:.5f}, F_MESURE = {:.3f} METHODE = {}'\\\n",
    "              .format(total_precision, total_recall,F, méthode))\n",
    "    if  train:\n",
    "        total_precision, total_recall = 0, 0\n",
    "        for i in range(len(pairs_trains)):          \n",
    "            index = find_right_index(pairs_trains[i][0], DICT, méthode)\n",
    "            precision, recall = precision_recall\\\n",
    "            (pairs_trains[i][1], pairs_trains[index][1])\n",
    "            total_precision  += precision\n",
    "            total_recall     += recall\n",
    "        print('-'*80)\n",
    "        total_precision = total_precision/len(pairs_trains)\n",
    "        total_recall = total_recall/len(pairs_trains)\n",
    "        F = 2*total_precision*total_recall/(total_precision+total_recall)\n",
    "        print('PRECISION = {:.5f},  RECALL = {:.5f}, F_MESURE = {:.3f} METHODE = {}'\\\n",
    "              .format(total_precision, total_recall, F, méthode))\n",
    "        \n",
    "            \n",
    "def dict_of_all_score(METHODE):\n",
    "    \"\"\"\n",
    "    return score of all word in all doc\"\"\"\n",
    "    DICT = {}\n",
    "    for méthode in METHODE:\n",
    "        dict_for_this_method ={}\n",
    "        for doc in QUESTION_TO_TRAINS:\n",
    "            dict_for_this_method[doc]=dict_doc_score(doc, méthode)\n",
    "        DICT[méthode] = dict_for_this_method\n",
    "    return DICT\n",
    "        \n",
    "def chatting_with_corpus():\n",
    "\n",
    "\n",
    "    path = 'processed/chat_tfidf.txt'\n",
    "    i = 0\n",
    "    questions = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            if i%2 ==0:\n",
    "                line = line[9:]\n",
    "                line = line.lower().strip()\n",
    "                questions.append(line)\n",
    "            i +=1\n",
    "    f.close()\n",
    "    questions_clean = []\n",
    "    for question in questions:\n",
    "        if question not in questions_clean:\n",
    "            questions_clean.append(question)\n",
    "    for line in questions_clean:\n",
    "                LINE = clear_line(line, STOPWORDS)   \n",
    "                index = find_right_index(LINE, DICT, METHODE[0])\n",
    "                print('YOU: ', line)\n",
    "                print('BOT: ', pairs_trains[index][1])\n",
    "                print()\n",
    "        \n",
    "def chatting_with_test_corpus():\n",
    "    \n",
    "    path = 'test.txt'\n",
    "    questions = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "                line = line.lower().strip()\n",
    "                questions.append(line)\n",
    "    f.close()\n",
    "    questions_clean = []\n",
    "    for question in questions:\n",
    "        if question not in questions_clean:\n",
    "            questions_clean.append(question)\n",
    "    for line in questions_clean:\n",
    "                LINE = clear_line(line, STOPWORDS)   \n",
    "                index = find_right_index(LINE, DICT, METHODE[0])\n",
    "                print('YOU: ', line)\n",
    "                print('BOT: ', pairs_trains[index][1])\n",
    "                print()\n",
    "            \n",
    "\n",
    "def get_all_and_all_convos():\n",
    "    convos = []\n",
    "    file1 = 'convos27juin_test.txt'\n",
    "    file2 = 'convos27juin_train.txt'\n",
    "    files = [file1, file2]\n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "            i=0\n",
    "            for line in f:\n",
    "                if i%2==0:\n",
    "                    question = line.strip()\n",
    "                    if '++++' in question:\n",
    "                         question = question[9:]\n",
    "                else:\n",
    "                    answer = line.strip()\n",
    "                    if '++++' in answer:\n",
    "                        answer = answer[9:]\n",
    "                    convos.append([question, answer])\n",
    "                i+=1\n",
    "        f.close()\n",
    "    return convos\n",
    "\n",
    "def clear_all_convos(all_convos, name):\n",
    "    \"\"\"\n",
    "    Supprimer tous les couples où les questions sont les mêmes\"\"\"\n",
    "    index_of_convos = []\n",
    "    question = []\n",
    "    index =0\n",
    "    for pair in all_convos:\n",
    "        if pair[0] not in question:\n",
    "            index_of_convos.append(index)\n",
    "            question.append(pair[0])\n",
    "        index +=1\n",
    "    convos = [all_convos[index] for index in index_of_convos]\n",
    "    print('Il y a {} de couples de  {}'.format(len(convos), name))\n",
    "    #print('nous avons sumpprimer {} couples parmis {} couples'.format(len(all_convos)-len(index_of_convos),index))\n",
    "    return convos\n",
    "\n",
    "def save_convos_in_file(all_convos):\n",
    "    \n",
    "    index_of_train = random.sample(range(len(all_convos)), int(len(all_convos)*0.80))\n",
    "    with open('convos6juillet_train.txt', 'w') as f:\n",
    "        for index in index_of_train:\n",
    "            pair = all_convos[index]\n",
    "            f.write('YOU ++++ '+ pair[0]+'\\n')\n",
    "            f.write('BOT ++++ '+ pair[1]+'\\n')\n",
    "    f.close()\n",
    "    with open('convos6juillet_test.txt', 'w') as f:\n",
    "        for index in range(len(all_convos)):\n",
    "            if index not in index_of_train:\n",
    "                pair = all_convos[index]\n",
    "                f.write('YOU ++++ '+ pair[0]+'\\n')\n",
    "                f.write('BOT ++++ '+ pair[1]+'\\n')\n",
    "    f.close()\n",
    "    len_test = len(all_convos)- len(index_of_train)\n",
    "    print('save {} convos in train and {} convos in test'.format(len(index_of_train), len_test))\n",
    "    \n",
    "def test_to_find_error(dict):\n",
    "    \n",
    "    index_of_error_prediction = []\n",
    "    index_of_true_pair = []\n",
    "    i = 0\n",
    "    for pair in pairs_trains:\n",
    "        index = find_right_index(pair[0],dict,  'normal')\n",
    "        if index != i:\n",
    "            index_of_error_prediction.append(index)\n",
    "            index_of_true_pair.append(i)\n",
    "        i +=1\n",
    "    for i in range(len(index_of_error_prediction)):\n",
    "        index1 = index_of_error_prediction[i]\n",
    "        index2 = index_of_true_pair[i]\n",
    "        score1 = score_by_new_doc(pairs_trains[index1][0], pairs_trains[index2][0],dict, 'normal')\n",
    "        score2 = score_by_new_doc(pairs_trains[index2][0], pairs_trains[index2][0],dict, 'normal')\n",
    "        print('False return question--- {} ---with score {}'.format(pairs_trains[index1][0], score1))\n",
    "        print('True return question--- {} ---with score {}'.format(pairs_trains[index2][0], score2))\n",
    "\n",
    "def print_all_errors_on_test(dict):\n",
    "    for pair in pairs_tests:\n",
    "        question = clear_line(pair[0], STOPWORDS)\n",
    "        index = find_right_index(question, dict, 'normal')\n",
    "        print(pair)\n",
    "        print(pairs_trains[index])\n",
    "        print()\n",
    "        \n",
    "def clear_all_trains_test_and_save_in_file(convos_train, convos_test):\n",
    "    \n",
    "    convos_train.extend(convos_test)\n",
    "\n",
    "    \n",
    "def construct_dict(dicts):\n",
    "    \n",
    "    in_file = open(os.path.join('processed', 'dictionnary.txt'), 'r')\n",
    "    lines = []\n",
    "    words = []\n",
    "    LINES_to_return = []\n",
    "    for line in in_file:\n",
    "        line = line.strip().split('|')\n",
    "        line = [stemmer.stem(word) for word in line]\n",
    "        lines.append(line)\n",
    "    for line in lines:\n",
    "        for index in range(len(dicts)):\n",
    "            word = dicts[index]\n",
    "            if str(word) in line and word not in words:\n",
    "                line.insert(0,str(word))\n",
    "                index1 = min(10, len(line))\n",
    "                LINES_to_return.append(line[:index1])\n",
    "                words.append(word)\n",
    "    for word in dicts:\n",
    "        boolean = False\n",
    "        for line in LINES_to_return:\n",
    "            if word in line:\n",
    "                boolean = True\n",
    "        if not boolean:\n",
    "             LINES_to_return.append(word)\n",
    "    return LINES_to_return\n",
    "\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    try:\n",
    "        pairs_trains_\n",
    "    except NameError :\n",
    "        pairs_trains = get_all_convos(STOPWORDS, 'convos27juin_train_smaller.txt')\n",
    "        pairs_tests = get_all_convos(STOPWORDS, 'convos27juin_test_smaller.txt')\n",
    "        pairs_trains = clear_all_convos(pairs_trains, 'train')\n",
    "        pairs_tests = clear_all_convos(pairs_tests, 'test')\n",
    "        #pairs_trains.extend(pairs_tests)\n",
    "        LIST_OF_WORDS = get_list_words(pairs_trains)\n",
    "        KEY_LIST = get_key_list(pairs_trains)\n",
    "        QUESTION_TO_TRAINS = []\n",
    "        for pairs in pairs_trains:\n",
    "            QUESTION_TO_TRAINS.append(pairs[0])\n",
    "        #METHODE = ['normal','lissé', 'probabiliste','probabiliste_lissé']\n",
    "        METHODE = ['normal']\n",
    "        DICT = dict_of_all_score(METHODE)  \n",
    "        DICTIONNARY = construct_dict(LIST_OF_WORDS)\n",
    "print('on train:')\n",
    "for méthode in METHODE:\n",
    "    test_with_precision_recall(DICT, méthode, train = True)\n",
    "print('On test:')\n",
    "for méthode in METHODE:\n",
    "    test_with_precision_recall(DICT, méthode, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ça v', 0)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = 'ça va'\n",
    "transformed_line(line, DICTIONNARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('v', 3)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = 'je veux une voiture'\n",
    "transformed_line(line, DICTIONNARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "veux   savoir   longueur   moyen   trajet   combien   véhicul   roul   carbur   vitess   quoi   problem   quel   voitur   mauvais   pression   pneu   moin   utilis   quand   révis   plus   grand   km   vit   prénom   batter   faibl   maximal   erreur   élev   charg   petit   salut   bisous   ampoul   feux   stop   bon   état   avon   l’état   d’usur   pneumat   haut   pass   pneus   hiv   derni   contrôl   techniqu   souhait   avoir   don   restitu   consomm   ok   min   peux   renseign   passager   bord   max   minimal   adapt   kilomètrag   tout   va   bien   appel   comment   disponibl   boiti   fonction   dur   contrat   locat   mod   transmiss   posit   correct   temp   paramêtr   boîti   immobilis   sembl   être   passag   ateli   revoir   estim   arriv   pet   excess   maximum   circulent   vas   manqu   huil   dan   moteur   con   bot   dang   sant   besoin   merc   madam   compar   distanc   parcouru   nom   garag   rapport   flott   cod   défaut   diminu   rejet   pollut   fair   brin   causet   rout   frein   usé   réduir   émiss   pollu   signif   dtc   hor   servic   trouv   proch   étrang   lien   mobil   taux   qu’il   fait   beau   autr   modul   géner   où   idiot   suivr   voudr   aid   marqu   age   thémat   kilométrag   connect   commun   coût   post   kilometr   caractérist   parcourus   tv   ça   gentil   indiqu   install   monsieur   grav   perform   cet   partag   del   livraison   urgenc   trait   gestion   modifi   inform   relat   compt   arrêt   pourquoi   prochain   histor   matin   vais   interlocuteur   souc   freinag   trop   brusqu   faut   aim   empreint   carbon   pai   alert   usag   embouteillag   disponibil   disqu   abîm   déconnect   bientôt   c’est   sup   outil   cart   pardon   horair   ouvertur   risqu   pann   organ   t’e   stupid   remplac   sais   président   franc   particul   fin   object   roulent   conduit   main   mal   soir   constructeur   co2   ca   craint   postul   présent   parc   accéler   franch   périmetr   fais   prêt   si   1h   prendr   mutualis   évalu   pertinent   connaîtr   mont   bonjour   mademoisel   liquid   peur   réserv   cherch   éven   fort   mond   énerg   embarqu   nombr   mois   déplac   demain   plac   échéanc   respect   doit   niveau   lav   glac   rest   hui   dat   essenc   coup   press   naissanc   bouchon   indec   opérationnel   kilometrag   tco   vin   gros   conducteur   bonsoir   puissanc   fiscal   contact   sav   question   embrayag   dois   prévoir   localis   vi   normal   chang   refroid   obten   crev   indisponibil   cordial   soutien   comport   tourn   optimis   électr   planning   sécur   effect   usur   plaquet   #to_return_when_good_reponse_is_not_found#   "
     ]
    }
   ],
   "source": [
    "for word in LIST_OF_WORDS:\n",
    "    print(word, end= '   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "veux\n",
      "avon\n",
      "va\n",
      "voudr\n",
      "tv\n",
      "vais\n"
     ]
    }
   ],
   "source": [
    "for line in DICTIONNARY:\n",
    "    if 'v' in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, C'est le bot d'Avicen, pose tes questions, s'il te plaît!\n",
      "Vous: bonjour\n",
      "Ligne tranformée:  salut\n",
      "bot:  cordialement\n",
      "Vous: salut\n",
      "Ligne tranformée:  salut\n",
      "bot:  cordialement\n",
      "Vous: comment tu va\n",
      "Ligne tranformée:  comment v\n",
      "bot:  je vais bien merci\n",
      "Vous: combien de voitures qui roulent\n",
      "Ligne tranformée:  combien voitur r\n",
      "bot:  le parc est composé de #nb_veh#\n",
      "Vous: combien de véhicules à l'arrêt?\n",
      "Ligne tranformée:  combien véhicul arrêt\n",
      "bot:  #combien# #arrêt#\n",
      "Vous: combien de voitures hors services\n",
      "Ligne tranformée:  combien voitur hor servic\n",
      "bot:  merci de signaler au personnel de Avicen au #numéro_avicen#\n",
      "Vous: je veux une voiture\n",
      "Ligne tranformée:  v voitur\n",
      "bot:  #ask_id# #position#\n",
      "Vous: veux\n",
      "Ligne tranformée:  v\n",
      "bot:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "Vous: va\n",
      "Ligne tranformée:  v\n",
      "bot:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "Vous: vraiment\n",
      "Ligne tranformée:  \n",
      "Désolé, je ne comprends pas ta question, peux tu la reformuler s'il te plaît?\n",
      "Vous: carburant comsomé\n",
      "Ligne tranformée:  carbur\n",
      "Désolé, je ne comprends pas ta question, peux tu la reformuler s'il te plaît?\n",
      "Vous: carburant consommé\n",
      "Ligne tranformée:  carbur consomm\n",
      "bot:  #ask_id# #consumption#\n",
      "Vous: combien de voitures qui consommes plus de carburant\n",
      "Ligne tranformée:  combien voitur consomm plus carbur\n",
      "bot:  #consumption# #total#\n",
      "Vous: \n",
      "Ligne tranformée:  \n"
     ]
    }
   ],
   "source": [
    "chat('normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STOPWORDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fe969ee36e19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconvos_to_return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mquestions_trains\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_questions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'convos27juin_train_smaller.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mquestions_tests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_questions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'convos27juin_test_smaller.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mquestions_trains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions_tests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'STOPWORDS' is not defined"
     ]
    }
   ],
   "source": [
    "def get_all_questions(stopwords, file):\n",
    "    \n",
    "    convos = []\n",
    "    #file = 'convos27juin.txt'\n",
    "    #file1 = 'chatbot_tout_corpus.txt'\n",
    "    #file2 = 'chatbot_tout_corpus_13juin.txt'\n",
    "    #file3 = 'convos_120_nettoye.txt' # cette fichier viens d'etre ajouter\n",
    "    liste_file = [file]\n",
    "    list_of_word = []\n",
    "    list_word = ['quelle voiture', 'quelles voitures', 'quel véhicule', 'quels véhicules']\n",
    "    for file in liste_file:\n",
    "        with open(file) as f:\n",
    "            i=0\n",
    "            for line in f:\n",
    "                if i%2==0:\n",
    "                    question = str(line)\n",
    "                    if '++++' in question:\n",
    "                         question = question[9:]\n",
    "                    boolean = True\n",
    "                    for word in list_word:\n",
    "                        if word in question:\n",
    "                            boolean = False\n",
    "                    if boolean:\n",
    "                        convos.append(question)\n",
    "                i+=1\n",
    "        convos_to_return = []\n",
    "        for pair in convos:\n",
    "            if len(pair[0]) !=0:\n",
    "                convos_to_return.append(pair)\n",
    "        f.close()\n",
    "    return convos_to_return\n",
    "questions_trains = get_all_questions(STOPWORDS, 'convos27juin_train_smaller.txt')\n",
    "questions_tests = get_all_questions(STOPWORDS, 'convos27juin_test_smaller.txt')\n",
    "questions_trains.extend(questions_tests)\n",
    "questions = []\n",
    "for question in questions_trains:\n",
    "    if question not in questions:\n",
    "        questions.append(question)\n",
    "with open('questions.txt', 'w') as f:\n",
    "        for question in questions:\n",
    "            f.write(question+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU:  voiture immobilisée\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  comment tu t'appelles\n",
      "BOT:  je suis le bot d'Avicen tu peux m'appeler Emmet\n",
      "\n",
      "YOU:  je veux voir s'il y a des problèmes\n",
      "BOT:  #problème#\n",
      "\n",
      "\n",
      "YOU:  il y a problèmes\n",
      "BOT:  #problème#\n",
      "\n",
      "YOU:  il y a des urgences\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  problème de freine\n",
      "BOT:  #ask_id# #problème# #frein#\n",
      "\n",
      "YOU:  problème de vitesse\n",
      "BOT:  véhicule #id# #problèmes# #vitesse#\n",
      "\n",
      "YOU:  combien de véhicules à l'arrêt?\n",
      "BOT:  #combien# #arrêt#\n",
      "\n",
      "YOU:  combien de véhicule à l'arrêt\n",
      "BOT:  #combien# #arrêt#\n",
      "\n",
      "YOU:  combien de véhicule en circulation\n",
      "BOT:  il y a #nb_véhicule#\n",
      "\n",
      "YOU:  il y a des véhicules hors zone définie\n",
      "BOT:  #combien# #hors_périmètre#\n",
      "\n",
      "YOU:  il y a des problèmes?\n",
      "BOT:  #problème#\n",
      "\n",
      "YOU:  il y a de problèmes\n",
      "BOT:  #problème#\n",
      "\n",
      "YOU:  coucou\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  trompé\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  je veux savoir si il y a de problème\n",
      "BOT:  #problème#\n",
      "\n",
      "\n",
      "YOU:  non, je veux savoir si tout va bien\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  combien de véhicules à l'arrêt\n",
      "BOT:  #combien# #arrêt#\n",
      "\n",
      "YOU:  combien de véhicules en circulation\n",
      "BOT:  il y a #nb_véhicule#\n",
      "\n",
      "YOU:  combien de véhicules en marche\n",
      "BOT:  il y a #nb_véhicule#\n",
      "\n",
      "YOU:  nombre de trajets\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  combien de km au total\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  combien de carburant au total\n",
      "BOT:  #consommation#\n",
      "\n",
      "YOU:  salut\n",
      "BOT:  cordialement\n",
      "\n",
      "YOU:  comment tu vas\n",
      "BOT:  je vais bien merci\n",
      "\n",
      "YOU:  la flotte\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  un résume sur flotte\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  combien de voitures en circulation\n",
      "BOT:  le parc est composé de #nb_veh#\n",
      "\n",
      "YOU:  combien de voitures à l'arrêt\n",
      "BOT:  #combien# #arrêt#\n",
      "\n",
      "YOU:  combien de voiture à l'arrêt?\n",
      "BOT:  #combien# #arrêt#\n",
      "\n",
      "YOU:  qui est président des états-unis\n",
      "BOT:  désolé je ne sais pas peut on parler d’autre sujets ou reformuler ta question?\n",
      "\n",
      "YOU:  qui est le plus fort\n",
      "BOT:  je l'ignore. peut être moi :)\n",
      "\n",
      "YOU:  qui est le plus con\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  qui est plus stupid\n",
      "BOT:  c’est vrai que je ne connais pas tout mais je suis toujours prêt à t’aider\n",
      "\n",
      "YOU:  a b c d e\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  qui est le plus fort que tout le monde entier\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  combien km au total\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  combien carburant comsomé\n",
      "BOT:  #consommation#\n",
      "\n",
      "YOU:  combien carburant\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  carburant\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  essence\n",
      "BOT:  #ask_id# #carburant#\n",
      "\n",
      "\n",
      "YOU:  essences\n",
      "BOT:  #ask_id# #carburant#\n",
      "\n",
      "\n",
      "YOU:  combien d'essence\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  combien\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  je cherche une voiture\n",
      "BOT:  #list_vin_free#\n",
      "\n",
      "YOU:  je veux un véhicule le plus vite possible\n",
      "BOT:  véhicule #id# #km# #MAX#\n",
      "\n",
      "YOU:  quel véhicule qui roule moins vite\n",
      "BOT:  véhicule #id# #km# #MIN#\n",
      "\n",
      "YOU:  la moyenne des vitesse\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  vitesse en moyenne\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  je cherche un véhicule\n",
      "BOT:  #ask_id# #position#\n",
      "\n",
      "YOU:  bonjour\n",
      "BOT:  bonjour\n",
      "\n",
      "\n",
      "YOU:  est ce que tout va bien\n",
      "BOT:  ça va et toi\n",
      "\n",
      "YOU:  problème\n",
      "BOT:  #problème#\n",
      "\n",
      "YOU:  combien carburant mon véhicule a comsommé ce mois\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  la santé des voitures\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  combien de véhicule sont à l'arrêt?\n",
      "BOT:  #combien# #arrêt#\n",
      "\n",
      "YOU:  combien de véhicule sont à lyon\n",
      "BOT:  il y a #nb_véhicule#\n",
      "\n",
      "YOU:  je veux savoir s'il y a des problèmes\n",
      "BOT:  #problème#\n",
      "\n",
      "\n",
      "YOU:  c'est qui le président de france\n",
      "BOT:  désolé je ne sais pas peut on parler d’autre sujets ou reformuler ta question?\n",
      "\n",
      "YOU:  c'est quoi\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  combien kilomètrage a parcouru mon véhicule\n",
      "BOT:  #ask_id# #km#\n",
      "\n",
      "YOU:  combien de km les véhicules sont parcouru en moyenne\n",
      "BOT:  #ask_id# #km#\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chatting_with_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, C'est le bot d'Avicen, pose tes questions, s'il te plaît!\n",
      "Vous: quelle est la distance moyenne\n",
      "bot:  #comparer# #km#\n",
      "Vous: la vitesse moyenne\n",
      "bot:  véhicule #id# #vitesse# #MOYENNE#\n",
      "Vous: la pression de pneu est bonne\n",
      "bot:  #ask_id# #pression#\n",
      "Vous: quels sont les véhicules avec une mauvaise pression de pneu\n",
      "bot:  #ask_id# #pression#\n",
      "Vous: quels est le véhicule qui est le moins utilisé\n",
      "bot:  vous pouvez vous servir du #list_vin_free#\n",
      "Vous: \n"
     ]
    }
   ],
   "source": [
    "chat('normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformed_line(line, dicts):\n",
    "    \n",
    "    line_to_return = []\n",
    "    for word in line.split():\n",
    "        for Line in dicts:\n",
    "            if word in Line and word not in line_to_return:\n",
    "                line_to_return.append(Line[0])\n",
    "                break\n",
    "    return ' '.join(line_to_return), len(line.split())-len(line_to_return)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
