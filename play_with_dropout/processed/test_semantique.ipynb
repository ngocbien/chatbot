{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2 sentence pairs of training set\n",
      "Read 0 sentence pairs of test set\n",
      "Counted words:\n",
      "question 10\n",
      "answer 9\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cet technique marche beaucoup mieux que dans tensorflow, avec en très peu de temps. \n",
    "Ce modèle fonctionne mieux que l'autre dans tensorflow parce qu'une raison évidente: \n",
    "il utilise méthode teacher forcing Un autre problème avec ce méthode, \n",
    "c'est dropout qui donne une technique plus ou moins bon. Il donne la \n",
    "réponse plus tôt aléatoire pour une question. En cas général, \n",
    "ce la peut être intéressant, mais dans notre cas, il est très important \n",
    "qu'il capture le mot clés \n",
    "(donc, surtout on risque de supprimer le mot clés, qui rendra une mauvais réponse)\n",
    "modèle est bien entrainé, donc, il ne sert à rien d'entrainer encore.\n",
    "hidden_size =45 tres mauvais; =70 bien; =100 tres bien; =120 très bien; =150 overfit.\n",
    "hidden_size 50 20%\n",
    "hidden_size 70 33%\n",
    "hidden_size 120 28%\n",
    "\"\"\"\n",
    "#from IPython.display import display, Markdown\n",
    "#display(Markdown(\"### Pour lancer un chat, il suffit de taper en même temps CTRL et ENTER\"))\n",
    "#display(Markdown(\"### Pour arrêter le mode chat, il suffit de taper ENTER dans votre conversation\"))\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import data\n",
    "import config\n",
    "import time\n",
    "from dateparser.search import search_dates\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "hidden_size = 5\n",
    "SOS_token  = config.SOS_token\n",
    "EOS_token  = config.EOS_token\n",
    "MAX_LENGTH = config.MAX_LENGTH\n",
    "stopwords  = config.STOPWORDS\n",
    "learning_rate = config.LEARNING_RATE\n",
    "teacher_forcing_ratio = 0.2\n",
    "dropout = config.DROPOUT\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  \n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "def normalizeString(s):\n",
    "    \"\"\"\n",
    "    Whith a tring s, we make it in lower case, delete \\n if exists at \n",
    "    the end of string, and delete specical case ? . and !\n",
    "    \"\"\"\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([,.!?\\n])\", r\"\", s)# sumprimer tous les caractères .! et ?\n",
    "    #s = re.sub(r\"[^a-zA-Z0-9.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH \n",
    "\n",
    "    \n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(PAIRS):\n",
    "    input_lang = Lang('question')\n",
    "    output_lang = Lang( 'answer')\n",
    "    pairs_trains, pairs_tests = [], []\n",
    "   # index_train = random.sample(range(len(PAIRS)), int(len(PAIRS)*0.80))\n",
    "    for i in range(len(PAIRS)):\n",
    "        #if i in index_train:\n",
    "            pairs_trains.append(PAIRS[i])\n",
    "        #else:\n",
    "            #pairs_tests.append(PAIRS[i])\n",
    "    print(\"Read %s sentence pairs of training set\" % len(pairs_trains))\n",
    "    print(\"Read %s sentence pairs of test set\" % len(pairs_tests))\n",
    "    pairs_trains = filterPairs(pairs_trains)\n",
    "    pairs_tests = filterPairs(pairs_tests)\n",
    "    for i  in range(len(pairs_trains)) :\n",
    "        pair = pairs_trains[i]\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    \n",
    "    for i  in range(len(pairs_tests)) :\n",
    "        pair = pairs_tests[i]\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs_trains, pairs_tests\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "        \n",
    "\n",
    "def normalizeSentenceInChat(sentence):\n",
    "    sentence = sentence.strip().lower().split()\n",
    "    s = [closetWord(word, input_lang) for word in sentence]\n",
    "    return ' '.join(s)\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    #sentence = normalizeSentence\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index ]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "def get_skip_step(n_iters):\n",
    "    return int(n_iters/10)\n",
    "\n",
    "def trainIters(n_iters, encoder, decoder, plot_every=100, learning_rate=learning_rate):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    skip_step = get_skip_step(n_iters)\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs_trains))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % skip_step == 0:\n",
    "            print_loss_avg = print_loss_total / skip_step\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    save_model(encoder, decoder)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    #sentence = normalizeSentenceInChat(sentence)\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  \n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        ni = int(ni)\n",
    "        if ni == EOS_token:\n",
    "            #decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluate_randomly(encoder, decoder,n_iters=200, test=True):\n",
    "    if not test:\n",
    "        print('TEST error of word to word on TRAIN')\n",
    "        list_print_random = random.sample(range(n_iters),20 )\n",
    "        total_loss = 0\n",
    "        for i in range(n_iters):\n",
    "            pair = random.choice(pairs_trains)\n",
    "            output_words = evaluate(encoder, decoder, pair[0])\n",
    "            if 'EOS' in output_words:\n",
    "                l = output_words.index('EOS')+1\n",
    "            else:\n",
    "                l = len(output_words)+1\n",
    "            reponse = ' '.join(output_words[:l])\n",
    "            loss = _evaluate_by_right_word(pair[1], reponse)\n",
    "            total_loss +=loss\n",
    "            if i in list_print_random:\n",
    "                #answer = answers_with_data(pair[0], reponse)\n",
    "                print('Question: ', pair[0])\n",
    "                print('Réponse: ', pair[1])\n",
    "                print('Bot: {}   ACCURACY {:.1f}'.format(reponse, 1-loss))\n",
    "                #if answer != reponse:\n",
    "                 #   print('Réponse avec data:', answer)                \n",
    "                print('-'*50)\n",
    "        print('Accuracy of good answer word to word: ', 1-total_loss/n_iters)\n",
    "    else:\n",
    "        n_iters = len(pairs_tests)\n",
    "        total_loss = 0\n",
    "        random_print_index = random.sample(range(n_iters), 20)\n",
    "        for i in range(n_iters):\n",
    "            pair = pairs_tests[i]\n",
    "            output_words= evaluate(encoder, decoder, pair[0])\n",
    "            if 'EOS' in output_words:\n",
    "                l = output_words.index('EOS')+1\n",
    "            else:\n",
    "                l = len(output_words)+1\n",
    "            reponse = ' '.join(output_words[:l])\n",
    "            loss = _evaluate_by_right_word(pair[1], reponse)\n",
    "            if i in random_print_index:\n",
    "                print('Question: ', pair[0])\n",
    "                print('Réponse: ', pair[1])\n",
    "                print('Bot: {}. ACCURACY {:.1f}'.format(reponse, 1-loss))\n",
    "                print('-'*50)\n",
    "            total_loss +=loss\n",
    "        print('Test on {}'.format(n_iters))\n",
    "        print('Accuracy by percent of true words {}'.format(1-total_loss/n_iters))\n",
    " \n",
    "\n",
    "                \n",
    "def make_dir(path):\n",
    "    \"\"\" Create a directory if there isn't one already. \"\"\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "\n",
    "def chat(encoder, decoder):\n",
    "    make_dir(config.CHECK_POINT_PATH)\n",
    "    lines = construct_dict(input_lang)\n",
    "    output_file = open(os.path.join(config.CHECK_POINT_PATH, 'convos70.txt'), 'a+')\n",
    "    print('Bonjour, c\\'est le Bot d\\'AVICEN, Je peux vous aider? \\n')\n",
    "    while True:\n",
    "            line = str(input('Vous: '))\n",
    "            if len(line) > 0 and line[-1] == '\\n':\n",
    "                line = line[:-1]\n",
    "            if line == '':\n",
    "                break\n",
    "            line = normalizeString(line)\n",
    "            #transform_line  = normalizeSentenceInChat(line)\n",
    "            #transform_line = find_close_line(lines, input_lang, transform_line)\n",
    "            #print('LIGNE TRANFORMÉ: ', line)\n",
    "            output_file.write('VOUS ++++ ' + line + '\\n')\n",
    "            reponse = evaluate(encoder, decoder, line)\n",
    "            if 'SOS' in reponse:\n",
    "                 reponse = reponse[1:] \n",
    "            if 'EOS' in reponse:\n",
    "                reponse = reponse[:-1] \n",
    "            reponse = \" \".join(reponse)\n",
    "            output_file.write('BOT ++++ ' + reponse + '\\n')\n",
    "            print('Without Data: ', reponse)\n",
    "            reponse = answers_with_data(line, reponse)\n",
    "            print('Bot AVICEN: ', reponse)\n",
    "            print('-'*50)\n",
    "    output_file.close() \n",
    "\n",
    "if __name__=='__main__':\n",
    "    try:\n",
    "        input_lang0\n",
    "    except NameError :\n",
    "        pair1 = ['combien de voitures qui roulent', 'il y en a cing']\n",
    "        pair2 = ['combien de véhicules à l\\'arrêt', 'environ trois']\n",
    "        PAIRS = [pair1, pair2]\n",
    "        input_lang, output_lang, pairs_trains, pairs_tests = prepareData(PAIRS)\n",
    "        encoder = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "        decoder = DecoderRNN(hidden_size, output_lang.n_words,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the parameters from check_point/encoder_test_semantique.ck and check_point/decoder_test_semantique.ck...\n",
      "Bonjour, c'est le Bot d'AVICEN, Je peux vous aider? \n",
      "\n",
      "Vous: combien de voitures\n",
      "Without Data:  il y en a cing\n",
      "Bot AVICEN:  il y en a cing\n",
      "--------------------------------------------------\n",
      "Vous: combien de véhicules\n",
      "Without Data:  il y en a cing\n",
      "Bot AVICEN:  il y en a cing\n",
      "--------------------------------------------------\n",
      "Vous: combien véhicules qui roulent\n",
      "Without Data:  il y en a cing\n",
      "Bot AVICEN:  il y en a cing\n",
      "--------------------------------------------------\n",
      "Vous: combien voitures à l'arrêt\n",
      "Without Data:  environ trois\n",
      "Bot AVICEN:  environ trois\n",
      "--------------------------------------------------\n",
      "Vous: qui\n",
      "Without Data:  il y en a cing\n",
      "Bot AVICEN:  il y en a cing\n",
      "--------------------------------------------------\n",
      "Vous: à\n",
      "Without Data:  environ trois\n",
      "Bot AVICEN:  environ trois\n",
      "--------------------------------------------------\n",
      "Vous: voitures\n",
      "Without Data:  il y en a cing\n",
      "Bot AVICEN:  il y en a cing\n",
      "--------------------------------------------------\n",
      "Vous: véhicules\n",
      "Without Data:  il y en a cing\n",
      "Bot AVICEN:  il y en a cing\n",
      "--------------------------------------------------\n",
      "Vous: combien\n",
      "Without Data:  environ trois\n",
      "Bot AVICEN:  environ trois\n",
      "--------------------------------------------------\n",
      "Vous: il\n",
      "Without Data:  environ trois\n",
      "Bot AVICEN:  environ trois\n",
      "--------------------------------------------------\n",
      "Vous: de\n",
      "Without Data:  il y en a cing\n",
      "Bot AVICEN:  il y en a cing\n",
      "--------------------------------------------------\n",
      "Vous: voitures véhicules\n",
      "Without Data:  il y en a cing\n",
      "Bot AVICEN:  il y en a cing\n",
      "--------------------------------------------------\n",
      "Vous: véhicules voitures\n",
      "Without Data:  il y en a cing\n",
      "Bot AVICEN:  il y en a cing\n",
      "--------------------------------------------------\n",
      "Vous: voitures à\n",
      "Without Data:  il y en a cing\n",
      "Bot AVICEN:  il y en a cing\n",
      "--------------------------------------------------\n",
      "Vous: \n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, c'est le Bot d'AVICEN, Je peux vous aider? \n",
      "\n",
      "Vous: bonjour\n",
      "Without Data:  environ trois\n",
      "Bot AVICEN:  environ trois\n",
      "--------------------------------------------------\n",
      "Vous: combien de voitures roulent\n",
      "Without Data:  il y en a cing\n",
      "Bot AVICEN:  il y en a cing\n",
      "--------------------------------------------------\n",
      "Vous: combien de véhicules à l'arrêt\n",
      "Without Data:  environ trois\n",
      "Bot AVICEN:  environ trois\n",
      "--------------------------------------------------\n",
      "Vous: voitures à l'arrêt\n",
      "Without Data:  environ trois\n",
      "Bot AVICEN:  environ trois\n",
      "--------------------------------------------------\n",
      "Vous: véhicules roulent\n",
      "Without Data:  il y en a\n",
      "Bot AVICEN:  il y en a\n",
      "--------------------------------------------------\n",
      "Vous: combien véhicules qui roulent\n",
      "Without Data:  il y en a cing\n",
      "Bot AVICEN:  il y en a cing\n",
      "--------------------------------------------------\n",
      "Vous: \n"
     ]
    }
   ],
   "source": [
    "chat(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:298: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 4s (- 0m 38s) (1500 10%) 0.0067\n",
      "0m 8s (- 0m 34s) (3000 20%) 0.0060\n",
      "0m 12s (- 0m 29s) (4500 30%) 0.0054\n",
      "0m 16s (- 0m 25s) (6000 40%) 0.0050\n",
      "0m 21s (- 0m 21s) (7500 50%) 0.0046\n",
      "0m 25s (- 0m 16s) (9000 60%) 0.0042\n",
      "0m 29s (- 0m 12s) (10500 70%) 0.0040\n",
      "0m 33s (- 0m 8s) (12000 80%) 0.0037\n",
      "0m 37s (- 0m 4s) (13500 90%) 0.0035\n",
      "0m 42s (- 0m 0s) (15000 100%) 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type EncoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type DecoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainIters(15000,encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the parameters from check_point/encoder_test_semantique.ck and check_point/decoder_test_semantique.ck...\n",
      "Bonjour, c'est le Bot d'AVICEN, Je peux vous aider? \n",
      "\n",
      "Vous: \n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the parameters from check_point/encoder_test_semantique.ck and check_point/decoder_test_semantique.ck...\n",
      "TEST error of word to word on TRAIN\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules à l'arrêt\n",
      "Réponse:  environ trois\n",
      "Bot: environ trois   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Accuracy of good answer word to word:  1.0\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly(test = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the parameters from check_point/encoder_simulation_2.ck and check_point/decoder_simulation_2.ck...\n",
      "Bonjour, c'est le Bot d'AVICEN, Je peux vous aider? \n",
      "\n",
      "Vous: \n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
