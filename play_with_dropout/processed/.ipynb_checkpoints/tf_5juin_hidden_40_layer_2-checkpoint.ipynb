{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modèle n'est pas bon, ce peut être la faute de quelque fonction comme sampled_softmax_loss() dans model.\n",
    "De toute façon, le modèle est plus lourd que ce lui de Torch\n",
    "Tester pour:\n",
    "hidden_size = 40, layer =3, sample_size = 200 accuracy = 17%\n",
    "hidden_size = 40, layer =3, sample_size = DEC_VOCAB-1, accuracy = 27%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from model_40_2 import ChatBotModel\n",
    "import config_tf as config\n",
    "import data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def run_step(sess, model, encoder_inputs, decoder_inputs,\n",
    "             decoder_masks, bucket_id, forward_only):\n",
    "    encoder_size, decoder_size = config.BUCKETS[bucket_id]\n",
    "    input_feed = {}\n",
    "    for step in range(encoder_size):\n",
    "        input_feed[model.encoder_inputs[step].name] = encoder_inputs[step]\n",
    "    for step in range(decoder_size):\n",
    "        input_feed[model.decoder_inputs[step].name] = decoder_inputs[step]\n",
    "        input_feed[model.decoder_masks[step].name] = decoder_masks[step]\n",
    "    \n",
    "    last_target = model.decoder_inputs[decoder_size].name\n",
    "    input_feed[last_target] = np.zeros([model.batch_size], dtype=np.int32)\n",
    "    if not forward_only:\n",
    "        output_feed = [model.train_ops[bucket_id],  # update op that does SGD.\n",
    "                       model.gradient_norms[bucket_id],  # gradient norm.\n",
    "                       model.losses[bucket_id]]  # loss for this batch.\n",
    "    else:\n",
    "        output_feed = [model.losses[bucket_id]]  # loss for this batch.\n",
    "        for step in range(decoder_size):  # output logits.\n",
    "            output_feed.append(model.outputs[bucket_id][step])\n",
    "    outputs = sess.run(output_feed, input_feed)\n",
    "    if not forward_only:\n",
    "        return outputs[1], outputs[2], None  # Gradient norm, loss, no outputs.\n",
    "    else:\n",
    "        return None, outputs[0], outputs[1:]  # No gradient norm, loss, outputs.\n",
    "\n",
    "def _get_data(train=True):\n",
    "    \n",
    "    #enc_vocab, dec_vocab, inv_enc_vocab, inv_dec_vocab = build_vocab()\n",
    "    if train:\n",
    "          DATA = data.load_data('train_question.txt', 'train_answer.txt', inv_enc_vocab, inv_dec_vocab)\n",
    "    else:\n",
    "          DATA = data.load_data('test_question.txt', 'test_answer.txt', inv_enc_vocab, inv_dec_vocab)                              \n",
    "    return  DATA\n",
    "\n",
    "def _get_skip_step(n_iters):\n",
    "    \"\"\" How many steps should the model train before it saves all the weights. \"\"\"\n",
    "\n",
    "    return int(n_iters/10)\n",
    "\n",
    "def _check_restore_parameters(sess, saver):\n",
    "    \"\"\" Restore the previously trained parameters if there are any. \"\"\"\n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname(config.CPT_PATH_40_2 + '/checkpoint'))\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        print(\"Loading parameters for the Chatbot\")\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        print(\"Initializing fresh parameters for the Chatbot\")\n",
    "\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def train(n_iters, lr = config.LR):\n",
    "    \"\"\" Train the bot \"\"\"\n",
    "    data_buckets = training_data\n",
    "    tf.reset_default_graph() \n",
    "    model = ChatBotModel(False, config.BATCH_SIZE, lr = lr)\n",
    "    model.build_graph()\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        print('Running session')\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        _check_restore_parameters(sess, saver)\n",
    "\n",
    "        iteration = model.global_step.eval()\n",
    "        total_loss = 0\n",
    "        step =0\n",
    "        loss_print = []\n",
    "        bucket_id = 0\n",
    "        start = time.time()\n",
    "        while step < n_iters:\n",
    "            step+=1\n",
    "            skip_step = _get_skip_step(n_iters)\n",
    "            encoder_inputs, decoder_inputs, decoder_masks = data.get_batch(data_buckets, \n",
    "                                                                           bucket_id,\n",
    "                                                                           batch_size=config.BATCH_SIZE)\n",
    "            \n",
    "            _, step_loss, _ = run_step(sess, model, encoder_inputs, \n",
    "                                       decoder_inputs, decoder_masks, bucket_id, False)\n",
    "            total_loss += step_loss\n",
    "            iteration += 1\n",
    "            if iteration % skip_step == 0:  \n",
    "                print_loss_avg = total_loss / skip_step\n",
    "                total_loss = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, step / n_iters),\n",
    "                                         iteration, step / n_iters * 100, print_loss_avg))\n",
    "                total_loss = 0\n",
    "                loss_print.append(step_loss)\n",
    "        saver.save(sess, os.path.join(config.CPT_PATH_40_2, 'chatbot'), global_step=model.global_step)\n",
    "        sys.stdout.flush()\n",
    "        plt.plot(loss_print)\n",
    "        plt.show()\n",
    "\n",
    "def _get_user_input():\n",
    "    t = input('Vous:  ')\n",
    "    return t\n",
    "\n",
    "def _construct_reponse(output_logits, dec_vocab):\n",
    "    outputs = [int(np.argmax(logit, axis=1)) for logit in output_logits]\n",
    "    if config.EOS_ID in outputs:\n",
    "        outputs = outputs[:outputs.index(config.EOS_ID)]\n",
    "\n",
    "    return \" \".join([tf.compat.as_str(dec_vocab[output]) for output in outputs])\n",
    "\n",
    "def chat():\n",
    "    _, enc_vocab = data.load_vocab(os.path.join(config.PROCESSED_PATH, 'encoder_vocab.txt'))\n",
    "    inv_dec_vocab, _= data.load_vocab(os.path.join(config.PROCESSED_PATH, 'decoder_vocab.txt'))\n",
    "    tf.reset_default_graph() \n",
    "    model = ChatBotModel(True, batch_size=1)\n",
    "    model.build_graph()\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        _check_restore_parameters(sess, saver)\n",
    "        output_file = open(os.path.join(config.PROCESSED_PATH, config.OUTPUT_FILE), 'a+')\n",
    "        max_length = config.BUCKETS[-1][0]\n",
    "        print('Bonjour, dites moi ce que vous voulez: ')\n",
    "        while True:\n",
    "            line = _get_user_input()\n",
    "            if len(line) > 0 and line[-1] == '\\n':\n",
    "                line = line[:-1]\n",
    "            if line == '':\n",
    "                break\n",
    "            output_file.write('VOUS ++++ ' + line + '\\n')\n",
    "            token_ids = data.sentence2id(enc_vocab, str(line))\n",
    "            if (len(token_ids) > max_length):\n",
    "                print('La longueur maximale est:', max_length)\n",
    "                continue\n",
    "            bucket_id = _find_right_bucket(len(token_ids))\n",
    "            encoder_inputs, decoder_inputs, decoder_masks = data.get_batch([(token_ids, [])], \n",
    "                                                                            bucket_id,\n",
    "                                                                            batch_size=1)\n",
    "            _, _, output_logits = run_step(sess, model, encoder_inputs, decoder_inputs,\n",
    "                                           decoder_masks, bucket_id, True)\n",
    "            response = _construct_reponse(output_logits, dec_vocab)\n",
    "            \n",
    "            print('Bot de AVICEN:  ', response)\n",
    "            output_file.write('BOT ++++ ' + response + '\\n')\n",
    "        output_file.write('=============================================\\n')\n",
    "        output_file.close()\n",
    "        \n",
    "def evaluate_randomly(n_iters=30, test=True):\n",
    "    if not test:\n",
    "        tf.reset_default_graph() \n",
    "        model = ChatBotModel(True, batch_size=1)\n",
    "        model.build_graph()\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            _check_restore_parameters(sess, saver)\n",
    "            for i in range(n_iters):\n",
    "                random_index = random.choice(range(len(training_data)))\n",
    "                bucket_id = 0  \n",
    "                question = training_data[random_index][0]\n",
    "                answer = training_data[random_index][1]\n",
    "                encoder_inputs, decoder_inputs, decoder_masks = \\\n",
    "                    data.get_batch([(question, [])], \\\n",
    "                    bucket_id, batch_size=1)\n",
    "                _, _, output_logits = run_step(sess, model, encoder_inputs, decoder_inputs,\n",
    "                                           decoder_masks, bucket_id, True)\n",
    "                reponse = _construct_reponse(output_logits, dec_vocab)\n",
    "                bonne_reponse = \" \".join([str(dec_vocab[id]) for id in answer])\n",
    "                question = \" \".join([str(enc_vocab[id]) for id in question])\n",
    "                print('--------------------------------------------------')\n",
    "                print('Question:  ',  question)\n",
    "                print('Bot     :  ', reponse)\n",
    "                print('Réponse : ', bonne_reponse)\n",
    "    else:\n",
    "        tf.reset_default_graph() \n",
    "        model = ChatBotModel(True, batch_size=1)\n",
    "        model.build_graph()\n",
    "        saver = tf.train.Saver()\n",
    "        total_loss = 0\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            _check_restore_parameters(sess, saver)\n",
    "            n_iters = len(test_data)\n",
    "            print_random_index = random.sample(range(n_iters), 20)\n",
    "            bucket_id = 0\n",
    "            for i in range(n_iters):\n",
    "                question = test_data[i][0]\n",
    "                answer = test_data[i][1]\n",
    "                encoder_inputs, decoder_inputs, decoder_masks = data.get_batch([(question, [])], \n",
    "                                                                            bucket_id,\n",
    "                                                                            batch_size=1)\n",
    "                _, _, output_logits = run_step(sess, model, encoder_inputs, decoder_inputs,\n",
    "                                           decoder_masks, bucket_id, True)\n",
    "                reponse = _construct_reponse(output_logits, dec_vocab)\n",
    "                bonne_reponse = \" \".join([str(dec_vocab[id]) for id in answer[1:-1]])\n",
    "                loss = _evaluate_by_right_word(reponse, bonne_reponse)\n",
    "                total_loss +=loss\n",
    "                if i in print_random_index:\n",
    "                    question = \" \".join([str(enc_vocab[id]) for id in question])\n",
    "                    print('Question: ', question)\n",
    "                    print('Reponse: ', reponse)\n",
    "                    print('Bonne Reponse: {}. ACCURACY {:.1f} '.format(bonne_reponse,1-loss))\n",
    "                    print('-'*50)\n",
    "        print('Test on {} sentences'.format(n_iters))\n",
    "        print('Accuracy by percent of true words {}'.format(1-total_loss/n_iters))\n",
    "        #return loss/n_iters\n",
    "\n",
    "def _evaluate_by_right_word(reponse, bonne_reponse):\n",
    "    reponse = reponse.split()\n",
    "    bonne_reponse = bonne_reponse.split()\n",
    "    min_length = min(len(reponse), len(bonne_reponse))\n",
    "    max_length = max(len(reponse), len(bonne_reponse))\n",
    "    error = max_length-min_length\n",
    "    for i in range(min_length):\n",
    "        if reponse[i] != bonne_reponse[i]:\n",
    "            error +=1\n",
    "    return error/max_length\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    try:\n",
    "        training_data\n",
    "    except NameError:\n",
    "        enc_vocab, dec_vocab, inv_enc_vocab, inv_dec_vocab = data.build_vocab()\n",
    "        training_data = _get_data(True)\n",
    "        test_data = _get_data(False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize new model\n",
      "Create placeholders\n",
      "Create inference\n",
      "Creating loss... \n",
      "It might take a couple of minutes depending on how many buckets you have.\n",
      "Time: 1.865391492843628\n",
      "Create optimizer... \n",
      "It might take a couple of minutes depending on how many data  you have.\n",
      "Running session\n",
      "Loading parameters for the Chatbot\n",
      "INFO:tensorflow:Restoring parameters from checkpoints_40_2/chatbot-43000\n",
      "5m 9s (- 46m 25s) (44000 10%) 2.4733\n",
      "9m 17s (- 37m 8s) (45000 20%) 0.5687\n",
      "13m 3s (- 30m 27s) (46000 30%) 0.1347\n",
      "15m 41s (- 23m 32s) (47000 40%) 0.0397\n",
      "17m 45s (- 17m 45s) (48000 50%) 0.2087\n",
      "21m 9s (- 14m 6s) (49000 60%) 0.0202\n",
      "27m 46s (- 11m 54s) (50000 70%) 0.0135\n",
      "34m 19s (- 8m 34s) (51000 80%) 0.0122\n",
      "40m 34s (- 4m 30s) (52000 90%) 0.0102\n",
      "44m 16s (- 0m 0s) (53000 100%) 0.0087\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize new model\n",
      "Create placeholders\n",
      "Create inference\n",
      "Creating loss... \n",
      "It might take a couple of minutes depending on how many buckets you have.\n",
      "Time: 7.814579725265503\n",
      "Create optimizer... \n",
      "It might take a couple of minutes depending on how many data  you have.\n",
      "Loading parameters for the Chatbot\n",
      "INFO:tensorflow:Restoring parameters from checkpoints_40_2/chatbot-53000\n",
      "--------------------------------------------------\n",
      "Question:   j'hésite avec la solution d'un concurrent\n",
      "Bot     :   préciser application application un fournisseur pour votre dashboard une informations de votre nous pouvez-vous votre besoin\n",
      "Réponse :  il faut effectivement faire un choix nous pouvons vous accompagner de manière objective\n",
      "--------------------------------------------------\n",
      "Question:   tvs\n",
      "Bot     :   le descriptif est entre de professionnel des pneus est accessible lyon fines est accessible lafayette lafayette\n",
      "Réponse :  co2 ou air\n",
      "--------------------------------------------------\n",
      "Question:   est-ce-que tout va bien\n",
      "Bot     :   va et toi et listés je vous disponibles sont rejets celle-ci client disponibles sur le store\n",
      "Réponse :  ça va et toi\n",
      "--------------------------------------------------\n",
      "Question:   je souhaite avoir un rapport sur l'état des véhicules\n",
      "Bot     :   module ou ou vous de composé de vous accueillir manière véhicules vous accueillir manière véhicules vous\n",
      "Réponse :  parfait\n",
      "--------------------------------------------------\n",
      "Question:   je veux comparer la distance parcouru par un véhicule\n",
      "Bot     :   recherche l'information données véhicules modules le carte le est est le véhicule concerné disponible disponible disponible\n",
      "Réponse :  je recherche l'information\n",
      "--------------------------------------------------\n",
      "Question:   quels sont les indicateurs\n",
      "Bot     :   sont les indicateurs dont vous avez besoin de dans la fiche disponibles sont #kpi_finance# dans la\n",
      "Réponse :  quels sont les indicateurs dont vous avez besoin\n",
      "--------------------------------------------------\n",
      "Question:   y a t-il des problèmes\n",
      "Bot     :   vous durée passagers vous #duree_lld# de la société de la société de la société de la\n",
      "Réponse :  #oui/non#\n",
      "--------------------------------------------------\n",
      "Question:   je veux connaître la date d'achat d'un véhicule\n",
      "Bot     :   de souci quel est le véhicule concerné est nécessaire la véhicule est de #km# véhicule est\n",
      "Réponse :  pas de souci quel est le véhicule concerné\n",
      "--------------------------------------------------\n",
      "Question:   quelles synergies\n",
      "Bot     :   synergie entre acteurs du monde professionnel est 69003 développement lafayette dans votre interface client sont est\n",
      "Réponse :  forte synergie entre acteurs du monde professionnel\n",
      "--------------------------------------------------\n",
      "Question:   quelle est la couleur du ciel\n",
      "Bot     :   je ne sais pas regardons la #map_météo# du firmware est #numéro_firmware# du #date_fin_contrat# la #map_météo# du\n",
      "Réponse :  désolé je ne sais pas\n",
      "--------------------------------------------------\n",
      "Question:   je veux réduire les consommations\n",
      "Bot     :   comment puis-je vous aider real-driving ou géographique driving de #calcul_roadtrip# véhicule émissions géographique visée de vision\n",
      "Réponse :  super comment puis-je vous aider\n",
      "--------------------------------------------------\n",
      "Question:   nombre de mois de location\n",
      "Bot     :   du contrat du informations de location mois de location mois de #durée_contrat# mois est disponible #durée_contrat#\n",
      "Réponse :  la durée du contrat de location est de #durée_contrat# mois\n",
      "--------------------------------------------------\n",
      "Question:   quel est l'état de la route\n",
      "Bot     :   traffic cela #état_traffic# personnes formation en on en dans en dans votre contrat on du dans\n",
      "Réponse :  le traffic est #état_traffic#\n",
      "--------------------------------------------------\n",
      "Question:   un véhicule apparaît grisé\n",
      "Bot     :   de trouve avoir prévenu pouvez-vous nous indiquer le #vin# le #vin# tous le rdv de votre\n",
      "Réponse :  merci de nous avoir prévenu pouvez-vous nous indiquer le #vin#\n",
      "--------------------------------------------------\n",
      "Question:   ça va\n",
      "Bot     :   va et toi toi toi pros compris entre de en celle-ci pros ownership de diminuer le\n",
      "Réponse :  ça va et toi\n",
      "--------------------------------------------------\n",
      "Question:   des boitiers ne sont pas reconnus\n",
      "Bot     :   ouvrons un ticket incident nous revenons très vite vers vous inscrire très vers vous sur le\n",
      "Réponse :  nous ouvrons un ticket incident nous revenons très vite vers vous\n",
      "--------------------------------------------------\n",
      "Question:   où sont les véhicules\n",
      "Bot     :   la carte la dans votre question je suis votre besoin conviendrait sont sur votre besoin conviendrait\n",
      "Réponse :  consultez la carte\n",
      "--------------------------------------------------\n",
      "Question:   quels sont les modules\n",
      "Bot     :   de du #vin# est le store disponibles sur le store disponibles sur le store store le\n",
      "Réponse :  l'ensemble des modules disponibles sont sur le store\n",
      "--------------------------------------------------\n",
      "Question:   combien de véhicules dans le parc\n",
      "Bot     :   parc comprend #nb_vehicule# comprend #nb_vehicule# #nb_vehicule# véhicules #list_vin_free# ce parc sont partir de du #list_vin_free# de\n",
      "Réponse :  le parc comprend #nb_vehicule# véhicules\n",
      "--------------------------------------------------\n",
      "Question:   quelles sont vos horaires d'ouverture\n",
      "Bot     :   sommes disponibles du lundi au vendredi de 9h à 18h pour 9h à 18h le 18h\n",
      "Réponse :  nous sommes disponibles du lundi au vendredi de 9h à 18h\n",
      "--------------------------------------------------\n",
      "Question:   des boitiers ne sont pas reconnus\n",
      "Bot     :   ouvrons un ticket incident nous revenons très vite vers vous inscrire très vers vous sur le\n",
      "Réponse :  nous ouvrons un ticket incident nous revenons très vite vers vous\n",
      "--------------------------------------------------\n",
      "Question:   bonjour monsieur\n",
      "Bot     :   #nb_véhicules# prends note plus voici pros procédure flotte 69003 lyon cours rejets été dit à numéro\n",
      "Réponse :  bonjour\n",
      "--------------------------------------------------\n",
      "Question:   quelles sont les voitures\n",
      "Bot     :   liste préciser ce véhicule est #listing_vin# dans #listing_vin# dans la coffre-fort administratif sont dans le véhicule\n",
      "Réponse :  la liste des véhicule est #listing_vin#\n",
      "--------------------------------------------------\n",
      "Question:   performance environnementale\n",
      "Bot     :   durée durée de en à doit management parcouru de le parcouru de toujours client de nombreux\n",
      "Réponse :  ce sujet d'actualité doit prendre en compte de nombreux paramêtres pouvez-vous préciser votre question\n",
      "--------------------------------------------------\n",
      "Question:   trouvez un véhicule le plus proche\n",
      "Bot     :   véhicule plus proche est de #vin_proxi# de #vin_proxi# de #vin_proxi# de #vin_proxi# de #vin_proxi# de #vin_proxi#\n",
      "Réponse :  le véhicule plus proche est de #vin_proxi#\n",
      "--------------------------------------------------\n",
      "Question:   quel véhicule puis-je utiliser aujourd'hui\n",
      "Bot     :   pouvez votre vous d'un du #list_vin_free# l'interface accessible pouvez interface client du #list_vin_free# l'interface dans la\n",
      "Réponse :  vous pouvez vous servir du #list_vin_free#\n",
      "--------------------------------------------------\n",
      "Question:   révision\n",
      "Bot     :   révision aura lieu le #date# #date# été réservé #date# of ownership cours 69003 lyon lyon #date#\n",
      "Réponse :  la révision aura lieu le #date#\n",
      "--------------------------------------------------\n",
      "Question:   est ce qu’il manque de l’huile dans le moteur\n",
      "Bot     :   de du dans le traffic le fonction comprend ce dashboard est question dans ce véhicule est\n",
      "Réponse :  #oui/non#\n",
      "--------------------------------------------------\n",
      "Question:   au revoir\n",
      "Bot     :   revoir bientôt bientôt certitude procédure au été d’expérience sont rejets total d’expérience pros procédure nous interpeller\n",
      "Réponse :  merci à bientôt\n",
      "--------------------------------------------------\n",
      "Question:   les véhicules sont-ils en bonne santé\n",
      "Bot     :   dépend préciser préciser vous sur #nb_vehicule# vous sur le boitier concerné de sur date vous sur\n",
      "Réponse :  #oui/non#\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly(30,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['est-ce-que', 'tout', 'va', 'bien']     ['ça', 'va', 'et', 'toi']\n"
     ]
    }
   ],
   "source": [
    "idx = random.sample(range(len(training_data)), 1)\n",
    "data1 = training_data[idx[0]]\n",
    "question =  [enc_vocab[ix] for ix in data1[0]]\n",
    "answer = [dec_vocab[ix] for ix in data1[1]]\n",
    "print(question, '   ', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quel', 'est', 'le', 'contexte', 'routier']     ['quelle', 'est', 'la', 'zone', 'géographique', 'visée']\n"
     ]
    }
   ],
   "source": [
    "#DATA = data.load_data('train_question.txt', 'train_answer.txt', inv_enc_vocab, inv_dec_vocab)\n",
    "idx = random.sample(range(len(training_data)), 1)\n",
    "data1 = DATA[idx[0]]\n",
    "question =  [enc_vocab[ix] for ix in data1[0]]\n",
    "answer = [dec_vocab[ix] for ix in data1[1]]\n",
    "print(question, '   ', answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
