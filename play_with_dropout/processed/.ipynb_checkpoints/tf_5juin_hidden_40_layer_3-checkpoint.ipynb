{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modèle n'est pas bon, ce peut être la faute de quelque fonction comme sampled_softmax_loss() dans model.\n",
    "De toute façon, le modèle est plus lourd que ce lui de Torch\n",
    "Tester pour:\n",
    "hidden_size = 40, layer =3, sample_size = 200 accuracy = 17%\n",
    "hidden_size = 40, layer =3, sample_size = DEC_VOCAB-1, accuracy = 27%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from model_40_3 import ChatBotModel\n",
    "import config_tf as config\n",
    "import data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def run_step(sess, model, encoder_inputs, decoder_inputs,\n",
    "             decoder_masks, bucket_id, forward_only):\n",
    "    encoder_size, decoder_size = config.BUCKETS[bucket_id]\n",
    "    input_feed = {}\n",
    "    for step in range(encoder_size):\n",
    "        input_feed[model.encoder_inputs[step].name] = encoder_inputs[step]\n",
    "    for step in range(decoder_size):\n",
    "        input_feed[model.decoder_inputs[step].name] = decoder_inputs[step]\n",
    "        input_feed[model.decoder_masks[step].name] = decoder_masks[step]\n",
    "    \n",
    "    last_target = model.decoder_inputs[decoder_size].name\n",
    "    input_feed[last_target] = np.zeros([model.batch_size], dtype=np.int32)\n",
    "    if not forward_only:\n",
    "        output_feed = [model.train_ops[bucket_id],  # update op that does SGD.\n",
    "                       model.gradient_norms[bucket_id],  # gradient norm.\n",
    "                       model.losses[bucket_id]]  # loss for this batch.\n",
    "    else:\n",
    "        output_feed = [model.losses[bucket_id]]  # loss for this batch.\n",
    "        for step in range(decoder_size):  # output logits.\n",
    "            output_feed.append(model.outputs[bucket_id][step])\n",
    "    outputs = sess.run(output_feed, input_feed)\n",
    "    if not forward_only:\n",
    "        return outputs[1], outputs[2], None  # Gradient norm, loss, no outputs.\n",
    "    else:\n",
    "        return None, outputs[0], outputs[1:]  # No gradient norm, loss, outputs.\n",
    "\n",
    "def _get_data(train=True):\n",
    "    \n",
    "    #enc_vocab, dec_vocab, inv_enc_vocab, inv_dec_vocab = build_vocab()\n",
    "    if train:\n",
    "          DATA = data.load_data('train_question.txt', 'train_answer.txt', inv_enc_vocab, inv_dec_vocab)\n",
    "    else:\n",
    "          DATA = data.load_data('test_question.txt', 'test_answer.txt', inv_enc_vocab, inv_dec_vocab)                              \n",
    "    return  DATA\n",
    "\n",
    "def _get_skip_step(n_iters):\n",
    "    \"\"\" How many steps should the model train before it saves all the weights. \"\"\"\n",
    "\n",
    "    return int(n_iters/10)\n",
    "\n",
    "def _check_restore_parameters(sess, saver):\n",
    "    \"\"\" Restore the previously trained parameters if there are any. \"\"\"\n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname(config.CPT_PATH_40_3 + '/checkpoint'))\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        print(\"Loading parameters for the Chatbot\")\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        print(\"Initializing fresh parameters for the Chatbot\")\n",
    "\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def train(n_iters, lr = config.LR):\n",
    "    \"\"\" Train the bot \"\"\"\n",
    "    data_buckets = training_data\n",
    "    tf.reset_default_graph() \n",
    "    model = ChatBotModel(False, config.BATCH_SIZE, lr = lr)\n",
    "    model.build_graph()\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        print('Running session')\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        _check_restore_parameters(sess, saver)\n",
    "\n",
    "        iteration = model.global_step.eval()\n",
    "        total_loss = 0\n",
    "        step =0\n",
    "        loss_print = []\n",
    "        bucket_id = 0\n",
    "        start = time.time()\n",
    "        while step < n_iters:\n",
    "            step+=1\n",
    "            skip_step = _get_skip_step(n_iters)\n",
    "            encoder_inputs, decoder_inputs, decoder_masks = data.get_batch(data_buckets, \n",
    "                                                                           bucket_id,\n",
    "                                                                           batch_size=config.BATCH_SIZE)\n",
    "            \n",
    "            _, step_loss, _ = run_step(sess, model, encoder_inputs, \n",
    "                                       decoder_inputs, decoder_masks, bucket_id, False)\n",
    "            total_loss += step_loss\n",
    "            iteration += 1\n",
    "            if iteration % skip_step == 0:  \n",
    "                print_loss_avg = total_loss / skip_step\n",
    "                total_loss = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, step / n_iters),\n",
    "                                         iteration, step / n_iters * 100, print_loss_avg))\n",
    "                total_loss = 0\n",
    "                loss_print.append(step_loss)\n",
    "        saver.save(sess, os.path.join(config.CPT_PATH_40_3, 'chatbot'), global_step=model.global_step)\n",
    "        sys.stdout.flush()\n",
    "        plt.plot(loss_print)\n",
    "        plt.show()\n",
    "\n",
    "def _get_user_input():\n",
    "    t = input('Vous:  ')\n",
    "    return t\n",
    "\n",
    "def _construct_reponse(output_logits, dec_vocab):\n",
    "    outputs = [int(np.argmax(logit, axis=1)) for logit in output_logits]\n",
    "    if config.EOS_ID in outputs:\n",
    "        outputs = outputs[:outputs.index(config.EOS_ID)]\n",
    "\n",
    "    return \" \".join([tf.compat.as_str(dec_vocab[output]) for output in outputs])\n",
    "\n",
    "def chat():\n",
    "    _, enc_vocab = data.load_vocab(os.path.join(config.PROCESSED_PATH, 'encoder_vocab.txt'))\n",
    "    inv_dec_vocab, _= data.load_vocab(os.path.join(config.PROCESSED_PATH, 'decoder_vocab.txt'))\n",
    "    tf.reset_default_graph() \n",
    "    model = ChatBotModel(True, batch_size=1)\n",
    "    model.build_graph()\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        _check_restore_parameters(sess, saver)\n",
    "        output_file = open(os.path.join(config.PROCESSED_PATH, config.OUTPUT_FILE), 'a+')\n",
    "        max_length = config.BUCKETS[-1][0]\n",
    "        print('Bonjour, dites moi ce que vous voulez: ')\n",
    "        while True:\n",
    "            line = _get_user_input()\n",
    "            if len(line) > 0 and line[-1] == '\\n':\n",
    "                line = line[:-1]\n",
    "            if line == '':\n",
    "                break\n",
    "            output_file.write('VOUS ++++ ' + line + '\\n')\n",
    "            token_ids = data.sentence2id(enc_vocab, str(line))\n",
    "            if (len(token_ids) > max_length):\n",
    "                print('La longueur maximale est:', max_length)\n",
    "                continue\n",
    "            bucket_id = _find_right_bucket(len(token_ids))\n",
    "            encoder_inputs, decoder_inputs, decoder_masks = data.get_batch([(token_ids, [])], \n",
    "                                                                            bucket_id,\n",
    "                                                                            batch_size=1)\n",
    "            _, _, output_logits = run_step(sess, model, encoder_inputs, decoder_inputs,\n",
    "                                           decoder_masks, bucket_id, True)\n",
    "            response = _construct_reponse(output_logits, dec_vocab)\n",
    "            \n",
    "            print('Bot de AVICEN:  ', response)\n",
    "            output_file.write('BOT ++++ ' + response + '\\n')\n",
    "        output_file.write('=============================================\\n')\n",
    "        output_file.close()\n",
    "        \n",
    "def evaluate_randomly(n_iters=30, test=True):\n",
    "    if not test:\n",
    "        tf.reset_default_graph() \n",
    "        model = ChatBotModel(True, batch_size=1)\n",
    "        model.build_graph()\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            _check_restore_parameters(sess, saver)\n",
    "            for i in range(n_iters):\n",
    "                random_index = random.choice(range(len(training_data)))\n",
    "                bucket_id = 0  \n",
    "                question = training_data[random_index][0]\n",
    "                answer = training_data[random_index][1]\n",
    "                encoder_inputs, decoder_inputs, decoder_masks = \\\n",
    "                    data.get_batch([(question, [])], \\\n",
    "                    bucket_id, batch_size=1)\n",
    "                _, _, output_logits = run_step(sess, model, encoder_inputs, decoder_inputs,\n",
    "                                           decoder_masks, bucket_id, True)\n",
    "                reponse = _construct_reponse(output_logits, dec_vocab)\n",
    "                bonne_reponse = \" \".join([str(dec_vocab[id]) for id in answer])\n",
    "                question = \" \".join([str(enc_vocab[id]) for id in question])\n",
    "                print('--------------------------------------------------')\n",
    "                print('Question:  ',  question)\n",
    "                print('Bot     :  ', reponse)\n",
    "                print('Réponse : ', bonne_reponse)\n",
    "    else:\n",
    "        tf.reset_default_graph() \n",
    "        model = ChatBotModel(True, batch_size=1)\n",
    "        model.build_graph()\n",
    "        saver = tf.train.Saver()\n",
    "        total_loss = 0\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            _check_restore_parameters(sess, saver)\n",
    "            n_iters = len(test_data)\n",
    "            print_random_index = random.sample(range(n_iters), 20)\n",
    "            bucket_id = 0\n",
    "            for i in range(n_iters):\n",
    "                question = test_data[i][0]\n",
    "                answer = test_data[i][1]\n",
    "                encoder_inputs, decoder_inputs, decoder_masks = data.get_batch([(question, [])], \n",
    "                                                                            bucket_id,\n",
    "                                                                            batch_size=1)\n",
    "                _, _, output_logits = run_step(sess, model, encoder_inputs, decoder_inputs,\n",
    "                                           decoder_masks, bucket_id, True)\n",
    "                reponse = _construct_reponse(output_logits, dec_vocab)\n",
    "                bonne_reponse = \" \".join([str(dec_vocab[id]) for id in answer[1:-1]])\n",
    "                loss = _evaluate_by_right_word(reponse, bonne_reponse)\n",
    "                total_loss +=loss\n",
    "                if i in print_random_index:\n",
    "                    question = \" \".join([str(enc_vocab[id]) for id in question])\n",
    "                    print('Question: ', question)\n",
    "                    print('Reponse: ', reponse)\n",
    "                    print('Bonne Reponse: {}. ACCURACY {:.1f} '.format(bonne_reponse,1-loss))\n",
    "                    print('-'*50)\n",
    "        print('Test on {} sentences'.format(n_iters))\n",
    "        print('Accuracy by percent of true words {}'.format(1-total_loss/n_iters))\n",
    "        #return loss/n_iters\n",
    "\n",
    "def _evaluate_by_right_word(reponse, bonne_reponse):\n",
    "    reponse = reponse.split()\n",
    "    bonne_reponse = bonne_reponse.split()\n",
    "    min_length = min(len(reponse), len(bonne_reponse))\n",
    "    max_length = max(len(reponse), len(bonne_reponse))\n",
    "    error = max_length-min_length\n",
    "    for i in range(min_length):\n",
    "        if reponse[i] != bonne_reponse[i]:\n",
    "            error +=1\n",
    "    return error/max_length\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    try:\n",
    "        training_data\n",
    "    except NameError:\n",
    "        enc_vocab, dec_vocab, inv_enc_vocab, inv_dec_vocab = data.build_vocab()\n",
    "        training_data = _get_data(True)\n",
    "        test_data = _get_data(False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize new model\n",
      "Create placeholders\n",
      "Create inference\n",
      "Creating loss... \n",
      "It might take a couple of minutes depending on how many buckets you have.\n",
      "Time: 1.865391492843628\n",
      "Create optimizer... \n",
      "It might take a couple of minutes depending on how many data  you have.\n",
      "Running session\n",
      "Loading parameters for the Chatbot\n",
      "INFO:tensorflow:Restoring parameters from checkpoints_40_2/chatbot-43000\n",
      "5m 9s (- 46m 25s) (44000 10%) 2.4733\n",
      "9m 17s (- 37m 8s) (45000 20%) 0.5687\n",
      "13m 3s (- 30m 27s) (46000 30%) 0.1347\n",
      "15m 41s (- 23m 32s) (47000 40%) 0.0397\n",
      "17m 45s (- 17m 45s) (48000 50%) 0.2087\n",
      "21m 9s (- 14m 6s) (49000 60%) 0.0202\n",
      "27m 46s (- 11m 54s) (50000 70%) 0.0135\n"
     ]
    }
   ],
   "source": [
    "train(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize new model\n",
      "Create placeholders\n",
      "Create inference\n",
      "Creating loss... \n",
      "It might take a couple of minutes depending on how many buckets you have.\n",
      "Time: 1.8949811458587646\n",
      "Create optimizer... \n",
      "It might take a couple of minutes depending on how many data  you have.\n",
      "Loading parameters for the Chatbot\n",
      "INFO:tensorflow:Restoring parameters from checkpoints_40_2/chatbot-43000\n",
      "--------------------------------------------------\n",
      "Question:   avons-nous des véhicules à l'étranger\n",
      "Bot     :   partagée il les les cela virement vision il définie entre il #list_vin_immediat# il vision #user# il\n",
      "Réponse :  je vérifie cela tout de suite\n",
      "--------------------------------------------------\n",
      "Question:   j'ai fais un remplacement de véhicule\n",
      "Bot     :   consommation cela virement il communiqué vérifie vérifie il communiqué vérifie vérifie il communiqué vérifie vérifie il\n",
      "Réponse :  il faut mettre à jour la base de données véhicules\n",
      "--------------------------------------------------\n",
      "Question:   je veux comparer le taux d'émissions polluantes\n",
      "Bot     :   lien rejoint lien embarquée fournisseur préciser préciser il vision fournisseur embarquée fournisseur embarquée traiter fournisseur embarquée\n",
      "Réponse :  génial découvrez notre module rde ou real driving emissions\n",
      "--------------------------------------------------\n",
      "Question:   avons-nous le carnet d'entretien\n",
      "Bot     :   facture certaines disposez social disposez faut moyens moyens disposez vers faut définie moyens chiffres vers disposez\n",
      "Réponse :  oui\n",
      "--------------------------------------------------\n",
      "Question:   combien de voitures avons-nous\n",
      "Bot     :   entendu vérifie envoyée il quelle envoyée il polluantes moyens envoyée il polluantes il entendu il polluantes\n",
      "Réponse :  le parc est composé de #nb_veh#\n",
      "--------------------------------------------------\n",
      "Question:   je veux réduire la pollution\n",
      "Bot     :   choisi disponible expérience cela #list_vin_afternoon# exhaustive des dédié expérience il vision exhaustive embarquée embarquée accédez il\n",
      "Réponse :  pour bien faire découvrez notre module rde ou real driving emissions\n",
      "--------------------------------------------------\n",
      "Question:   comment tu t'appelles\n",
      "Bot     :   espace moyens partagée disposition il retrouvez plusieurs il définie moyens #nb_vehicule# plusieurs il définie accédez il\n",
      "Réponse :  je suis un bot de avicen tu peux m'appeler charlie\n",
      "--------------------------------------------------\n",
      "Question:   quelle est ta date de naissance\n",
      "Bot     :   par moyens embarquée moyens moyens par moyens moyens gestion moyens faut prévenir moyens gestion faut définie\n",
      "Réponse :  peut on parler d’autre sujets\n",
      "--------------------------------------------------\n",
      "Question:   combien de véhicules sont immobilisés\n",
      "Bot     :   définie #tel_comptabilite# équipe modifier définie #tel_comptabilite# faut #tel_comptabilite# faut #list_vin_immediat# #tel_comptabilite# faut définie faut #list_vin_immediat# faut\n",
      "Réponse :  ce véhicule #vin# semble immobilisé\n",
      "--------------------------------------------------\n",
      "Question:   bonjour mademoiselle\n",
      "Bot     :   facture arrêtés arrêtés arrêtés disposez faut #date_last_formation# faut non cela il rejoint cela il rejoint cela\n",
      "Réponse :  bonjour\n",
      "--------------------------------------------------\n",
      "Question:   à quelle vitesse roule ce véhicule\n",
      "Bot     :   #kpi# il modifier définie virement virement pneu virement définie virement son il définie par il virement\n",
      "Réponse :  la vitesse de ce véhicule est #vitesse#\n",
      "--------------------------------------------------\n",
      "Question:   je peux avoir un véhicule\n",
      "Bot     :   le dehors le plusieurs par il communiqué entre vérifie entre plusieurs plusieurs vérifie vérifie plusieurs plusieurs\n",
      "Réponse :  ok sous quel délai\n",
      "--------------------------------------------------\n",
      "Question:   as-t-il son permis de conduire\n",
      "Bot     :   vigilants il selon visiter approximative vers bien moyens #list_vin_immediat# il faut entendu visiter cordialement zone entendu\n",
      "Réponse :  les permis de vos collaborateurs sont disponibles dans le coffre-fort administratif\n",
      "--------------------------------------------------\n",
      "Question:   y'a-t-il des véhicules à l'arrêt\n",
      "Bot     :   définie #tel_comptabilite# modifier définie par il virement définie #tel_comptabilite# il management cela cela il #user# cela\n",
      "Réponse :  ce véhicule #vin# semble immobilisé\n",
      "--------------------------------------------------\n",
      "Question:   bonjour\n",
      "Bot     :   connu #trajet# #trajet# disposition il bancaire traffic plusieurs il plusieurs #nb_vehicule# embarquée #nb_vehicule# cela il proche\n",
      "Réponse :  bonjour\n",
      "--------------------------------------------------\n",
      "Question:   dernière révision\n",
      "Bot     :   moyens #vin# disposez par social faut retrouvez entre cela question faut retrouvez envoyée il choisi #date_debut_contrat#\n",
      "Réponse :  #date_last_entretien#\n",
      "--------------------------------------------------\n",
      "Question:   je veux trouver un véhicule le plus proche\n",
      "Bot     :   définie votre jour par il définie roulent il définie roulent il définie roulent il définie zone\n",
      "Réponse :  le véhicule plus proche est de #vin_proxi#\n",
      "--------------------------------------------------\n",
      "Question:   je veux mes contrat\n",
      "Bot     :   vers expérience moyens moyens vérifie des définie moyens vérifie vérifie approximative il #list_vin_immediat# vérifie bien moyens\n",
      "Réponse :  pouvez-vous préciser votre demande\n",
      "--------------------------------------------------\n",
      "Question:   + des véhicules à l'étranger\n",
      "Bot     :   il votre lundi virement virement plusieurs bien il définie série communiqué il définie virement liste il\n",
      "Réponse :  #oui/non#\n",
      "--------------------------------------------------\n",
      "Question:   quels sont des problèmes\n",
      "Bot     :   je disposez expérience il embarquée facture des des des vérifie des embarquée des je des embarquée\n",
      "Réponse :  la liste des problèmes vous sont notifiés en page d'administration\n",
      "--------------------------------------------------\n",
      "Question:   je veux comparer la distance parcouru par un véhicule\n",
      "Bot     :   consommation y par lien embarquée constructeurs constructeurs par il prévenir penser #kpi# virement prévenir #kpi# zone\n",
      "Réponse :  je recherche l'information\n",
      "--------------------------------------------------\n",
      "Question:   je suis indécise\n",
      "Bot     :   tardez #kpi_conduite# disposez moyens il définie par moyens bien faut proche pneus question faut définie pneus\n",
      "Réponse :  convenons d'un échange téléphonique quelle date vous conviendrait le mieux\n",
      "--------------------------------------------------\n",
      "Question:   peut-on convenir d'un rendez-vous\n",
      "Bot     :   tardez #kpi_conduite# disposez disposez faut proche cela faut d'une cela faut définie par facture il tardez\n",
      "Réponse :  oui quelle date vous conviendrait\n",
      "--------------------------------------------------\n",
      "Question:   je peux avoir des renseignements\n",
      "Bot     :   bancaire lancée choisir disposez choisir il retrouvez expérience il configurer configurer configurer configurer configurer configurer configurer\n",
      "Réponse :  bonjour je m'appelle emmet comment puis-je vous aider\n",
      "--------------------------------------------------\n",
      "Question:   il y a des problèmes\n",
      "Bot     :   qui y le il communiqué embarquée disposition disposez il #list_vin_immediat# embarquée facture fournisseur disposez il #list_vin_immediat#\n",
      "Réponse :  #oui/non#\n",
      "--------------------------------------------------\n",
      "Question:   la puissance de ce véhicule est-elle adaptée pour faire la mission\n",
      "Bot     :   modifier définie #tel_comptabilite# roulent cela virement il virement #list_vin_free# zone #list_vin_free# par virement il #list_vin_free# virement\n",
      "Réponse :  oui ce véhicule semble adapté à la réalisation de la mission\n",
      "--------------------------------------------------\n",
      "Question:   tco de la flotte\n",
      "Bot     :   il #tx_dispo# fiche des dédié #tx_dispo# carnet vérifie il forte par #list_vin_afternoon# modifier définie pour bien\n",
      "Réponse :  #tco_fleet#\n",
      "--------------------------------------------------\n",
      "Question:   bonjour monsieur\n",
      "Bot     :   #trajet# sont #trajet# disposez cela social plusieurs plusieurs faut l'écran faut retrouvez cela social plusieurs faut\n",
      "Réponse :  j'en #nb_véhicules# prends note plus voici pros procédure\n",
      "--------------------------------------------------\n",
      "Question:   le carburant est il adapté au véhicule\n",
      "Bot     :   définie virement dont aider virement virement zone définie zone définie aider il définie bien moyens il\n",
      "Réponse :  #oui/non#\n",
      "--------------------------------------------------\n",
      "Question:   est-ce que la voiture a été\n",
      "Bot     :   bancaire espace plusieurs embarquée pneu plusieurs plusieurs plusieurs plusieurs plusieurs virement plusieurs plusieurs embarquée plusieurs entre\n",
      "Réponse :  de je suis peux t’aider en moyenne\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly(30, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['est-ce-que', 'tout', 'va', 'bien']     ['ça', 'va', 'et', 'toi']\n"
     ]
    }
   ],
   "source": [
    "idx = random.sample(range(len(training_data)), 1)\n",
    "data1 = training_data[idx[0]]\n",
    "question =  [enc_vocab[ix] for ix in data1[0]]\n",
    "answer = [dec_vocab[ix] for ix in data1[1]]\n",
    "print(question, '   ', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quel', 'est', 'le', 'contexte', 'routier']     ['quelle', 'est', 'la', 'zone', 'géographique', 'visée']\n"
     ]
    }
   ],
   "source": [
    "#DATA = data.load_data('train_question.txt', 'train_answer.txt', inv_enc_vocab, inv_dec_vocab)\n",
    "idx = random.sample(range(len(training_data)), 1)\n",
    "data1 = DATA[idx[0]]\n",
    "question =  [enc_vocab[ix] for ix in data1[0]]\n",
    "answer = [dec_vocab[ix] for ix in data1[1]]\n",
    "print(question, '   ', answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
