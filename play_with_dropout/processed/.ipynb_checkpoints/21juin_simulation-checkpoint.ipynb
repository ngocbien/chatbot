{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stop_word = ['?', '.']\n",
    "def clearing_word(word):\n",
    "    word = re.sub('\\x8e', 'é', word)\n",
    "    word = re.sub('\\x88', 'à', word)\n",
    "    word = re.sub('\\x9d', 'ù', word)\n",
    "    word = re.sub('\\x8f', 'è', word)\n",
    "    word = re.sub('\\x9e', 'û', word)\n",
    "    word = re.sub('\\x90', 'ê', word)\n",
    "    word = re.sub('\\x99', 'ô', word)\n",
    "    word = re.sub('\\x94', 'î', word)\n",
    "   # word = re.sub('\\x8f', 'è', word)\n",
    "    word = re.sub('\\x8d', 'ç', word)\n",
    "    word = re.sub('õ', '', word)\n",
    "    word = re.sub('Ê', '', word)\n",
    "    word = re.sub('[?,.,!, \\,,  %]', '', word)\n",
    "    if word == 'û' or word == 'v' or word == 'é':\n",
    "        word = ''\n",
    "    if word ==\"2017êles\":\n",
    "        word = \"2017\"\n",
    "    if \"ênox\" in word:\n",
    "        word =\"nox\"\n",
    "    return word\n",
    "\n",
    "def clearing(pharse):\n",
    "    \"\"\"\n",
    "    Arg: Data is a list of questions or answers\n",
    "    Return: clean questions et answers \n",
    "    \"\"\"\n",
    "    #clean_data = []\n",
    "    pharses =[]\n",
    "    for word in pharse.strip().lower().split(' '):\n",
    "       # line= data[i].lower().split(' ')        \n",
    "        #for word in line:\n",
    "        word = clearing_word(word)\n",
    "        if word not in stop_word and len(word) !=0:       \n",
    "            pharses.append(word)        \n",
    "    return ' '.join(pharses)\n",
    "\n",
    "\n",
    "\n",
    "def get_all_convos():\n",
    "    convos = []\n",
    "    file2 = 'chatbot_tout_corpus_13juin.txt'\n",
    "    liste_file = [ file2]\n",
    "    for file in liste_file:\n",
    "        with open(file) as f:\n",
    "            i=0\n",
    "            for line in f:\n",
    "                if i%2==0:\n",
    "                    question = clearing(line)\n",
    "                    if '++++' in question:\n",
    "                         question = question[9:]\n",
    "                else:\n",
    "                    answer = clearing(line)\n",
    "                    if '++++' in answer:\n",
    "                        answer = answer[9:]\n",
    "                    convos.append([question, answer])\n",
    "                i+=1\n",
    "        f.close()\n",
    "    return convos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 641 sentence pairs of training set\n",
      "Read 161 sentence pairs of test set\n",
      "Counted words:\n",
      "question 275\n",
      "answer 203\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cet technique marche beaucoup mieux que dans tensorflow, avec en très peu de temps. \n",
    "Ce modèle fonctionne mieux que l'autre dans tensorflow parce qu'une raison évidente: \n",
    "il utilise méthode teacher forcing Un autre problème avec ce méthode, \n",
    "c'est dropout qui donne une technique plus ou moins bon. Il donne la \n",
    "réponse plus tôt aléatoire pour une question. En cas général, \n",
    "ce la peut être intéressant, mais dans notre cas, il est très important \n",
    "qu'il capture le mot clés \n",
    "(donc, surtout on risque de supprimer le mot clés, qui rendra une mauvais réponse)\n",
    "modèle est bien entrainé, donc, il ne sert à rien d'entrainer encore.\n",
    "hidden_size =45 tres mauvais; =70 bien; =100 tres bien; =120 très bien; =150 overfit.\n",
    "hidden_size 50 20%\n",
    "hidden_size 70 33%\n",
    "hidden_size 120 28%\n",
    "\"\"\"\n",
    "#from IPython.display import display, Markdown\n",
    "#display(Markdown(\"### Pour lancer un chat, il suffit de taper en même temps CTRL et ENTER\"))\n",
    "#display(Markdown(\"### Pour arrêter le mode chat, il suffit de taper ENTER dans votre conversation\"))\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import data\n",
    "import config\n",
    "import time\n",
    "from dateparser.search import search_dates\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "hidden_size = 20\n",
    "SOS_token  = config.SOS_token\n",
    "EOS_token  = config.EOS_token\n",
    "MAX_LENGTH = config.MAX_LENGTH\n",
    "stopwords  = config.STOPWORDS\n",
    "learning_rate = config.LEARNING_RATE\n",
    "teacher_forcing_ratio = 0.2\n",
    "dropout = config.DROPOUT\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  \n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "def normalizeString(s):\n",
    "    \"\"\"\n",
    "    Whith a tring s, we make it in lower case, delete \\n if exists at \n",
    "    the end of string, and delete specical case ? . and !\n",
    "    \"\"\"\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([,.!?\\n])\", r\"\", s)# sumprimer tous les caractères .! et ?\n",
    "    #s = re.sub(r\"[^a-zA-Z0-9.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs():\n",
    "    print(\"Reading lines...\")\n",
    "    pairs_trains, pairs_tests = [], []   \n",
    "    encode_train = open(os.path.join(config.PROCESSED_PATH, \"question_train.txt\"), 'r')\n",
    "    decode_train = open(os.path.join(config.PROCESSED_PATH, \"answer_train.txt\"), 'r')\n",
    "    encode, decode = encode_train.readline(), decode_train.readline()\n",
    "    while encode and decode:\n",
    "        encode, decode = normalizeString(encode), normalizeString(decode)\n",
    "        decode = 'SOS '+ decode + ' EOS'\n",
    "        pairs_trains.append([encode, decode])\n",
    "        encode, decode = encode_train.readline(), decode_train.readline()\n",
    "    encode_train.close()\n",
    "    decode_train.close()\n",
    "    encode_test = open(os.path.join(config.PROCESSED_PATH, \"question_test.txt\"), 'r')\n",
    "    decode_test = open(os.path.join(config.PROCESSED_PATH, \"answer_test.txt\"), 'r')\n",
    "    encode, decode = encode_test.readline(), decode_test.readline()\n",
    "    while encode and decode:\n",
    "        encode, decode = normalizeString(encode), normalizeString(decode)\n",
    "        decode = 'SOS '+ decode + ' EOS'\n",
    "        pairs_tests.append([encode, decode])\n",
    "        encode, decode = encode_test.readline(), decode_test.readline()\n",
    "    encode_test.close()\n",
    "    decode_test.close()\n",
    "    return pairs_trains, pairs_tests\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH \n",
    "\n",
    "    \n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(pairs1, PAIRS):\n",
    "    input_lang = Lang('question')\n",
    "    output_lang = Lang( 'answer')\n",
    "    pairs_trains, pairs_tests = [], []\n",
    "    PAIRS.extend(pairs1)\n",
    "    index_train = random.sample(range(len(PAIRS)), int(len(PAIRS)*0.80))\n",
    "    for i in range(len(PAIRS)):\n",
    "        if i in index_train:\n",
    "            pairs_trains.append(PAIRS[i])\n",
    "        else:\n",
    "            pairs_tests.append(PAIRS[i])\n",
    "    print(\"Read %s sentence pairs of training set\" % len(pairs_trains))\n",
    "    print(\"Read %s sentence pairs of test set\" % len(pairs_tests))\n",
    "    pairs_trains = filterPairs(pairs_trains)\n",
    "    pairs_tests = filterPairs(pairs_tests)\n",
    "    for i  in range(len(pairs_trains)) :\n",
    "        pair = pairs_trains[i]\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    \n",
    "    for i  in range(len(pairs_tests)) :\n",
    "        pair = pairs_tests[i]\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs_trains, pairs_tests\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "        \n",
    "def closetWord(word, lang):\n",
    "    \"\"\"\n",
    "    find and return the closest word in lang\n",
    "    \"\"\"\n",
    "    Dict = lang.word2index\n",
    "    corpus = lang.index2word\n",
    "    if word in Dict:\n",
    "        return word\n",
    "    else:\n",
    "        distance = levenshtein(word, corpus[0])\n",
    "        close_word = corpus[0]\n",
    "        for ix in corpus:\n",
    "            if levenshtein(word, corpus[ix]) <distance:\n",
    "                close_word = corpus[ix]\n",
    "                distance = levenshtein(word, corpus[ix])\n",
    "        if distance <=1:\n",
    "            return close_word\n",
    "        else:\n",
    "            return word\n",
    "        \n",
    "def normalizeSentenceInChat(sentence):\n",
    "    sentence = sentence.strip().lower().split()\n",
    "    s = [closetWord(word, input_lang) for word in sentence]\n",
    "    return ' '.join(s)\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    #sentence = normalizeSentence\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index ]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "def get_skip_step(n_iters):\n",
    "    return int(n_iters/10)\n",
    "\n",
    "def trainIters(n_iters, plot_every=100, learning_rate=learning_rate):\n",
    "    training_pairs = get_all_convos()\n",
    "    encoder, decoder = restore_model()\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    skip_step = get_skip_step(n_iters)\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs_trains))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % skip_step == 0:\n",
    "            print_loss_avg = print_loss_total / skip_step\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    save_model(encoder, decoder)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    #sentence = normalizeSentenceInChat(sentence)\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  \n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        ni = int(ni)\n",
    "        if ni == EOS_token:\n",
    "            #decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluate_randomly(n_iters=200, test=True):\n",
    "    encoder, decoder = restore_model()\n",
    "    if not test:\n",
    "        print('TEST error of word to word on TRAIN')\n",
    "        list_print_random = random.sample(range(n_iters),20 )\n",
    "        total_loss = 0\n",
    "        for i in range(n_iters):\n",
    "            pair = random.choice(pairs_trains)\n",
    "            output_words = evaluate(encoder, decoder, pair[0])\n",
    "            if 'EOS' in output_words:\n",
    "                l = output_words.index('EOS')+1\n",
    "            else:\n",
    "                l = len(output_words)+1\n",
    "            reponse = ' '.join(output_words[:l])\n",
    "            loss = _evaluate_by_right_word(pair[1], reponse)\n",
    "            total_loss +=loss\n",
    "            if i in list_print_random:\n",
    "                #answer = answers_with_data(pair[0], reponse)\n",
    "                print('Question: ', pair[0])\n",
    "                print('Réponse: ', pair[1])\n",
    "                print('Bot: {}   ACCURACY {:.1f}'.format(reponse, 1-loss))\n",
    "                #if answer != reponse:\n",
    "                 #   print('Réponse avec data:', answer)\n",
    "                \n",
    "                print('-'*50)\n",
    "        print('Accuracy of good answer word to word: ', 1-total_loss/n_iters)\n",
    "    else:\n",
    "        n_iters = len(pairs_tests)\n",
    "        total_loss = 0\n",
    "        random_print_index = random.sample(range(n_iters), 20)\n",
    "        for i in range(n_iters):\n",
    "            pair = pairs_tests[i]\n",
    "            output_words= evaluate(encoder, decoder, pair[0])\n",
    "            if 'EOS' in output_words:\n",
    "                l = output_words.index('EOS')+1\n",
    "            else:\n",
    "                l = len(output_words)+1\n",
    "            reponse = ' '.join(output_words[:l])\n",
    "            loss = _evaluate_by_right_word(pair[1], reponse)\n",
    "            if i in random_print_index:\n",
    "                print('Question: ', pair[0])\n",
    "                print('Réponse: ', pair[1])\n",
    "                print('Bot: {}. ACCURACY {:.1f}'.format(reponse, 1-loss))\n",
    "                print('-'*50)\n",
    "            total_loss +=loss\n",
    "        print('Test on {}'.format(n_iters))\n",
    "        print('Accuracy by percent of true words {}'.format(1-total_loss/n_iters))\n",
    " \n",
    "\n",
    "KEYWORD_TO_FUNCTION_DICT = {'#id#':'ID Véhicule','#km#':'Distance', '#check_batterie#':'Tension Batterie',\\\n",
    "                            '#vitesse#':'Vitesse Moyenne'}\n",
    "\n",
    "def answers_with_data(question, answer):\n",
    "    data = analyse_reponse(question, answer)\n",
    "    if data is None:\n",
    "        return answer\n",
    "    else:\n",
    "        index = 0\n",
    "        for word in answer.split():\n",
    "            if \"#\" in word:\n",
    "                try:\n",
    "                    good_answer = re.sub(word, str(data[index]), answer)\n",
    "                except IndexError:\n",
    "                    break\n",
    "                index +=1\n",
    "        return good_answer\n",
    "    \n",
    "                \n",
    "def analyse_reponse(question, answer):\n",
    "    \"\"\"\n",
    "    arg: question is the question of user, reponse is given by chatbot\n",
    "\n",
    "    \"\"\"\n",
    "    if '#' not in answer:\n",
    "        return None\n",
    "    else:\n",
    "        parameter = []\n",
    "        for key in KEYWORD_TO_FUNCTION_DICT:\n",
    "            if key in answer.split():\n",
    "                parameter.append(key)\n",
    "        times = find_right_time(question)\n",
    "        variables = _get_variable(answer)\n",
    "        data = []\n",
    "        if len(variables)==0:\n",
    "            return None\n",
    "        else:\n",
    "            ids = find_ids(question)\n",
    "            for variable in variables:\n",
    "                data.append(_get_data_from_table(ids, variable, times))\n",
    "            return data\n",
    "            \n",
    "                \n",
    "def find_right_time(question):\n",
    "    \"\"\"\n",
    "    cette fonction retourne période de temps dans la question\"\"\"\n",
    "    dictionnary = {'cette':'1', 'ce':'1', \"dernier\": '1',\"dernière\": '1' }\n",
    "    for word in dictionnary:\n",
    "        question = re.sub(word, dictionnary[word], question)\n",
    "    end_time = time.time()\n",
    "    try:\n",
    "         t = search_dates(question)\n",
    "    except ZeroDivisionError:\n",
    "        return None, None\n",
    "    if t == None:\n",
    "        return None, None\n",
    "    \n",
    "    else:\n",
    "        if len(t)>=2:\n",
    "        \n",
    "            t0 = t[0][-1]\n",
    "            start_time = time.mktime(t0.timetuple())\n",
    "                \n",
    "            t1 = t[-1][-1]\n",
    "            end_time = time.mktime(t1.timetuple())\n",
    "        if len(t)==1:\n",
    "            t = t[0][1]\n",
    "            start_time = time.mktime(t.timetuple())\n",
    "    #start_time, end_time = find_good_time_in_table(start_time, end_time)\n",
    "    return start_time, end_time\n",
    "    \n",
    "\n",
    "def _get_variable(reponse):\n",
    "    list_variable =[]\n",
    "    for word in reponse.split():\n",
    "        if \"#\" in word:\n",
    "            list_variable.append(word)\n",
    "    #if variable in KEYWORD_TO_FUNCTION_DICT:\n",
    "    return [KEYWORD_TO_FUNCTION_DICT[variable] for variable in list_variable\n",
    "               if variable in KEYWORD_TO_FUNCTION_DICT]\n",
    "\n",
    "    \n",
    "def _get_data_from_table(ids, variable, time):\n",
    "    \"\"\"\n",
    "    temps est un couple de début et fin\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('fleet_donnees.csv', sep = ';')\n",
    "    #time1 = string_to_datetime(time[0])\n",
    "    #time2 = string_to_datetime(time[1])\n",
    "    if variable is None:\n",
    "        return \"#TO_CONSTRUCT#\"\n",
    "    if variable =='Tension Batterie':\n",
    "        return min(df['Tension Batterie'])\n",
    "    time1 = time[0]\n",
    "    time2 = time[1]\n",
    "    if time1 is None:\n",
    "        time1 = string_to_datetime(df.iloc[0]['Debut période'])\n",
    "    if time2 is None:\n",
    "        time2 = string_to_datetime(df.iloc[len(df)-1]['Fin Période'])\n",
    "    if ids is not None:\n",
    "        try:\n",
    "            df = df.loc[(df['ID Véhicule'] ==  int(ids))] \n",
    "        except ValueError:\n",
    "            pass\n",
    "    List = []\n",
    "    for i in range(len(df)):\n",
    "        if string_to_datetime(df.iloc[i]['Debut période']) >=time1 and \\\n",
    "           string_to_datetime(df.iloc[i]['Fin Période'])<=time2:\n",
    "                List.append(i)\n",
    "\n",
    "    list_data_to_return = df.iloc[List][variable]\n",
    "    if len(list_data_to_return)>1:\n",
    "        t = sum(list_string_to_float(list_data_to_return))/len(list_data_to_return)\n",
    "    else:\n",
    "        t= list_data_to_return\n",
    "    \n",
    "   # try:\n",
    "       # t=sum(list_data_to_return.values[0])/len(list_to_return.values[0])\n",
    "   # except AttributeError or IndexError:\n",
    "   # t = sum(list_data_to_return)/len(list_data_to_return)\n",
    "    return t\n",
    "        \n",
    "          \n",
    "def find_ids(question):\n",
    "    if 'tous' in question or 'toutes' in question or 'tout'in question or 'toute' in question:\n",
    "        return None\n",
    "    return None\n",
    "    #else:\n",
    "     #   print('La liste de ID des voitures:')\n",
    "      #  imprimer_id()\n",
    "       # return str(input('indiquez l\\'identifiant de ce véhicule:'))\n",
    "    \n",
    "\n",
    "def string_to_datetime(string):\n",
    "    t = search_dates(string)\n",
    "    t = t[0][1]\n",
    "    t = time.mktime(t.timetuple())\n",
    "    return t\n",
    "\n",
    "def list_string_to_float(List_string):\n",
    "    List = []\n",
    "    for string in List_string:\n",
    "        if type(string)==str:\n",
    "            string = re.sub(',', '.', string)\n",
    "        else:\n",
    "            pass\n",
    "        string2float  = float(string)\n",
    "        List.append(string2float)\n",
    "    return List\n",
    "    \n",
    "def find_good_time_in_table(begin_time, end_time):\n",
    "    \"\"\"\n",
    "    begin_time and end_time is in float type\n",
    "    return right begin_time and end_time in table\"\"\"   \n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('fleet_donnees.csv', sep = ';')\n",
    "    start_time_colone = df['Debut période']\n",
    "    end_time_colone = df['Fin Période']\n",
    "    start_time_table = []\n",
    "    for i in start_time_colone:\n",
    "        time,_=find_right_time(i)\n",
    "        start_time_table.append(time)\n",
    "    end_time_table = []\n",
    "    for i in fin_time_colone:\n",
    "        time, _ = find_right_time(i)\n",
    "        end_time_table.append(time)\n",
    "    start = start_time_table[-1]\n",
    "    for i in start_time_table:\n",
    "        if begin_time <= i:\n",
    "            start = i\n",
    "            break\n",
    "    end = end_time_table[-1]\n",
    "    for i in end_time_table:\n",
    "        if end <=i:\n",
    "            end = i\n",
    "            break\n",
    "    #start = start_time_table[start_time_table==start].index[0]\n",
    "    #end = fin_time_table[fin_time_table==end].index[0]\n",
    "    start = start_time_table.index(start)\n",
    "    end =  end_time_table.index(end)\n",
    "    start = start_time_colone[start]\n",
    "    end = _time_colone[end]\n",
    "    return start, end    \n",
    "    \n",
    "    \n",
    "def _evaluate_by_right_word(reponse, bonne_reponse):\n",
    "    reponse = reponse.split()\n",
    "    bonne_reponse = bonne_reponse.split()\n",
    "    min_length = min(len(reponse), len(bonne_reponse))\n",
    "    max_length = max(len(reponse), len(bonne_reponse))\n",
    "    error = max_length-min_length\n",
    "    for i in range(min_length):\n",
    "        if reponse[i] != bonne_reponse[i]:\n",
    "            error +=1\n",
    "    return error/max_length      \n",
    "        \n",
    "def make_dir(path):\n",
    "    \"\"\" Create a directory if there isn't one already. \"\"\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "def save_model(encoder, decoder):        \n",
    "    make_dir(config.CHECK_POINT_PATH)\n",
    "    path1= os.path.join(config.CHECK_POINT_PATH, 'encoder_simulation_2.ck')\n",
    "    path2 = os.path.join(config.CHECK_POINT_PATH, 'decoder_simulation_2.ck')\n",
    "    try: \n",
    "        os.remove(path1)  \n",
    "        os.remove(path2)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    torch.save(encoder,path1)\n",
    "    torch.save(decoder, path2)\n",
    "    \n",
    "memo = {}\n",
    "def levenshtein(s, t):\n",
    "    \"\"\"\n",
    "    Pour calculer la distance  Levenshtein entre 2 string s et t\n",
    "    \"\"\"\n",
    "    if s == \"\":\n",
    "        return len(t)\n",
    "    if t == \"\":\n",
    "        return len(s)\n",
    "    cost = 0 if s[-1] == t[-1] else 1\n",
    "       \n",
    "    i1 = (s[:-1], t)\n",
    "    if not i1 in memo:\n",
    "        memo[i1] = levenshtein(*i1)\n",
    "    i2 = (s, t[:-1])\n",
    "    if not i2 in memo:\n",
    "        memo[i2] = levenshtein(*i2)\n",
    "    i3 = (s[:-1], t[:-1])\n",
    "    if not i3 in memo:\n",
    "        memo[i3] = levenshtein(*i3)\n",
    "    res = min([memo[i1]+1, memo[i2]+1, memo[i3]+cost])\n",
    "    \n",
    "    return res\n",
    "    \n",
    "def restore_model():\n",
    "    #hidden_size = hidden_size\n",
    "    path1 = os.path.join(config.CHECK_POINT_PATH, 'encoder_simulation_2.ck')\n",
    "    path2 = os.path.join(config.CHECK_POINT_PATH, 'decoder_simulation_2.ck')\n",
    "    if os.path.exists(path1)and os.path.exists(path2):\n",
    "        print('Reading the parameters from {} and {}...'.format(path1, path2))\n",
    "        encoder = torch.load(path1)\n",
    "        decoder = torch.load(path2)\n",
    "    else:\n",
    "        print('Initializing fresh parameters...')\n",
    "        encoder = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "        decoder = DecoderRNN(hidden_size, output_lang.n_words,1)\n",
    "\n",
    "    if use_cuda:\n",
    "        encoder = encoder.cuda()\n",
    "        decoder = decoder.cuda()\n",
    "    return encoder, decoder \n",
    "\n",
    "def imprimer_id():\n",
    "    df = pd.read_csv('fleet_donnees.csv', sep = ';')   \n",
    "    df = df['ID Véhicule']\n",
    "    List_voiture = []\n",
    "    for i in df:\n",
    "        if i not in List_voiture:\n",
    "            List_voiture.append(i)\n",
    "    for i in List_voiture:\n",
    "        print(i, end='  ')\n",
    "\n",
    "def construct_dict(lang):\n",
    "    in_file = open(os.path.join(config.PROCESSED_PATH, 'dictionnary.txt'), 'r')\n",
    "    lines = []\n",
    "    dicts = lang.word2index.copy()\n",
    "    for line in in_file:\n",
    "        line = line.strip().split('|')\n",
    "        for word in dicts:\n",
    "            if str(word) in line and len(word)>0:\n",
    "                line.insert(0,str(word))\n",
    "                lines.append(line)\n",
    "                del dicts[str(word)]\n",
    "                break\n",
    "    return lines\n",
    "\n",
    "def find_close_line(lines, lang, line):\n",
    "    LINE = []\n",
    "    for word in line.strip().split():\n",
    "        if word in lang.word2index:\n",
    "            LINE.append(word)\n",
    "        else:\n",
    "            for pharse in lines:\n",
    "                if word in pharse:\n",
    "                    LINE.append(pharse[0])\n",
    "                    break\n",
    "    return ' '.join(LINE)\n",
    "\n",
    "def chat():\n",
    "    encoder, decoder = restore_model()\n",
    "    make_dir(config.CHECK_POINT_PATH)\n",
    "    lines = construct_dict(input_lang)\n",
    "    output_file = open(os.path.join(config.CHECK_POINT_PATH, 'convos70.txt'), 'a+')\n",
    "    print('Bonjour, c\\'est le Bot d\\'AVICEN, Je peux vous aider? \\n')\n",
    "    while True:\n",
    "            line = str(input('Vous: '))\n",
    "            if len(line) > 0 and line[-1] == '\\n':\n",
    "                line = line[:-1]\n",
    "            if line == '':\n",
    "                break\n",
    "            line = normalizeString(line)\n",
    "            transform_line  = normalizeSentenceInChat(line)\n",
    "            transform_line = find_close_line(lines, input_lang, transform_line)\n",
    "            print('LIGNE TRANFORMÉ: ', line)\n",
    "            output_file.write('VOUS ++++ ' + line + '\\n')\n",
    "            reponse = evaluate(encoder, decoder, transform_line)\n",
    "            if 'SOS' in reponse:\n",
    "                 reponse = reponse[1:] \n",
    "            if 'EOS' in reponse:\n",
    "                reponse = reponse[:-1] \n",
    "            reponse = \" \".join(reponse)\n",
    "            output_file.write('BOT ++++ ' + reponse + '\\n')\n",
    "            print('Without Data: ', reponse)\n",
    "            reponse = answers_with_data(line, reponse)\n",
    "            print('Bot AVICEN: ', reponse)\n",
    "            print('-'*50)\n",
    "    output_file.close() \n",
    "\n",
    "def test(pairs_test):\n",
    "    \"\"\"\n",
    "    Use test for know how our model is good\n",
    "    \"\"\"\n",
    "    encoder, decoder = restore_model()\n",
    "    total_loss = 0\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "    for pair in pairs_test:\n",
    "        variable = variablesFromPair(pair)\n",
    "        loss = train( variable[0], variable[1], encoder, decoder, encoder_optimizer, decoder_optimizer,\\\n",
    "                     criterion= criterion)\n",
    "        total_loss +=loss\n",
    "    Length_inputs = len(pairs_test) if len(pairs_test) !=0 else 1\n",
    "    return total_loss/Length_inputs\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################-----------------------\n",
    "import re\n",
    "stop_word = ['?', '.']\n",
    "def clearing_word(word):\n",
    "    word = re.sub('\\x8e', 'é', word)\n",
    "    word = re.sub('\\x88', 'à', word)\n",
    "    word = re.sub('\\x9d', 'ù', word)\n",
    "    word = re.sub('\\x8f', 'è', word)\n",
    "    word = re.sub('\\x9e', 'û', word)\n",
    "    word = re.sub('\\x90', 'ê', word)\n",
    "    word = re.sub('\\x99', 'ô', word)\n",
    "    word = re.sub('\\x94', 'î', word)\n",
    "   # word = re.sub('\\x8f', 'è', word)\n",
    "    word = re.sub('\\x8d', 'ç', word)\n",
    "    word = re.sub('õ', '', word)\n",
    "    word = re.sub('Ê', '', word)\n",
    "    word = re.sub('[?,.,!, \\,,  %]', '', word)\n",
    "    if word == 'û' or word == 'v' or word == 'é':\n",
    "        word = ''\n",
    "    if word ==\"2017êles\":\n",
    "        word = \"2017\"\n",
    "    if \"ênox\" in word:\n",
    "        word =\"nox\"\n",
    "    return word\n",
    "\n",
    "def clearing(pharse):\n",
    "    \"\"\"\n",
    "    Arg: Data is a list of questions or answers\n",
    "    Return: clean questions et answers \n",
    "    \"\"\"\n",
    "    #clean_data = []\n",
    "    pharses =[]\n",
    "    for word in pharse.strip().lower().split(' '):\n",
    "       # line= data[i].lower().split(' ')        \n",
    "        #for word in line:\n",
    "        word = clearing_word(word)\n",
    "        if word not in stop_word and len(word) !=0:       \n",
    "            pharses.append(word)        \n",
    "    return ' '.join(pharses)\n",
    "\n",
    "\n",
    "\n",
    "def get_all_convos():\n",
    "    convos = []\n",
    "    file2 = 'chatbot_tout_corpus_13juin.txt'\n",
    "    liste_file = [ file2]\n",
    "    for file in liste_file:\n",
    "        with open(file) as f:\n",
    "            i=0\n",
    "            for line in f:\n",
    "                if i%2==0:\n",
    "                    question = clearing(line)\n",
    "                    if '++++' in question:\n",
    "                         question = question[9:]\n",
    "                else:\n",
    "                    answer = clearing(line)\n",
    "                    if '++++' in answer:\n",
    "                        answer = answer[9:]\n",
    "                    convos.append([question, answer])\n",
    "                i+=1\n",
    "        f.close()\n",
    "    return convos\n",
    "\n",
    "DIRECT_VARIABLE = ['vitesse', 'batterie', 'position', 'km']\n",
    "TIME = []\n",
    "GEOGRAPHY = ['Lyon', 'hors lyon', 'paris', 'l\\'étranger','france' , 'hors la france']\n",
    "BORDE = {'MAX': ['plus grand', 'plus grande', 'plus grands', \n",
    "         'plus grandes',  'moin faible', 'moins faibles',\n",
    "         'plus vite', 'max', 'maximum', 'maximal', 'maximaux', 'maximale',\n",
    "        'plus haut', 'plus haute', 'plus hautes', 'plus hauts',  \n",
    "        'plus élevé', 'plus élevée', 'plus élevés', 'plus élevées'], \n",
    "         'MIN':['moins grand', 'moins grande', 'moins grands','moins grandes',\n",
    "        'plus petit', 'plus petite', 'plus petits', 'plus petites','plus faible', 'plus faibles', \n",
    "         'min', 'minimal', 'minimale', 'minimales', 'minimaux','moins vite', \n",
    "         'moins élevé', 'moins élevée', 'moins élevés', 'moins élevées'],\n",
    "        'MOYENNE': ['moyenne', 'moyen', 'moyennement']\n",
    "        }\n",
    "COMPLEX_ANALYSIS = ['problème', 'problèmes', 'erreurs', 'erreur', 'danger']\n",
    "PAIRS = []\n",
    "question_for_simulation = ['quels véhicules ont', 'quel véhicule', 'quelle voiture', 'quelles voitures']\n",
    "reponse_for_simulation = 'véhicule'\n",
    "for borde in BORDE:\n",
    "    for word in BORDE[borde]:\n",
    "        for direct_variable in DIRECT_VARIABLE:\n",
    "            for question_f_s in question_for_simulation:\n",
    "                if direct_variable !='position':\n",
    "                      question= question_f_s+' '+direct_variable + ' '+ word\n",
    "                      key0 = '#id#'\n",
    "                      key1 = '#'+direct_variable+'#'\n",
    "                      key2 = '#'+borde +'#'\n",
    "                      reponse = reponse_for_simulation +' '+key0+ ' '+ key1+ ' '+ key2\n",
    "                      PAIRS.append([question,reponse])\n",
    "\n",
    "question_for_simulation = ['', 'quel véhicule a', 'quelle voiture a', 'quelles voitures ont', 'il y a']\n",
    "reponse_for_simulation = 'véhicule' \n",
    "for direct_variable in DIRECT_VARIABLE:\n",
    "    for complex_analysis in COMPLEX_ANALYSIS:\n",
    "            for question_f_s in question_for_simulation:\n",
    "                #if direct_variable !='position':\n",
    "                      question= question_f_s+' '+complex_analysis + ' '+ direct_variable\n",
    "                      key0 = '#id#'\n",
    "                      key1 = '#'+direct_variable+'#'\n",
    "                      key2 = '#'+ complex_analysis +'#'\n",
    "                      reponse = reponse_for_simulation +' '+key0+ ' '+ key2 +' '+ key1\n",
    "                      PAIRS.append([question,reponse])\n",
    "\n",
    "if __name__=='__main__':\n",
    "    try:\n",
    "        input_lang\n",
    "    except NameError :\n",
    "        pairs1 = get_all_convos()\n",
    "        input_lang, output_lang, pairs_trains, pairs_tests = prepareData(pairs1, PAIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the parameters from check_point/encoder_simulation_2.ck and check_point/decoder_simulation_2.ck...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:299: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 35s (- 5m 23s) (10000 10%) 0.3544\n",
      "1m 10s (- 4m 43s) (20000 20%) 0.2661\n",
      "1m 46s (- 4m 8s) (30000 30%) 0.2088\n",
      "2m 21s (- 3m 32s) (40000 40%) 0.1591\n"
     ]
    }
   ],
   "source": [
    "trainIters(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gros bisous'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = construct_dict(input_lang)\n",
    "line = 'gros bisous'\n",
    "line = normalizeString(line)\n",
    "transform_line  = normalizeSentenceInChat(line)\n",
    "transform_line = find_close_line(lines, input_lang, transform_line)\n",
    "transform_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the parameters from check_point/encoder_simulation_2.ck and check_point/decoder_simulation_2.ck...\n",
      "TEST error of word to word on TRAIN\n",
      "Question:  quel véhicule batterie plus élevés\n",
      "Réponse:  véhicule #id# #batterie# #MAX#\n",
      "Bot: véhicule #id# #batterie# #MAX#   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quelle voiture batterie plus hauts\n",
      "Réponse:  véhicule #id# #batterie# #MAX#\n",
      "Bot: véhicule #id# #batterie# #MAX#   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quelle voiture km minimaux\n",
      "Réponse:  véhicule #id# #km# #MIN#\n",
      "Bot: véhicule #id# #km# #MIN#   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quels véhicules ont km plus hauts\n",
      "Réponse:  véhicule #id# #km# #MAX#\n",
      "Bot: véhicule #id# #km# #MAX#   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:   combien de véhicules hors périmètre\n",
      "Réponse:  il y a #nb_véhicules# en dehors de la zone définie\n",
      "Bot: il y a #nb_véhicules# en dehors de la zone définie   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quelles voitures vitesse moins vite\n",
      "Réponse:  véhicule #id# #vitesse# #MIN#\n",
      "Bot: véhicule #id# #vitesse# #MIN#   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quel véhicule a danger position\n",
      "Réponse:  véhicule #id# #danger# #position#\n",
      "Bot: véhicule #id# #danger# #position#   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quelles voitures vitesse min\n",
      "Réponse:  véhicule #id# #vitesse# #MIN#\n",
      "Bot: véhicule #id# #vitesse# #MIN#   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quelles voitures batterie moins élevés\n",
      "Réponse:  véhicule #id# #batterie# #MIN#\n",
      "Bot: véhicule #id# #batterie# #MIN#   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quel véhicule km minimales\n",
      "Réponse:  véhicule #id# #km# #MIN#\n",
      "Bot: véhicule #id# #km# #MIN#   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quel véhicule a danger position\n",
      "Réponse:  véhicule #id# #danger# #position#\n",
      "Bot: véhicule #id# #danger# #position#   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:   je cherche ma voiture\n",
      "Réponse:  elle #ask_id# est à #position#\n",
      "Bot: #ask_id# #ask_id# est à #position#   ACCURACY 0.8\n",
      "--------------------------------------------------\n",
      "Question:  quelles voitures ont danger vitesse\n",
      "Réponse:  véhicule #id# #danger# #vitesse#\n",
      "Bot: véhicule #id# #danger# #vitesse#   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:   bonjour\n",
      "Réponse:  bonjour\n",
      "Bot: bonjour   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quelles voitures km plus grandes\n",
      "Réponse:  véhicule #id# #km# #MAX#\n",
      "Bot: véhicule #id# #km# #MAX#   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quels véhicules ont vitesse minimal\n",
      "Réponse:  véhicule #id# #vitesse# #MIN#\n",
      "Bot: véhicule #id# #vitesse# #MIN#   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:   etat de la batterie\n",
      "Réponse:  #problème# #batterie#\n",
      "Bot: #problème# #batterie#   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quelle voiture vitesse plus élevée\n",
      "Réponse:  véhicule #id# #vitesse# #MAX#\n",
      "Bot: véhicule #id# #vitesse# #MAX#   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:   gros bisous\n",
      "Réponse:  a bien tôt\n",
      "Bot: a bien tôt   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quelle voiture batterie moin faible\n",
      "Réponse:  véhicule #id# #batterie# #MAX#\n",
      "Bot: véhicule #id# #batterie# #MAX#   ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Accuracy of good answer word to word:  0.994\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly(test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the parameters from check_point/encoder_simulation_2.ck and check_point/decoder_simulation_2.ck...\n",
      "Bonjour, c'est le Bot d'AVICEN, Je peux vous aider? \n",
      "\n",
      "Vous: gros bisous\n",
      "LIGNE TRANFORMÉ:  gros bisous\n",
      "Without Data:  la #check_batterie#\n",
      "Bot AVICEN:  la 12.33\n",
      "--------------------------------------------------\n",
      "Vous: bisous\n",
      "LIGNE TRANFORMÉ:  bisous\n",
      "Without Data:  a #mouvement#\n",
      "Bot AVICEN:  a #mouvement#\n",
      "--------------------------------------------------\n",
      "Vous: bonjour\n",
      "LIGNE TRANFORMÉ:  bonjour\n",
      "Without Data:  véhicule #id# #batterie# #MIN#\n",
      "Bot AVICEN:  véhicule 520830.68253968254 #batterie# #MIN#\n",
      "--------------------------------------------------\n",
      "Vous: bonjour madame\n",
      "LIGNE TRANFORMÉ:  bonjour madame\n",
      "Without Data:  véhicule #id# #batterie# #MAX#\n",
      "Bot AVICEN:  véhicule 520830.68253968254 #batterie# #MAX#\n",
      "--------------------------------------------------\n",
      "Vous: je cherche ma voiture\n",
      "LIGNE TRANFORMÉ:  je cherche ma voiture\n",
      "Without Data:  elle #ask_id# est à #position#\n",
      "Bot AVICEN:  elle #ask_id# est à #position#\n",
      "--------------------------------------------------\n",
      "Vous: je veux ma voiture\n",
      "LIGNE TRANFORMÉ:  je veux ma voiture\n",
      "Without Data:  ta voiture #ask_id# est #position#\n",
      "Bot AVICEN:  ta voiture #ask_id# est #position#\n",
      "--------------------------------------------------\n",
      "Vous: la vitesse moyenne\n",
      "LIGNE TRANFORMÉ:  la vitesse moyenne\n",
      "Without Data:  véhicule #id# #vitesse# #MOYENNE#\n",
      "Bot AVICEN:  véhicule #id# 61.955999999999996 #MOYENNE#\n",
      "--------------------------------------------------\n",
      "Vous: quel véhicule de vitesse plus élevé\n",
      "LIGNE TRANFORMÉ:  quel véhicule de vitesse plus élevé\n",
      "Without Data:  véhicule #id# #vitesse# #MAX#\n",
      "Bot AVICEN:  véhicule #id# 69.5004761904762 #MAX#\n",
      "--------------------------------------------------\n",
      "Vous: \n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = []\n",
    "for pair in pairs1:\n",
    "    for word in pair[1].strip().split():\n",
    "        if '#' in word and word not in key:\n",
    "            key.append(word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the parameters from check_point/encoder_simulation_2.ck and check_point/decoder_simulation_2.ck...\n",
      "Question:  quelles voitures vitesse plus grand\n",
      "Réponse:  véhicule #id# #vitesse# #MAX#\n",
      "Bot: véhicule #id# #vitesse# #MAX#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quels véhicules ont km plus grandes\n",
      "Réponse:  véhicule #id# #km# #MAX#\n",
      "Bot: véhicule #id# #km# #MAX#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quelles voitures vitesse moin faible\n",
      "Réponse:  véhicule #id# #vitesse# #MAX#\n",
      "Bot: véhicule #id# #vitesse# #MAX#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quelles voitures batterie moin faible\n",
      "Réponse:  véhicule #id# #batterie# #MAX#\n",
      "Bot: véhicule #id# #batterie# #MAX#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quels véhicules ont vitesse plus vite\n",
      "Réponse:  véhicule #id# #vitesse# #MAX#\n",
      "Bot: véhicule #id# #vitesse# #MAX#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quels véhicules ont batterie max\n",
      "Réponse:  véhicule #id# #batterie# #MAX#\n",
      "Bot: véhicule #id# #batterie# #MAX#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quelle voiture batterie maximale\n",
      "Réponse:  véhicule #id# #batterie# #MAX#\n",
      "Bot: véhicule #id# #batterie# #MAX#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quelle voiture batterie plus élevés\n",
      "Réponse:  véhicule #id# #batterie# #MAX#\n",
      "Bot: véhicule #id# #batterie# #MAX#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quelles voitures batterie plus petit\n",
      "Réponse:  véhicule #id# #batterie# #MIN#\n",
      "Bot: véhicule #id# #batterie# #MIN#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quelles voitures vitesse plus petites\n",
      "Réponse:  véhicule #id# #vitesse# #MIN#\n",
      "Bot: véhicule #id# #vitesse# #MIN#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quelle voiture batterie plus faibles\n",
      "Réponse:  véhicule #id# #batterie# #MIN#\n",
      "Bot: véhicule #id# #batterie# #MIN#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quelles voitures vitesse moins élevée\n",
      "Réponse:  véhicule #id# #vitesse# #MIN#\n",
      "Bot: véhicule #id# #vitesse# #MIN#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quelles voitures ont erreurs vitesse\n",
      "Réponse:  véhicule #id# #erreurs# #vitesse#\n",
      "Bot: véhicule #id# #erreurs# #vitesse#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quelle voiture a erreur position\n",
      "Réponse:  véhicule #id# #erreur# #position#\n",
      "Bot: véhicule #id# #erreur# #position#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quel véhicule a erreurs km\n",
      "Réponse:  véhicule #id# #erreurs# #km#\n",
      "Bot: véhicule #id# #erreurs# #km#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quel véhicule a erreur km\n",
      "Réponse:  véhicule #id# #erreur# #km#\n",
      "Bot: véhicule #id# #erreur# #km#. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:   danger km\n",
      "Réponse:  véhicule #id# #danger# #km#\n",
      "Bot: véhicule #id# #problème# #id# #danger#. ACCURACY 0.4\n",
      "--------------------------------------------------\n",
      "Question:   les véhicules sont-ils en bonne santé\n",
      "Réponse:  #problème#\n",
      "Bot: il y a #nb_véhicules#. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   quel est le mode d'énergie\n",
      "Réponse:  #ask_id# #carburant#\n",
      "Bot: je suis là pour t'aider. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Question:   combien de kilomètre mon véhicule a t-il parcouru aujourd’hui\n",
      "Réponse:  ce véhicule #ask_id# a effectué #km#\n",
      "Bot: #ask_id# je. ACCURACY 0.0\n",
      "--------------------------------------------------\n",
      "Test on 161\n",
      "Accuracy by percent of true words 0.7829537612146308\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
