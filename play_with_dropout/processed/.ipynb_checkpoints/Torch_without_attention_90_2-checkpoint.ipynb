{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 563 sentence pairs of training set\n",
      "Read 141 sentence pairs of test set\n",
      "Counted words:\n",
      "question 643\n",
      "answer 762\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cet technique marche beaucoup mieux que dans tensorflow, avec en très peu de temps. \n",
    "Ce modèle fonctionne mieux que l'autre dans tensorflow parce qu'une raison évidente: \n",
    "il utilise méthode teacher forcing Un autre problème avec ce méthode, \n",
    "c'est dropout qui donne une technique plus ou moins bon. Il donne la \n",
    "réponse plus tôt aléatoire pour une question. En cas général, \n",
    "ce la peut être intéressant, mais dans notre cas, il est très important \n",
    "qu'il capture le mot clés \n",
    "(donc, surtout on risque de supprimer le mot clés, qui rendra une mauvais réponse)\n",
    "modèle est bien entrainé, donc, il ne sert à rien d'entrainer encore.\n",
    "hidden_size =45 tres mauvais; =70 bien; =100 tres bien; =120 très bien; =150 overfit.\n",
    "hidden_size 50 20%\n",
    "hidden_size 70 33%\n",
    "hidden_size 120 28%\n",
    "\"\"\"\n",
    "#from IPython.display import display, Markdown\n",
    "#display(Markdown(\"### Pour lancer un chat, il suffit de taper en même temps CTRL et ENTER\"))\n",
    "#display(Markdown(\"### Pour arrêter le mode chat, il suffit de taper ENTER dans votre conversation\"))\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import data\n",
    "import config\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "hidden_size = 70\n",
    "SOS_token  = config.SOS_token\n",
    "EOS_token  = config.EOS_token\n",
    "MAX_LENGTH = config.MAX_LENGTH\n",
    "stopwords  = config.STOPWORDS\n",
    "learning_rate = config.LEARNING_RATE\n",
    "teacher_forcing_ratio = 0.2\n",
    "dropout = config.DROPOUT\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  \n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "def normalizeString(s):\n",
    "    \"\"\"\n",
    "    Whith a tring s, we make it in lower case, delete \\n if exists at \n",
    "    the end of string, and delete specical case ? . and !\n",
    "    \"\"\"\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([,.!?\\n])\", r\"\", s)# sumprimer tous les caractères .! et ?\n",
    "    #s = re.sub(r\"[^a-zA-Z0-9.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs():\n",
    "    print(\"Reading lines...\")\n",
    "    pairs_trains, pairs_tests = [], []   \n",
    "    encode_train = open(os.path.join(config.PROCESSED_PATH, \"question_train.txt\"), 'r')\n",
    "    decode_train = open(os.path.join(config.PROCESSED_PATH, \"answer_train.txt\"), 'r')\n",
    "    encode, decode = encode_train.readline(), decode_train.readline()\n",
    "    while encode and decode:\n",
    "        encode, decode = normalizeString(encode), normalizeString(decode)\n",
    "        decode = 'SOS '+ decode + ' EOS'\n",
    "        pairs_trains.append([encode, decode])\n",
    "        encode, decode = encode_train.readline(), decode_train.readline()\n",
    "    encode_train.close()\n",
    "    decode_train.close()\n",
    "    encode_test = open(os.path.join(config.PROCESSED_PATH, \"question_test.txt\"), 'r')\n",
    "    decode_test = open(os.path.join(config.PROCESSED_PATH, \"answer_test.txt\"), 'r')\n",
    "    encode, decode = encode_test.readline(), decode_test.readline()\n",
    "    while encode and decode:\n",
    "        encode, decode = normalizeString(encode), normalizeString(decode)\n",
    "        decode = 'SOS '+ decode + ' EOS'\n",
    "        pairs_tests.append([encode, decode])\n",
    "        encode, decode = encode_test.readline(), decode_test.readline()\n",
    "    encode_test.close()\n",
    "    decode_test.close()\n",
    "    return pairs_trains, pairs_tests\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH \n",
    "\n",
    "    \n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData():\n",
    "    input_lang = Lang('question')\n",
    "    output_lang = Lang('answer')\n",
    "    pairs_trains, pairs_tests = readLangs()\n",
    "    print(\"Read %s sentence pairs of training set\" % len(pairs_trains))\n",
    "    print(\"Read %s sentence pairs of test set\" % len(pairs_tests))\n",
    "    pairs_trains = filterPairs(pairs_trains)\n",
    "    pairs_tests = filterPairs(pairs_tests)\n",
    "    for i  in range(len(pairs_trains)) :\n",
    "        pair = pairs_trains[i]\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    \n",
    "    for i  in range(len(pairs_tests)) :\n",
    "        pair = pairs_tests[i]\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs_trains,pairs_tests\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=2):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=2):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "        \n",
    "def closetWord(word, lang):\n",
    "    \"\"\"\n",
    "    find and return the closest word in lang\n",
    "    \"\"\"\n",
    "    Dict = lang.word2index\n",
    "    corpus = lang.index2word\n",
    "    if word in Dict:\n",
    "        return word\n",
    "    else:\n",
    "        distance = levenshtein(word, corpus[0])\n",
    "        close_word = corpus[0]\n",
    "        for ix in corpus:\n",
    "            if levenshtein(word, corpus[ix]) <distance:\n",
    "                close_word = corpus[ix]\n",
    "                distance = levenshtein(word, corpus[ix])\n",
    "        if distance <=1:\n",
    "            return close_word\n",
    "        else:\n",
    "            return word\n",
    "        \n",
    "def normalizeSentenceInChat(sentence):\n",
    "    sentence = sentence.strip().lower().split()\n",
    "    s = [closetWord(word, input_lang) for word in sentence]\n",
    "    return ' '.join(s)\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    #sentence = normalizeSentence\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index ]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "def get_skip_step(n_iters):\n",
    "    return int(n_iters/10)\n",
    "\n",
    "def trainIters(n_iters, plot_every=100, learning_rate=learning_rate):\n",
    "    encoder, decoder = restore_model()\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    skip_step = get_skip_step(n_iters)\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs_trains))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % skip_step == 0:\n",
    "            print_loss_avg = print_loss_total / skip_step\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    save_model(encoder, decoder)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    #sentence = normalizeSentenceInChat(sentence)\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  \n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        ni = int(ni)\n",
    "        if ni == EOS_token:\n",
    "            #decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluate_randomly(n_iters=200, test=True):\n",
    "    encoder, decoder = restore_model()\n",
    "    if not test:\n",
    "        print('TEST error of word to word on TRAIN')\n",
    "        list_print_random = random.sample(range(n_iters),20 )\n",
    "        total_loss = 0\n",
    "        for i in range(n_iters):\n",
    "            pair = random.choice(pairs_trains)\n",
    "            output_words = evaluate(encoder, decoder, pair[0])\n",
    "            if 'EOS' in output_words:\n",
    "                l = output_words.index('EOS')+1\n",
    "            else:\n",
    "                l = len(output_words)+1\n",
    "            reponse = ' '.join(output_words[:l])\n",
    "            loss = _evaluate_by_right_word(pair[1], reponse)\n",
    "            total_loss +=loss\n",
    "            if i in list_print_random:\n",
    "                print('Question: ', pair[0])\n",
    "                print('Réponse: ', pair[1])\n",
    "                print('Bot: {}   ACCURACY {:.1f}'.format(reponse, 1-loss))\n",
    "                print('-'*50)\n",
    "        print('Accuracy of good answer word to word: ', 1-total_loss/n_iters)\n",
    "    else:\n",
    "        n_iters = len(pairs_tests)\n",
    "        total_loss = 0\n",
    "        random_print_index = random.sample(range(n_iters), 20)\n",
    "        for i in range(n_iters):\n",
    "            pair = pairs_tests[i]\n",
    "            output_words= evaluate(encoder, decoder, pair[0])\n",
    "            if 'EOS' in output_words:\n",
    "                l = output_words.index('EOS')+1\n",
    "            else:\n",
    "                l = len(output_words)+1\n",
    "            reponse = ' '.join(output_words[:l])\n",
    "            loss = _evaluate_by_right_word(pair[1], reponse)\n",
    "            if i in random_print_index:\n",
    "                print('Question: ', pair[0])\n",
    "                print('Réponse: ', pair[1])\n",
    "                print('Bot: {}. ACCURACY {:.1f}'.format(reponse, 1-loss))\n",
    "                print('-'*50)\n",
    "            total_loss +=loss\n",
    "        print('Test on {}'.format(n_iters))\n",
    "        print('Accuracy by percent of true words {}'.format(1-total_loss/n_iters))\n",
    "       \n",
    "   \n",
    "    \n",
    "def _evaluate_by_right_word(reponse, bonne_reponse):\n",
    "    reponse = reponse.split()\n",
    "    bonne_reponse = bonne_reponse.split()\n",
    "    min_length = min(len(reponse), len(bonne_reponse))\n",
    "    max_length = max(len(reponse), len(bonne_reponse))\n",
    "    error = max_length-min_length\n",
    "    for i in range(min_length):\n",
    "        if reponse[i] != bonne_reponse[i]:\n",
    "            error +=1\n",
    "    return error/max_length      \n",
    "        \n",
    "def make_dir(path):\n",
    "    \"\"\" Create a directory if there isn't one already. \"\"\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "def save_model(encoder, decoder):        \n",
    "    make_dir(config.CHECK_POINT_PATH)\n",
    "    path1= os.path.join(config.CHECK_POINT_PATH, 'encoder_no_att_70_2.ck')\n",
    "    path2 = os.path.join(config.CHECK_POINT_PATH, 'decoder_no_att_70_2.ck')\n",
    "    try: \n",
    "        os.remove(path1)  \n",
    "        os.remove(path2)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    torch.save(encoder,path1)\n",
    "    torch.save(decoder, path2)\n",
    "    \n",
    "memo = {}\n",
    "def levenshtein(s, t):\n",
    "    \"\"\"\n",
    "    Pour calculer la distance  Levenshtein entre 2 string s et t\n",
    "    \"\"\"\n",
    "    if s == \"\":\n",
    "        return len(t)\n",
    "    if t == \"\":\n",
    "        return len(s)\n",
    "    cost = 0 if s[-1] == t[-1] else 1\n",
    "       \n",
    "    i1 = (s[:-1], t)\n",
    "    if not i1 in memo:\n",
    "        memo[i1] = levenshtein(*i1)\n",
    "    i2 = (s, t[:-1])\n",
    "    if not i2 in memo:\n",
    "        memo[i2] = levenshtein(*i2)\n",
    "    i3 = (s[:-1], t[:-1])\n",
    "    if not i3 in memo:\n",
    "        memo[i3] = levenshtein(*i3)\n",
    "    res = min([memo[i1]+1, memo[i2]+1, memo[i3]+cost])\n",
    "    \n",
    "    return res\n",
    "    \n",
    "def restore_model():\n",
    "    #hidden_size = hidden_size\n",
    "    path1 = os.path.join(config.CHECK_POINT_PATH, 'encoder_no_att_70_2.ck')\n",
    "    path2 = os.path.join(config.CHECK_POINT_PATH, 'decoder_no_att_70_2.ck')\n",
    "    if os.path.exists(path1)and os.path.exists(path2):\n",
    "        print('Reading the parameters from {} and {}...'.format(path1, path2))\n",
    "        encoder = torch.load(path1)\n",
    "        decoder = torch.load(path2)\n",
    "    else:\n",
    "        print('Initializing fresh parameters...')\n",
    "        encoder = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "        decoder = DecoderRNN(hidden_size, output_lang.n_words,2)\n",
    "\n",
    "    if use_cuda:\n",
    "        encoder = encoder.cuda()\n",
    "        decoder = decoder.cuda()\n",
    "    return encoder, decoder  \n",
    "\n",
    "def construct_dict(lang):\n",
    "    in_file = open(os.path.join(config.PROCESSED_PATH, 'dictionnary.txt'), 'r')\n",
    "    lines = []\n",
    "    dicts = lang.word2index.copy()\n",
    "    for line in in_file:\n",
    "        line = line.strip().split('|')\n",
    "        for word in dicts:\n",
    "            if str(word) in line and len(word)>0:\n",
    "                line.insert(0,str(word))\n",
    "                lines.append(line)\n",
    "                del dicts[str(word)]\n",
    "                break\n",
    "    return lines\n",
    "\n",
    "def find_close_line(lines, lang, line):\n",
    "    LINE = []\n",
    "    for word in line.strip().split():\n",
    "        if word in lang.word2index:\n",
    "            LINE.append(word)\n",
    "        else:\n",
    "            for pharse in lines:\n",
    "                if word in pharse:\n",
    "                    LINE.append(pharse[0])\n",
    "                    break\n",
    "    return ' '.join(LINE)\n",
    "\n",
    "def chat():\n",
    "    encoder, decoder = restore_model()\n",
    "    make_dir(config.CHECK_POINT_PATH)\n",
    "    lines = construct_dict(input_lang)\n",
    "    output_file = open(os.path.join(config.CHECK_POINT_PATH, 'convos70.txt'), 'a+')\n",
    "    print('Bonjour, c\\'est le Bot d\\'AVICEN, Je peux vous aider? \\n')\n",
    "    while True:\n",
    "            line = str(input('Vous: '))\n",
    "            if len(line) > 0 and line[-1] == '\\n':\n",
    "                line = line[:-1]\n",
    "            if line == '':\n",
    "                break\n",
    "            line = normalizeString(line)\n",
    "            transform_line  = normalizeSentenceInChat(line)\n",
    "            transform_line = find_close_line(lines, input_lang, transform_line)\n",
    "            print('LIGNE TRANFORMÉ: ', line)\n",
    "            output_file.write('VOUS ++++ ' + line + '\\n')\n",
    "            reponse, _ = evaluate(encoder, decoder, transform_line)\n",
    "            reponse = \" \".join(reponse[:-1])\n",
    "            output_file.write('BOT ++++ ' + reponse + '\\n')\n",
    "            print('Bot AVICEN: ', reponse)\n",
    "            print('-'*50)\n",
    "    output_file.close()\n",
    "    \n",
    "def langTest():\n",
    "    pairs_test = []   \n",
    "    test_file = open(os.path.join(config.PROCESSED_PATH, \"test.txt\"), 'r')\n",
    "    i=0\n",
    "    for line in test_file:\n",
    "        line = normalizeString(line)\n",
    "        if i%2 ==0:\n",
    "            question = line\n",
    "        else:\n",
    "            answer = line\n",
    "            pairs_test.append([question, answer])\n",
    "        i +=1\n",
    "    return pairs_test  \n",
    "\n",
    "def test(pairs_test):\n",
    "    \"\"\"\n",
    "    Use test for know how our model is good\n",
    "    \"\"\"\n",
    "    encoder, decoder = restore_model()\n",
    "    total_loss = 0\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "    for pair in pairs_test:\n",
    "        variable = variablesFromPair(pair)\n",
    "        loss = train( variable[0], variable[1], encoder, decoder, encoder_optimizer, decoder_optimizer,\\\n",
    "                     criterion= criterion)\n",
    "        total_loss +=loss\n",
    "    Length_inputs = len(pairs_test) if len(pairs_test) !=0 else 1\n",
    "    return total_loss/Length_inputs\n",
    "\n",
    "def construct_train_test_set(pairs):\n",
    "    max_length = len(pairs)\n",
    "    portion_of_train = int(max_length*0.85)\n",
    "    index_of_train = random.sample(range(max_length), portion_of_train)\n",
    "    train, test = [], []\n",
    "    for index in range(max_length):\n",
    "        if index in index_of_train:\n",
    "            train.append(pairs[index])\n",
    "        else:\n",
    "            test.append(pairs[index])\n",
    "    return train, test\n",
    "\n",
    "if __name__=='__main__':\n",
    "    try:\n",
    "        input_lang\n",
    "    except NameError : \n",
    "        input_lang, output_lang, pairs_trains, pairs_tests = prepareData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing fresh parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:288: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 14s (- 20m 11s) (10000 10%) 2.1349\n",
      "4m 47s (- 19m 8s) (20000 20%) 2.1659\n",
      "6m 36s (- 15m 26s) (30000 30%) 1.5763\n",
      "8m 16s (- 12m 25s) (40000 40%) 1.1545\n",
      "9m 56s (- 9m 56s) (50000 50%) 1.4121\n",
      "11m 31s (- 7m 41s) (60000 60%) 1.8447\n",
      "12m 56s (- 5m 32s) (70000 70%) 1.9472\n",
      "14m 21s (- 3m 35s) (80000 80%) 1.8877\n",
      "15m 49s (- 1m 45s) (90000 90%) 1.8573\n",
      "17m 16s (- 0m 0s) (100000 100%) 1.7913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type EncoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type DecoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainIters(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the parameters from check_point/encoder_no_att_70_2.ck and check_point/decoder_no_att_70_2.ck...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:288: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 30s (- 13m 32s) (10000 10%) 1.5521\n",
      "2m 58s (- 11m 52s) (20000 20%) 1.5231\n",
      "4m 25s (- 10m 19s) (30000 30%) 1.5385\n",
      "5m 56s (- 8m 54s) (40000 40%) 1.5235\n",
      "7m 29s (- 7m 29s) (50000 50%) 1.4998\n",
      "9m 9s (- 6m 6s) (60000 60%) 1.4723\n",
      "10m 45s (- 4m 36s) (70000 70%) 1.5928\n",
      "12m 18s (- 3m 4s) (80000 80%) 1.6942\n",
      "13m 48s (- 1m 32s) (90000 90%) 1.6538\n"
     ]
    }
   ],
   "source": [
    "trainIters(100000, learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the parameters from check_point/encoder_no_att_50_2.ck and check_point/decoder_no_att_50_2.ck...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:288: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    }
   ],
   "source": [
    "trainIters(100000, learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the parameters from check_point/encoder_no_att_50_2.ck and check_point/decoder_no_att_50_2.ck...\n",
      "TEST error of word to word on TRAIN\n",
      "Question:  quels sont les indicateurs disponibles\n",
      "Réponse:  SOS la liste des indicateurs sont disponibles dans #kpi# EOS\n",
      "Bot: SOS la liste est est EOS   ACCURACY 0.3\n",
      "--------------------------------------------------\n",
      "Question:  quels sont les instances non-traitées\n",
      "Réponse:  SOS vous devez traiter les #list_instances# EOS\n",
      "Bot: SOS vous devez traiter EOS   ACCURACY 0.6\n",
      "--------------------------------------------------\n",
      "Question:  quel est le véhicule disponible\n",
      "Réponse:  SOS le véhicule disponible est indiqué dans votre espace client EOS\n",
      "Bot: SOS #oui/non# EOS   ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  bonjour madame\n",
      "Réponse:  SOS bonjour EOS\n",
      "Bot: SOS #oui/non# EOS   ACCURACY 0.7\n",
      "--------------------------------------------------\n",
      "Question:  nous avons combien de véhicules\n",
      "Réponse:  SOS il y a #nb_véhicule# EOS\n",
      "Bot: SOS la liste   ACCURACY 0.2\n",
      "--------------------------------------------------\n",
      "Question:  je veux une voitures\n",
      "Réponse:  SOS le véhicule le plus proche est #vin_proxi# EOS\n",
      "Bot: SOS le EOS   ACCURACY 0.2\n",
      "--------------------------------------------------\n",
      "Question:  combien de véhicules sont présents dans le parc\n",
      "Réponse:  SOS le parc comprend #list_vin_free# véhicules EOS\n",
      "Bot: SOS le parc parler d’autre sujets EOS   ACCURACY 0.6\n",
      "--------------------------------------------------\n",
      "Question:  lequel choisir\n",
      "Réponse:  SOS vous pouvez choisir plusieurs modules parmi #nb_module# EOS\n",
      "Bot: SOS ça va EOS   ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  je souhaite avoir des données de gestion\n",
      "Réponse:  SOS bien entendu EOS\n",
      "Bot: SOS la révision   ACCURACY 0.2\n",
      "--------------------------------------------------\n",
      "Question:  nom du loueur\n",
      "Réponse:  SOS le loueur est la société #list_lld# EOS\n",
      "Bot: SOS quels EOS   ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  combien de boîtiers défaillants\n",
      "Réponse:  SOS #list_disconnect# EOS\n",
      "Bot: SOS il EOS   ACCURACY 0.7\n",
      "--------------------------------------------------\n",
      "Question:  je souhaite avoir des données de restitution\n",
      "Réponse:  SOS d'accord quel véhicule EOS\n",
      "Bot: SOS la EOS   ACCURACY 0.2\n",
      "--------------------------------------------------\n",
      "Question:  bonjour\n",
      "Réponse:  SOS social :) approximative descriptif par détaillé EOS\n",
      "Bot: SOS bonjour EOS   ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  où est ma voiture\n",
      "Réponse:  SOS elle est à #position# EOS\n",
      "Bot: SOS elle est #position# EOS   ACCURACY 0.5\n",
      "--------------------------------------------------\n",
      "Question:  le pneu semble ne pas être adapté\n",
      "Réponse:  SOS je vérifie cela dans la base constructeur EOS\n",
      "Bot: SOS #oui/non# EOS   ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  coût d'usage de ce véhicule\n",
      "Réponse:  SOS le tco de ce véhicule est de #tco_vehicule# EOS\n",
      "Bot: SOS le use EOS   ACCURACY 0.2\n",
      "--------------------------------------------------\n",
      "Question:  performance environnementale\n",
      "Réponse:  SOS ce sujet d'actualité doit prendre en compte de nombreux paramêtres pouvez-vous préciser votre question EOS\n",
      "Bot: SOS il EOS   ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  quelles sont les caractéristiques des pneus\n",
      "Réponse:  SOS oui trouverez cela ici #spec_tyre# de #spec_tyre# EOS\n",
      "Bot: SOS bonjour EOS   ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  c'est le bon véhicule pour cette mission\n",
      "Réponse:  SOS de tous les véhicules c'est celui qui semble répondre le mieux à votre besoin EOS\n",
      "Bot: SOS le EOS   ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  il y a des dossiers non traités\n",
      "Réponse:  SOS oui EOS\n",
      "Bot: SOS bonjour EOS   ACCURACY 0.7\n",
      "--------------------------------------------------\n",
      "Accuracy of good answer word to word:  0.30649801709728175\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly(test = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the parameters from check_point/encoder_no_att_50_2.ck and check_point/decoder_no_att_50_2.ck...\n",
      "Question:  livraison de boîtiers\n",
      "Réponse:  SOS la date de livraison approximative est #date# EOS\n",
      "Bot: SOS #oui/non# EOS. ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  a quoi sert le paramêtrage\n",
      "Réponse:  SOS il s'agit de configurer correctement la solution embarquée pour vous offrir la meilleure expérience possible EOS\n",
      "Bot: SOS le EOS. ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  combien de kilomètres a fait ce véhicule cette année\n",
      "Réponse:  SOS le kilomètrage annuel est de #km# EOS\n",
      "Bot: SOS #oui/non# EOS. ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  peut-on convenir d'un rendez-vous\n",
      "Réponse:  SOS oui quelle date vous conviendrait EOS\n",
      "Bot: SOS #oui/non# EOS. ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  est-ce que la batterie fonctionne\n",
      "Réponse:  SOS #check_batterie# EOS\n",
      "Bot: SOS ça va est de #voltage# EOS. ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  comment vas tu\n",
      "Réponse:  SOS je vais bien merci EOS\n",
      "Bot: SOS je suis. ACCURACY 0.3\n",
      "--------------------------------------------------\n",
      "Question:  je cherche mon véhicule\n",
      "Réponse:  SOS il est à #position# EOS\n",
      "Bot: SOS #oui/non# EOS. ACCURACY 0.2\n",
      "--------------------------------------------------\n",
      "Question:  quel est le niveau de lave glace restant\n",
      "Réponse:  SOS #lave_glace# EOS\n",
      "Bot: SOS elle est. ACCURACY 0.3\n",
      "--------------------------------------------------\n",
      "Question:  est ce que mes ampoules sont usées\n",
      "Réponse:  SOS #oui/non# EOS\n",
      "Bot: SOS #oui/non# EOS. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  quel véhicule dois-je restituer prochainement\n",
      "Réponse:  SOS #oui/non# EOS\n",
      "Bot: SOS le EOS. ACCURACY 0.7\n",
      "--------------------------------------------------\n",
      "Question:  un boîtier ne fonctionne plus\n",
      "Réponse:  SOS nous prenons en compte cet incident quel est le boitier concerné EOS\n",
      "Bot: SOS nous EOS. ACCURACY 0.2\n",
      "--------------------------------------------------\n",
      "Question:  quels sont les problèmes\n",
      "Réponse:  SOS #oui/non# EOS\n",
      "Bot: SOS les urgences. ACCURACY 0.3\n",
      "--------------------------------------------------\n",
      "Question:  il y a des problèmes\n",
      "Réponse:  SOS #oui/non# EOS\n",
      "Bot: SOS #oui/non# EOS. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  je veux savoir si il y a des problèmes\n",
      "Réponse:  SOS #oui/non# EOS\n",
      "Bot: SOS #oui/non# EOS. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  combien de voiture\n",
      "Réponse:  SOS il y a #nb_veh# EOS\n",
      "Bot: SOS #oui/non# EOS. ACCURACY 0.2\n",
      "--------------------------------------------------\n",
      "Question:  je veux tous les contrats\n",
      "Réponse:  SOS pouvez-vous préciser votre demande EOS\n",
      "Bot: SOS le EOS. ACCURACY 0.2\n",
      "--------------------------------------------------\n",
      "Question:  bonsoir\n",
      "Réponse:  SOS bonsoir EOS\n",
      "Bot: SOS bonsoir EOS. ACCURACY 1.0\n",
      "--------------------------------------------------\n",
      "Question:  la pression correspond à la pression des pneumatiques\n",
      "Réponse:  SOS #oui/non# EOS\n",
      "Bot: SOS la durée nous contacter ce EOS. ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Question:  quelle est la pression des pneus\n",
      "Réponse:  SOS la pression des pneus est #tpms# bar EOS\n",
      "Bot: SOS le prenons en compte cet incident ce EOS. ACCURACY 0.2\n",
      "--------------------------------------------------\n",
      "Question:  j'aimerais réduire mon empreinte carbone\n",
      "Réponse:  SOS notre module #rde# pour real-driving emissions vise à mesurer les rejets nox de particules fines EOS\n",
      "Bot: SOS je EOS. ACCURACY 0.1\n",
      "--------------------------------------------------\n",
      "Test on 137\n",
      "Accuracy by percent of true words 0.2986212549437116\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
