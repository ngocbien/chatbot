{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-23-c8131c6fc627>:71: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape () for Tensor 'encoder0_3:0', which has shape '(?,)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c8131c6fc627>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# no outputs in training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtest_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-c8131c6fc627>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, session, encoder_inputs, decoder_inputs, target_weights, test)\u001b[0m\n\u001b[1;32m     95\u001b[0m                                 \u001b[0moutput_feed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbucket_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m# Gradient norm, loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1114\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1116\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1117\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape () for Tensor 'encoder0_3:0', which has shape '(?,)'"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"Sequence-to-sequence model with an attention mechanism.\"\"\"\n",
    "# see https://www.tensorflow.org/versions/r0.10/tutorials/seq2seq/index.html\n",
    "# compare https://github.com/tflearn/tflearn/blob/master/examples/nlp/seq2seq_example.py\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "vocab_size=256 # # of ASCII Code\n",
    "target_vocab_size=vocab_size # the model selects (classify) one of 256 classes (ASCII codes) per time unit\n",
    "learning_rate=0.1\n",
    "buckets=[(12, 12)] # Because seq2seq does batch learning, it buckets input by length. This time we will only deal with one bucket.\n",
    "PAD=[0] # If the input / target sentence is smaller than the bucket size, pad 0.\n",
    "GO=[1] # Decoder RNN puts the symbol GO as the first input.\n",
    "batch_size=1\n",
    "input_string = \"Hello World\" \n",
    "target_string = \"How are you\"\n",
    "input_ids = [ord(i) for i in input_string]\n",
    "target_ids = [ord(i) for i in target_string]\n",
    "input_PAD_size = buckets[0][0] - len(input_string) # Decide how much PAD you want to input/\n",
    "target_PAD_size = buckets[0][0] - len(target_string) - 1 # Decide how much PAD you want to target.\n",
    "input_data = (input_ids + PAD * input_PAD_size) * batch_size # Change the input text to a list of ASCII codes.\n",
    "target_data = (GO + target_ids + PAD * target_PAD_size) * batch_size # Change target phrase to list of ASCII codes.\n",
    "target_weights= ([1.0]*12 + [0.0]*0) * batch_size \n",
    "\n",
    "\n",
    "class BabySeq2Seq(object):\n",
    "\n",
    "\tdef __init__(self, source_vocab_size, target_vocab_size, buckets, size, num_layers, batch_size):\n",
    "\t\tself.buckets = buckets\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.source_vocab_size = source_vocab_size\n",
    "\t\tself.target_vocab_size = target_vocab_size\n",
    "\n",
    "\t\tcell = single_cell = tf.nn.rnn_cell.GRUCell(size)\n",
    "\t\tif num_layers > 1:\n",
    "\t\t cell = tf.nn.rnn_cell.MultiRNNCell([single_cell] * num_layers)\n",
    "\n",
    "\t\t# The seq2seq function: we use embedding for the input and attention.\n",
    "\t\tdef seq2seq_f(encoder_inputs, decoder_inputs, do_decode):\n",
    "\t\t\treturn tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(\n",
    "\t\t\t\t\tencoder_inputs, decoder_inputs, cell,\n",
    "\t\t\t\t\tnum_encoder_symbols=source_vocab_size,\n",
    "\t\t\t\t\tnum_decoder_symbols=target_vocab_size,\n",
    "\t\t\t\t\tembedding_size=size,\n",
    "\t\t\t\t\tfeed_previous=do_decode)\n",
    "\n",
    "\t\t# Feeds for inputs.\n",
    "\t\tself.encoder_inputs = []\n",
    "\t\tself.decoder_inputs = []\n",
    "\t\tself.target_weights = []\n",
    "\t\tfor i in range(buckets[-1][0]):\t# Last bucket is the biggest one.\n",
    "\t\t\tself.encoder_inputs.append(tf.placeholder(tf.int32, shape=[None], name=\"encoder{0}\".format(i)))\n",
    "\t\tfor i in range(buckets[-1][1] + 1):\n",
    "\t\t\tself.decoder_inputs.append(tf.placeholder(tf.int32, shape=[None], name=\"decoder{0}\".format(i)))\n",
    "\t\t\tself.target_weights.append(tf.placeholder(tf.float32, shape=[None], name=\"weight{0}\".format(i)))\n",
    "\n",
    "\t\t# Our targets are decoder inputs shifted by one. OK\n",
    "\t\ttargets = [self.decoder_inputs[i + 1] for i in range(len(self.decoder_inputs) - 1)]\n",
    "\t\tself.outputs, self.losses = tf.contrib.legacy_seq2seq.model_with_buckets(\n",
    "\t\t\t\tself.encoder_inputs, self.decoder_inputs, targets,\n",
    "\t\t\t\tself.target_weights, buckets,\n",
    "\t\t\t\tlambda x, y: seq2seq_f(x, y, False))\n",
    "\n",
    "\t\t# Gradients update operation for training the model.\n",
    "\t\tparams = tf.trainable_variables()\n",
    "\t\tself.updates=[]\n",
    "\t\tfor b in range(len(buckets)):\n",
    "\t\t\tself.updates.append(tf.train.AdamOptimizer(learning_rate).minimize(self.losses[b]))\n",
    "\n",
    "\t\tself.saver = tf.train.Saver(tf.all_variables())\n",
    "\n",
    "\tdef step(self, session, encoder_inputs, decoder_inputs, target_weights, test):\n",
    "\t\tbucket_id=0 # todo: auto-select\n",
    "\t\tencoder_size, decoder_size = self.buckets[bucket_id]\n",
    "\n",
    "\t\t# Input feed: encoder inputs, decoder inputs, target_weights, as provided.\n",
    "\t\tinput_feed = {}\n",
    "\t\tfor l in range(encoder_size):\n",
    "\t\t\tinput_feed[self.encoder_inputs[l].name] = encoder_inputs[l]\n",
    "\t\tfor l in range(decoder_size):\n",
    "\t\t\tinput_feed[self.decoder_inputs[l].name] = decoder_inputs[l]\n",
    "\t\t\tinput_feed[self.target_weights[l].name] = target_weights[l]\n",
    "\n",
    "\t\t# Since our targets are decoder inputs shifted by one, we need one more.\n",
    "\t\tlast_target = self.decoder_inputs[decoder_size].name\n",
    "\t\tinput_feed[last_target] = np.zeros([self.batch_size], dtype=np.int32)\n",
    "\n",
    "\t\t# Output feed: depends on whether we do a backward step or not.\n",
    "\t\tif not test:\n",
    "\t\t\toutput_feed = [self.updates[bucket_id], self.losses[bucket_id]]\n",
    "\t\telse:\n",
    "\t\t\toutput_feed = [self.losses[bucket_id]]\t# Loss for this batch.\n",
    "\t\t\tfor l in range(decoder_size):\t# Output logits.\n",
    "\t\t\t\toutput_feed.append(self.outputs[bucket_id][l])\n",
    "\n",
    "\t\toutputs = session.run(output_feed, input_feed)\n",
    "\t\tif not test:\n",
    "\t\t\treturn outputs[0], outputs[1]# Gradient norm, loss\n",
    "\t\telse:\n",
    "\t\t\treturn outputs[0], outputs[1:]# loss, outputs.\n",
    "\n",
    "\n",
    "def decode(bytes):\n",
    "\treturn \"\".join(map(chr, bytes)).replace('\\x00', '').replace('\\n', '')\n",
    "\n",
    "def test():\n",
    "\tperplexity, outputs = model.step(session, input_data, target_data, target_weights, test=True)\n",
    "\twords = np.argmax(outputs, axis=2)  # shape (10, 10, 256)\n",
    "\tword = decode(words[0])\n",
    "\tprint(\"step %d, perplexity %f, output: hello %s?\" % (step, perplexity, word))\n",
    "\tif word == \"world\":\n",
    "\t\tprint(\">>>>> success! hello \" + word + \"! <<<<<<<\")\n",
    "\t\texit()\n",
    "\n",
    "step=0\n",
    "test_step=1\n",
    "with tf.Session() as session:\n",
    "\tmodel= BabySeq2Seq(vocab_size, target_vocab_size, buckets, size=10, num_layers=1, batch_size=batch_size)\n",
    "\tsession.run(tf.initialize_all_variables())\n",
    "\twhile True:\n",
    "\t\tmodel.step(session, input_data, target_data, target_weights, test=False) # no outputs in training\n",
    "\t\tif step % test_step == 0:\n",
    "\t\t\ttest()\n",
    "\t\tstep=step+1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
