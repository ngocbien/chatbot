{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 427 de couples de  train\n",
      "Il y a 151 de couples de  test\n",
      "There are 314 words in corpus:\n",
      "on train:\n",
      "--------------------------------------------------------------------------------\n",
      "PRECISION = 1.00000,  RECALL = 1.00000, F_MESURE = 1.000 METHODE = normal\n",
      "--------------------------------------------------------------------------------\n",
      "PRECISION = 1.00000,  RECALL = 1.00000, F_MESURE = 1.000 METHODE = lissé\n",
      "--------------------------------------------------------------------------------\n",
      "PRECISION = 1.00000,  RECALL = 1.00000, F_MESURE = 1.000 METHODE = probabiliste\n",
      "--------------------------------------------------------------------------------\n",
      "PRECISION = 1.00000,  RECALL = 1.00000, F_MESURE = 1.000 METHODE = probabiliste_lissé\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-99b747e85e13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on train:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mméthode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMETHODE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m     \u001b[0mtest_with_precision_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mméthode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'On test:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mméthode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMETHODE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-99b747e85e13>\u001b[0m in \u001b[0;36mtest_with_precision_recall\u001b[0;34m(DICT, méthode, train)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mtotal_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_recall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs_trains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_right_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs_trains\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mméthode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m             \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall\u001b[0m            \u001b[0;34m(\u001b[0m\u001b[0mpairs_trains\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_trains\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mtotal_precision\u001b[0m  \u001b[0;34m+=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-99b747e85e13>\u001b[0m in \u001b[0;36mfind_right_index\u001b[0;34m(new_doc, DICT, méthode)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0mbiggest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_by_new_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQUESTION_TO_TRAINS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mméthode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQUESTION_TO_TRAINS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mboolean1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_by_new_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQUESTION_TO_TRAINS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mméthode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0mbiggest_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-99b747e85e13>\u001b[0m in \u001b[0;36mscore_by_new_doc\u001b[0;34m(new_doc, doc, DICT, méthode)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDICT_of_methode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                  \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mDICT_of_methode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_doc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mreturn\u001b[0m  \u001b[0mcoord\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +=: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "les symboles particulières comme ? ! et . sont supprimé dans la question.\n",
    "Il faut peut être returner une réponse spécifique si il rencontre plus 1 mot qu'il existe pas dans le corpus\n",
    "Nous suprimmons également:\n",
    "  1. Mot qui contient une seule lettre(qui sont suivante des erreurs)\n",
    "  2. Une fonction unique pour nettoyage tous les données dans train-test et chat\n",
    "Nous allons traiter tous les mots clés suivant :\n",
    "km, vitesse, carburant, huile, position, batterie, pression_pneu. Il reste trajet et vin\n",
    "  \n",
    "\"\"\"\n",
    "#import sys\n",
    "#!{sys.executable} -m pip uninstall gtts\n",
    "\n",
    "#from gtts import gTTS\n",
    "#from playsound import playsound\n",
    "#import speech_recognition\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = stopwords.words('french')\n",
    "from nltk.stem import *\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"french\", ignore_stopwords = False)\n",
    "\n",
    "import re\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from dateparser.search import search_dates\n",
    "import pandas as pd\n",
    "\n",
    "def clearing_word(word):\n",
    "    word = re.sub('\\x8e', 'é', word)\n",
    "    word = re.sub('\\x88', 'à', word)\n",
    "    word = re.sub('\\x9d', 'ù', word)\n",
    "    word = re.sub('\\x8f', 'è', word)\n",
    "    word = re.sub('\\x9e', 'û', word)\n",
    "    word = re.sub('\\x90', 'ê', word)\n",
    "    word = re.sub('\\x99', 'ô', word)\n",
    "    word = re.sub('\\x94', 'î', word)\n",
    "   # word = re.sub('\\x8f', 'è', word)\n",
    "    word = re.sub('\\x8d', 'ç', word)\n",
    "    word = re.sub('õ', '', word)\n",
    "    word = re.sub('Ê', '', word)\n",
    "    word = re.sub('[?,.,!, \\,,  %]', '', word)\n",
    "    if word == 'û' or word == 'v' or word == 'é':\n",
    "        word = ''\n",
    "    if word ==\"2017êles\":\n",
    "        word = \"2017\"\n",
    "    if \"ênox\" in word:\n",
    "        word =\"nox\"\n",
    "    return word\n",
    "\n",
    "def clear_line(pharse, stop_word):\n",
    "    \"\"\"\n",
    "    Arg: string\n",
    "    Return: string\n",
    "    \"\"\"\n",
    "    #clean_data = []\n",
    "    pharse_ =[]\n",
    "    for words in pharse.strip().strip('?').strip('.').strip('!').lower().split(' '):\n",
    "        for word in words.split('-'):\n",
    "            for word_ in word.split('\\''):\n",
    "                word_ = clearing_word(word_)\n",
    "                word_ = stemmer.stem(word_)\n",
    "        if word_ not in stop_word and len(word_) >1:       \n",
    "            pharse_.append(word_)        \n",
    "    return ' '.join(pharse_)\n",
    "\n",
    "def prepareData(PAIRS):\n",
    "    pairs_trains, pairs_tests = [], []\n",
    "   # PAIRS.extend(pairs1)\n",
    "    index_train = random.sample(range(len(PAIRS)), int(len(PAIRS)*0.80))\n",
    "    for i in range(len(PAIRS)):\n",
    "        if i in index_train:\n",
    "            pairs_trains.append(PAIRS[i])\n",
    "        else:\n",
    "            pairs_tests.append(PAIRS[i])\n",
    "    print(\"Read %s sentence pairs of training set\" % len(pairs_trains))\n",
    "    print(\"Read %s sentence pairs of test set\" % len(pairs_tests))\n",
    "    return pairs_trains, pairs_tests\n",
    "\n",
    "def get_all_convos(stopwords, file):\n",
    "    \n",
    "    convos = []\n",
    "    #file = 'convos27juin.txt'\n",
    "    #file1 = 'chatbot_tout_corpus.txt'\n",
    "    #file2 = 'chatbot_tout_corpus_13juin.txt'\n",
    "    #file3 = 'convos_120_nettoye.txt' # cette fichier viens d'etre ajouter\n",
    "    liste_file = [file]\n",
    "    list_of_word = []\n",
    "    for file in liste_file:\n",
    "        with open(file) as f:\n",
    "            i=0\n",
    "            for line in f:\n",
    "                if i%2==0:\n",
    "                    question = str(line)\n",
    "                    if '++++' in question:\n",
    "                         question = question[9:]\n",
    "                    question = clear_line(question, stopwords)\n",
    "                else:\n",
    "                    answer = str(line)\n",
    "                    if '++++' in answer:\n",
    "                        answer = answer[9:].strip()\n",
    "                    convos.append([question, answer])\n",
    "                i+=1\n",
    "        convos_to_return = []\n",
    "        for pair in convos:\n",
    "            if len(pair[0]) !=0:\n",
    "                convos_to_return.append(pair)\n",
    "        f.close()\n",
    "    return convos_to_return\n",
    "\n",
    "def get_list_words(convos):\n",
    "    list_words =[]\n",
    "    for pair in convos:\n",
    "        for word in pair[0].split():\n",
    "            if word not in list_words:\n",
    "                list_words.append(word)\n",
    "    print('There are {} words in corpus:'.format(len(list_words)))\n",
    "    return list_words\n",
    "                \n",
    "\n",
    "def simulation_pairs():\n",
    "    \n",
    "    DIRECT_VARIABLE = ['vitesse', 'batterie', 'position', 'km']\n",
    "    TIME = []\n",
    "    GEOGRAPHY = ['Lyon', 'hors lyon', 'paris', 'l\\'étranger','france' , 'hors la france']\n",
    "    BORDE = {'MAX': ['plus grand', 'plus grande', 'plus grands', \n",
    "         'plus grandes',\n",
    "         'plus vite', 'max', 'maximum', 'maximal', 'maximaux', 'maximale',\n",
    "        'plus haut', 'plus haute', 'plus hautes', 'plus hauts',  \n",
    "        'plus élevé', 'plus élevée', 'plus élevés', 'plus élevées'], \n",
    "         'MIN':['moins grand', 'moins grande', 'moins grands','moins grandes',\n",
    "        'plus petit', 'plus petite', 'plus petits', 'plus petites','plus faible', 'plus faibles', \n",
    "         'min', 'minimal', 'minimale', 'minimales', 'minimaux','moins vite', \n",
    "         'moins élevé', 'moins élevée', 'moins élevés', 'moins élevées'],\n",
    "        'MOYENNE': ['moyenne', 'moyen', 'moyennement']\n",
    "        }\n",
    "    COMPLEX_ANALYSIS = ['problème', 'problèmes', 'erreurs', 'erreur', 'danger']\n",
    "    PAIRS = []\n",
    "    question_for_simulation = ['quels véhicules ont', 'quel véhicule', 'quelle voiture', 'quelles voitures']\n",
    "    reponse_for_simulation = 'véhicule'\n",
    "    for borde in BORDE:\n",
    "        for word in BORDE[borde]:\n",
    "            for direct_variable in DIRECT_VARIABLE:\n",
    "                for question_f_s in question_for_simulation:\n",
    "                    if direct_variable !='position':\n",
    "                        question= question_f_s+' '+direct_variable + ' '+ word\n",
    "                        key0 = '#id#'\n",
    "                        key1 = '#'+direct_variable+'#'\n",
    "                        key2 = '#'+borde +'#'\n",
    "                        reponse = reponse_for_simulation +' '+key0+ ' '+ key1+ ' '+ key2\n",
    "                        PAIRS.append([question,reponse])\n",
    "\n",
    "    question_for_simulation = ['', 'quel véhicule a', 'quelle voiture a', 'quelles voitures ont', 'il y a']\n",
    "    reponse_for_simulation = 'véhicule' \n",
    "    for direct_variable in DIRECT_VARIABLE:\n",
    "        for complex_analysis in COMPLEX_ANALYSIS:\n",
    "            for question_f_s in question_for_simulation:\n",
    "                #if direct_variable !='position':\n",
    "                      question= question_f_s+' '+complex_analysis + ' '+ direct_variable\n",
    "                      key0 = '#id#'\n",
    "                      key1 = '#'+direct_variable+'#'\n",
    "                      key2 = '#'+ complex_analysis +'#'\n",
    "                      reponse = reponse_for_simulation +' '+key0+ ' '+ key2 +' '+ key1\n",
    "                      PAIRS.append([question,reponse])\n",
    "    return PAIRS\n",
    "\n",
    "def clear_pairs_trains(pairs_trains):\n",
    "    questions = []\n",
    "    index = []\n",
    "    for i in range(len(pairs_trains)):\n",
    "        if  pairs_trains[i][0] not in questions:\n",
    "            index.append(i)\n",
    "            questions.append(pairs_trains[i][0])\n",
    "    return [pairs_trains[i] for i in index]\n",
    "\n",
    "def tf_idf(word, doc, méthode):\n",
    "    tf, df = 0, 0\n",
    "    if word in str(doc):\n",
    "        tf = 1\n",
    "    for doc_ex in QUESTION_TO_TRAINS:\n",
    "        if word in str(doc_ex):\n",
    "            df+=1\n",
    "    if méthode  == 'normal':\n",
    "        if df>0:\n",
    "            return tf*math.log(len(QUESTION_TO_TRAINS)/(df), 10)\n",
    "        else:\n",
    "            return 0\n",
    "    if méthode == 'probabiliste':\n",
    "        if df>0:\n",
    "            return tf*math.log((len(QUESTION_TO_TRAINS)-df)/(df), 10)\n",
    "        else:\n",
    "            return 0\n",
    "    if méthode == 'lissé':\n",
    "        if df>0:\n",
    "            return tf*(1+math.log(len(QUESTION_TO_TRAINS)/df, 10))\n",
    "        else:\n",
    "            return tf\n",
    "    if méthode == 'probabiliste_lissé':\n",
    "        if df>0:\n",
    "            return tf*(1+math.log((len(QUESTION_TO_TRAINS)-df)/(df), 10))\n",
    "        else:\n",
    "            return tf\n",
    "    \n",
    "    \n",
    "def dict_doc_score(doc, méthode = 'normal'):   \n",
    "    return {word: tf_idf(word, doc, méthode) for word in doc.split()}\n",
    "   \n",
    "    \n",
    "def score_by_new_doc(new_doc, doc, DICT, méthode):\n",
    "    \n",
    "    if méthode != 'Lucene':\n",
    "        DICT_of_methode = DICT[méthode]\n",
    "        score = 0\n",
    "        for word in new_doc.split():\n",
    "            if word in DICT_of_methode[doc]:\n",
    "                 score += DICT_of_methode[doc][word]\n",
    "        return score\n",
    "    else:\n",
    "        DICT_of_methode = DICT[méthode]\n",
    "        score = 0\n",
    "        for word in new_doc.split():\n",
    "            if word in DICT_of_methode[doc]:\n",
    "                 score += DICT_of_methode[doc][word]\n",
    "        coord = 1.5*len([word for word in new_doc if word in doc])\n",
    "        return  coord*score\n",
    "    \n",
    "def get_key_list(pairs_trains):\n",
    "    \n",
    "    KEY_LIST = []\n",
    "    for pair in pairs_trains:\n",
    "        for word in pair[1].split():\n",
    "            if '#' in word and word not in KEY_LIST:\n",
    "                word = re.sub('#', '', word)\n",
    "                KEY_LIST.append(word)\n",
    "    return KEY_LIST\n",
    "        \n",
    "\n",
    "def find_right_index(new_doc,DICT, méthode = 'normal'):\n",
    "    \n",
    "    index=0\n",
    "    biggest_score = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[0],DICT, méthode)\n",
    "    for i in range(len(QUESTION_TO_TRAINS)):\n",
    "        boolean1 = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[i], DICT, méthode) >biggest_score\n",
    "        boolean2 = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[i], DICT, méthode) == biggest_score\n",
    "        boolean3 = len(QUESTION_TO_TRAINS[index]) >len(QUESTION_TO_TRAINS[i])\n",
    "        if boolean1 or (boolean2 and boolean3):\n",
    "            biggest_score = score_by_new_doc(new_doc, QUESTION_TO_TRAINS[i],DICT, méthode)\n",
    "            index = i\n",
    "    if biggest_score ==0:\n",
    "        index = len(QUESTION_TO_TRAINS)-1\n",
    "    return index\n",
    "\n",
    "def test(DICT, méthode, train =False):\n",
    "    \n",
    "    if not train:\n",
    "        index_to_print = random.sample(range(len(pairs_tests)), 20)\n",
    "        #loss_total = 0\n",
    "        for i in range(len(pairs_tests)):\n",
    "            index = find_right_index(pairs_tests[i][0], DICT, méthode)\n",
    "            #loss = _evaluate_by_right_word(pairs_trains[index][1], pairs_tests[i][1])\n",
    "            #loss_total +=loss\n",
    "            if i in index_to_print:\n",
    "                print(pairs_tests[i])\n",
    "                print(pairs_trains[index][1])\n",
    "        print('-'*80)\n",
    "       # print('ACCURACY=', 1-loss_total/len(pairs_tests))\n",
    "    if  train:\n",
    "        #loss_total = 0\n",
    "        #index_to_print = random.sample(range(len(pairs_trains)), 20)  \n",
    "        list_of_bad_prediction = []\n",
    "        i0 = 0\n",
    "        for i in range(len(pairs_trains)):\n",
    "            index = find_right_index(pairs_trains[i][0], DICT, méthode)\n",
    "            #loss = _evaluate_by_right_word(pairs_trains[index][1], pairs_trains[i][1])\n",
    "            #loss_total +=loss\n",
    "            if index != i :\n",
    "                i0 +=1\n",
    "                print(pairs_trains[i])\n",
    "                print(pairs_trains[index][1])\n",
    "        print('-'*80)\n",
    "        #print('ACCURACY=', 1-loss_total/len(pairs_trains))\n",
    "        print('Il y a {} erreurs d\\'indexes parmis {} prédictions'.format(i0, len(pairs_trains)))\n",
    "\n",
    "def test_without_print(DICT, méthode, train =False):\n",
    "    \n",
    "    if not train:\n",
    "        loss_total = 0\n",
    "        for i in range(len(pairs_tests)):\n",
    "            index = find_right_index(pairs_tests[i][0], DICT, méthode)\n",
    "            loss = _evaluate_by_right_word(pairs_trains[index][1], pairs_tests[i][1])\n",
    "            loss_total +=loss\n",
    "        print('-'*80)\n",
    "        print('ACCURACY=', 1-loss_total/len(pairs_tests))\n",
    "    if  train:\n",
    "        loss_total = 0\n",
    "        index_to_print = random.sample(range(len(pairs_trains)), 20)   \n",
    "        for i in range(len(pairs_trains)):\n",
    "            index = find_right_index(pairs_trains[i][0], DICT, méthode)\n",
    "            loss = _evaluate_by_right_word(pairs_trains[index][1], pairs_trains[i][1])\n",
    "            loss_total +=loss\n",
    "        print('-'*80)\n",
    "        print('ACCURACY=', 1-loss_total/len(pairs_trains))\n",
    "        \n",
    "        \n",
    "def chat(méthode):\n",
    "    \n",
    "    print('Bonjour, C\\'est le bot d\\'Avicen, pose tes questions, s\\'il te plaît!')\n",
    "    path = 'processed/chat_tfidf.txt'\n",
    "    f =  open(path, 'a+') \n",
    "    while True:\n",
    "            line = str(input('Vous: '))\n",
    "            LINE = clear_line(line, STOPWORDS)\n",
    "            unknown_word =0\n",
    "            for word in LINE.split():\n",
    "                if word not in LIST_OF_WORDS:\n",
    "                    unknown_word += 1\n",
    "            if unknown_word > 1:\n",
    "                print('Désolé, je ne comprends pas ta question, peux tu la reformuler s\\'il te plaît?')\n",
    "                continue\n",
    "            if len(line) !=0:\n",
    "                index= find_right_index(LINE, DICT, méthode)\n",
    "                print('bot: ', pairs_trains[index][1])\n",
    "                f.write('VOUS ++++ '+line+'\\n')\n",
    "                f.write('BOT ++++ '+pairs_trains[index][1]+'\\n')\n",
    "            \n",
    "            else:\n",
    "                f.close()\n",
    "                break \n",
    "\n",
    "def precision_recall(lstcomp, lstref):\n",
    "    \n",
    "    card_intersec = 0.0 # force à utiliser la division non entière\n",
    "    for t in set(lstcomp) :\n",
    "        card_intersec += min(lstref.count(t), lstcomp.count(t))\n",
    "    precision = card_intersec/len(lstcomp)\n",
    "    rappel = card_intersec/len(lstref)\n",
    "    return (precision, rappel)\n",
    "\n",
    "\n",
    "def test_with_precision_recall(DICT, méthode, train = False):\n",
    "    \n",
    "    if not train:\n",
    "        total_precision, total_recall = 0, 0\n",
    "        for i in range(len(pairs_tests)):\n",
    "            index = find_right_index(pairs_tests[i][0], DICT, méthode)\n",
    "            precision, recall = precision_recall\\\n",
    "            (pairs_tests[i][1], pairs_trains[index][1])\n",
    "            total_precision  += precision\n",
    "            total_recall     += recall\n",
    "        print('-'*80)\n",
    "        total_precision = total_precision/len(pairs_tests)\n",
    "        total_recall = total_recall/len(pairs_tests)      \n",
    "        F = 2*total_precision*total_recall/(total_precision+total_recall)\n",
    "        print('PRECISION = {:.5f},  RECALL = {:.5f}, F_MESURE = {:.3f} METHODE = {}'\\\n",
    "              .format(total_precision, total_recall,F, méthode))\n",
    "    if  train:\n",
    "        total_precision, total_recall = 0, 0\n",
    "        for i in range(len(pairs_trains)):          \n",
    "            index = find_right_index(pairs_trains[i][0], DICT, méthode)\n",
    "            precision, recall = precision_recall\\\n",
    "            (pairs_trains[i][1], pairs_trains[index][1])\n",
    "            total_precision  += precision\n",
    "            total_recall     += recall\n",
    "        print('-'*80)\n",
    "        total_precision = total_precision/len(pairs_trains)\n",
    "        total_recall = total_recall/len(pairs_trains)\n",
    "        F = 2*total_precision*total_recall/(total_precision+total_recall)\n",
    "        print('PRECISION = {:.5f},  RECALL = {:.5f}, F_MESURE = {:.3f} METHODE = {}'\\\n",
    "              .format(total_precision, total_recall, F, méthode))\n",
    "        \n",
    "            \n",
    "def dict_of_all_score(METHODE):\n",
    "    \"\"\"\n",
    "    return score of all word in all doc\"\"\"\n",
    "    DICT = {}\n",
    "    for méthode in METHODE:\n",
    "        dict_for_this_method ={}\n",
    "        for doc in QUESTION_TO_TRAINS:\n",
    "            dict_for_this_method[doc]=dict_doc_score(doc, méthode)\n",
    "        DICT[méthode] = dict_for_this_method\n",
    "    return DICT\n",
    "        \n",
    "def chatting_with_corpus():\n",
    "    \n",
    "    path = 'processed/chat_tfidf.txt'\n",
    "    i = 0\n",
    "    questions = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            if i%2 ==0:\n",
    "                line = line[9:]\n",
    "                line = line.lower().strip()\n",
    "                questions.append(line)\n",
    "            i +=1\n",
    "    f.close()\n",
    "    questions_clean = []\n",
    "    for question in questions:\n",
    "        if question not in questions_clean:\n",
    "            questions_clean.append(question)\n",
    "    for line in questions_clean:\n",
    "                LINE = clear_line(line, STOPWORDS)   \n",
    "                index = find_right_index(LINE, DICT, METHODE[0])\n",
    "                print('YOU: ', line)\n",
    "                print('BOT: ', pairs_trains[index][1])\n",
    "                print()\n",
    "        \n",
    "\n",
    "def get_all_and_all_convos():\n",
    "    convos = []\n",
    "    file1 = 'convos27juin_test.txt'\n",
    "    file2 = 'convos27juin_train.txt'\n",
    "    files = [file1, file2]\n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "            i=0\n",
    "            for line in f:\n",
    "                if i%2==0:\n",
    "                    question = line.strip()\n",
    "                    if '++++' in question:\n",
    "                         question = question[9:]\n",
    "                else:\n",
    "                    answer = line.strip()\n",
    "                    if '++++' in answer:\n",
    "                        answer = answer[9:]\n",
    "                    convos.append([question, answer])\n",
    "                i+=1\n",
    "        f.close()\n",
    "    return convos\n",
    "\n",
    "def clear_all_convos(all_convos, name):\n",
    "    \"\"\"\n",
    "    Supprimer tous les couples où les questions sont les mêmes\"\"\"\n",
    "    index_of_convos = []\n",
    "    question = []\n",
    "    index =0\n",
    "    for pair in all_convos:\n",
    "        if pair[0] not in question:\n",
    "            index_of_convos.append(index)\n",
    "            question.append(pair[0])\n",
    "        index +=1\n",
    "    convos = [all_convos[index] for index in index_of_convos]\n",
    "    print('Il y a {} de couples de  {}'.format(len(convos), name))\n",
    "    #print('nous avons sumpprimer {} couples parmis {} couples'.format(len(all_convos)-len(index_of_convos),index))\n",
    "    return convos\n",
    "\n",
    "def save_convos_in_file(all_convos):\n",
    "    \n",
    "    index_of_train = random.sample(range(len(all_convos)), int(len(all_convos)*0.80))\n",
    "    with open('convos6juillet_train.txt', 'w') as f:\n",
    "        for index in index_of_train:\n",
    "            pair = all_convos[index]\n",
    "            f.write('YOU ++++ '+ pair[0]+'\\n')\n",
    "            f.write('BOT ++++ '+ pair[1]+'\\n')\n",
    "    f.close()\n",
    "    with open('convos6juillet_test.txt', 'w') as f:\n",
    "        for index in range(len(all_convos)):\n",
    "            if index not in index_of_train:\n",
    "                pair = all_convos[index]\n",
    "                f.write('YOU ++++ '+ pair[0]+'\\n')\n",
    "                f.write('BOT ++++ '+ pair[1]+'\\n')\n",
    "    f.close()\n",
    "    len_test = len(all_convos)- len(index_of_train)\n",
    "    print('save {} convos in train and {} convos in test'.format(len(index_of_train), len_test))\n",
    "    \n",
    "def test_to_find_error(dict):\n",
    "    \n",
    "    index_of_error_prediction = []\n",
    "    index_of_true_pair = []\n",
    "    i = 0\n",
    "    for pair in pairs_trains:\n",
    "        index = find_right_index(pair[0],dict,  'normal')\n",
    "        if index != i:\n",
    "            index_of_error_prediction.append(index)\n",
    "            index_of_true_pair.append(i)\n",
    "        i +=1\n",
    "    for i in range(len(index_of_error_prediction)):\n",
    "        index1 = index_of_error_prediction[i]\n",
    "        index2 = index_of_true_pair[i]\n",
    "        score1 = score_by_new_doc(pairs_trains[index1][0], pairs_trains[index2][0],dict, 'normal')\n",
    "        score2 = score_by_new_doc(pairs_trains[index2][0], pairs_trains[index2][0],dict, 'normal')\n",
    "        print('False return question--- {} ---with score {}'.format(pairs_trains[index1][0], score1))\n",
    "        print('True return question--- {} ---with score {}'.format(pairs_trains[index2][0], score2))\n",
    "        \n",
    "def clear_all_trains_test_and_save_in_file(convos_train, convos_test):\n",
    "    \n",
    "    convos_train.extend(convos_test)\n",
    "    \n",
    "    \n",
    "if __name__=='__main__':\n",
    "    try:\n",
    "        pairs_trains_\n",
    "    except NameError :\n",
    "        pairs_trains = get_all_convos(STOPWORDS, 'convos27juin_train_smaller.txt')\n",
    "        pairs_tests = get_all_convos(STOPWORDS, 'convos27juin_test_smaller.txt')\n",
    "        pairs_trains = clear_all_convos(pairs_trains, 'train')\n",
    "        pairs_tests = clear_all_convos(pairs_tests, 'test')\n",
    "        LIST_OF_WORDS = get_list_words(pairs_trains)\n",
    "        KEY_LIST = get_key_list(pairs_trains)\n",
    "        QUESTION_TO_TRAINS = []\n",
    "        for pairs in pairs_trains:\n",
    "            QUESTION_TO_TRAINS.append(pairs[0])\n",
    "        METHODE = ['normal','lissé', 'probabiliste','probabiliste_lissé', 'Lucene']\n",
    "        #METHODE = ['normal']\n",
    "        DICT = dict_of_all_score(METHODE)     \n",
    "print('on train:')\n",
    "for méthode in METHODE:\n",
    "    test_with_precision_recall(DICT, méthode, train = True)\n",
    "print('On test:')\n",
    "for méthode in METHODE:\n",
    "    test_with_precision_recall(DICT, méthode, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU:  voiture immobilisée\n",
      "BOT:  #id# #arrêt#\n",
      "\n",
      "YOU:  comment tu t'appelles\n",
      "BOT:  je suis le bot d'Avicen tu peux m'appeler Emmet\n",
      "\n",
      "YOU:  je veux voir s'il y a des problèmes\n",
      "BOT:  #problème#\n",
      "\n",
      "\n",
      "YOU:  il y a problèmes\n",
      "BOT:  #problème#\n",
      "\n",
      "YOU:  il y a des urgences\n",
      "BOT:  vos urgences sont #priorité#\n",
      "\n",
      "YOU:  problème de freine\n",
      "BOT:  #ask_id# #problème# #frein#\n",
      "\n",
      "YOU:  problème de vitesse\n",
      "BOT:  véhicule #id# #problèmes# #vitesse#\n",
      "\n",
      "YOU:  combien de véhicules à l'arrêt?\n",
      "BOT:  #combien# #arrêt#\n",
      "\n",
      "YOU:  combien de véhicule à l'arrêt\n",
      "BOT:  #combien# #arrêt#\n",
      "\n",
      "YOU:  combien de véhicule en circulation\n",
      "BOT:  il y a #nb_véhicule#\n",
      "\n",
      "YOU:  il y a des véhicules hors zone définie\n",
      "BOT:  #combien# #hors_périmètre#\n",
      "\n",
      "YOU:  il y a des problèmes?\n",
      "BOT:  #problème#\n",
      "\n",
      "YOU:  il y a de problèmes\n",
      "BOT:  #problème#\n",
      "\n",
      "YOU:  coucou\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  trompé\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  je veux savoir si il y a de problème\n",
      "BOT:  #problème#\n",
      "\n",
      "\n",
      "YOU:  non, je veux savoir si tout va bien\n",
      "BOT:  ça va et toi\n",
      "\n",
      "YOU:  combien de véhicules à l'arrêt\n",
      "BOT:  #combien# #arrêt#\n",
      "\n",
      "YOU:  combien de véhicules en circulation\n",
      "BOT:  il y a #nb_véhicule#\n",
      "\n",
      "YOU:  combien de véhicules en marche\n",
      "BOT:  il y a #nb_véhicule#\n",
      "\n",
      "YOU:  nombre de trajets\n",
      "BOT:  #ask_id# #vin_seat#\n",
      "\n",
      "YOU:  combien de km au total\n",
      "BOT:  #ask_id# #km#\n",
      "\n",
      "YOU:  combien de carburant au total\n",
      "BOT:  #consommation#\n",
      "\n",
      "YOU:  salut\n",
      "BOT:  cordialement\n",
      "\n",
      "YOU:  comment tu vas\n",
      "BOT:  je vais bien merci\n",
      "\n",
      "YOU:  la flotte\n",
      "BOT:  #tco_fleet#\n",
      "\n",
      "YOU:  un résume sur flotte\n",
      "BOT:  #tco_fleet#\n",
      "\n",
      "YOU:  combien de voitures en circulation\n",
      "BOT:  le parc est composé de #nb_veh#\n",
      "\n",
      "YOU:  combien de voitures à l'arrêt\n",
      "BOT:  #combien# #arrêt#\n",
      "\n",
      "YOU:  combien de voiture à l'arrêt?\n",
      "BOT:  #combien# #arrêt#\n",
      "\n",
      "YOU:  qui est président des états-unis\n",
      "BOT:  désolé je ne sais pas peut on parler d’autre sujets ou reformuler ta question?\n",
      "\n",
      "YOU:  qui est le plus fort\n",
      "BOT:  je l'ignore. peut être moi :)\n",
      "\n",
      "YOU:  qui est le plus con\n",
      "BOT:  pourquoi t'es méchant avec un bot\n",
      "\n",
      "YOU:  qui est plus stupid\n",
      "BOT:  c’est vrai que je ne connais pas tout mais je suis toujours prêt à t’aider\n",
      "\n",
      "YOU:  a b c d e\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  qui est le plus fort que tout le monde entier\n",
      "BOT:  je l'ignore. peut être moi :)\n",
      "\n",
      "YOU:  combien km au total\n",
      "BOT:  #ask_id# #km#\n",
      "\n",
      "YOU:  combien carburant comsomé\n",
      "BOT:  #consommation#\n",
      "\n",
      "YOU:  combien carburant\n",
      "BOT:  #consommation#\n",
      "\n",
      "YOU:  carburant\n",
      "BOT:  #oui/non#\n",
      "\n",
      "YOU:  essence\n",
      "BOT:  #ask_id# #carburant#\n",
      "\n",
      "\n",
      "YOU:  essences\n",
      "BOT:  #ask_id# #carburant#\n",
      "\n",
      "\n",
      "YOU:  combien d'essence\n",
      "BOT:  #ask_id# #carburant#\n",
      "\n",
      "\n",
      "YOU:  combien\n",
      "BOT:  le parc est composé de #nb_veh#\n",
      "\n",
      "YOU:  je cherche une voiture\n",
      "BOT:  #list_vin_free#\n",
      "\n",
      "YOU:  je veux un véhicule le plus vite possible\n",
      "BOT:  véhicule #id# #km# #MAX#\n",
      "\n",
      "YOU:  quel véhicule qui roule moins vite\n",
      "BOT:  véhicule #id# #km# #MIN#\n",
      "\n",
      "YOU:  la moyenne des vitesse\n",
      "BOT:  #moyenne# #vitesse#\n",
      "\n",
      "\n",
      "YOU:  vitesse en moyenne\n",
      "BOT:  #moyenne# #vitesse#\n",
      "\n",
      "\n",
      "YOU:  je cherche un véhicule\n",
      "BOT:  #ask_id# #position#\n",
      "\n",
      "YOU:  bonjour\n",
      "BOT:  bonjour\n",
      "\n",
      "\n",
      "YOU:  est ce que tout va bien\n",
      "BOT:  ça va et toi\n",
      "\n",
      "YOU:  problème\n",
      "BOT:  #problème#\n",
      "\n",
      "YOU:  combien carburant mon véhicule a comsommé ce mois\n",
      "BOT:  #consommation#\n",
      "\n",
      "YOU:  la santé des voitures\n",
      "BOT:  #ask_id# #problème# #technique#\n",
      "\n",
      "YOU:  combien de véhicule sont à l'arrêt?\n",
      "BOT:  #combien# #arrêt#\n",
      "\n",
      "YOU:  combien de véhicule sont à lyon\n",
      "BOT:  il y a #nb_véhicule#\n",
      "\n",
      "YOU:  je veux savoir s'il y a des problèmes\n",
      "BOT:  #problème#\n",
      "\n",
      "\n",
      "YOU:  c'est qui le président de france\n",
      "BOT:  désolé je ne sais pas peut on parler d’autre sujets ou reformuler ta question?\n",
      "\n",
      "YOU:  c'est quoi\n",
      "BOT:  le tco c'est le total cost of ownership\n",
      "\n",
      "YOU:  combien kilomètrage a parcouru mon véhicule\n",
      "BOT:  #ask_id# #km#\n",
      "\n",
      "YOU:  combien de km les véhicules sont parcouru en moyenne\n",
      "BOT:  #ask_id# #km#\n",
      "\n",
      "YOU:  quelle est la distance moyenne\n",
      "BOT:  #comparer# #km#\n",
      "\n",
      "YOU:  la vitesse moyenne\n",
      "BOT:  #moyenne# #vitesse#\n",
      "\n",
      "\n",
      "YOU:  la pression de pneu est bonne\n",
      "BOT:  #ask_id# #pression#\n",
      "\n",
      "YOU:  quels sont les véhicules avec une mauvaise pression de pneu\n",
      "BOT:  #ids# #problème# #pression#\n",
      "\n",
      "\n",
      "YOU:  quels est le véhicule qui est le moins utilisé\n",
      "BOT:  #ids# #km# #MIN#\n",
      "\n",
      "\n",
      "YOU:  pannes\n",
      "BOT:  #ask_id# #problème# #technique#\n",
      "\n",
      "YOU:  combien de pannes\n",
      "BOT:  #ask_id# #problème# #technique#\n",
      "\n",
      "YOU:  nombre de places\n",
      "BOT:  #ask_id# #vin_seat#\n",
      "\n",
      "YOU:  nombre de déplacements\n",
      "BOT:  oui, #ask_id# #position#\n",
      "\n",
      "YOU:  nombre de sieges\n",
      "BOT:  #ask_id# #vin_seat#\n",
      "\n",
      "YOU:  km\n",
      "BOT:  véhicule #id# #danger# #km#\n",
      "\n",
      "YOU:  combien de km\n",
      "BOT:  #ask_id# #km#\n",
      "\n",
      "YOU:  kilometres\n",
      "BOT:  #ask_id# #km#\n",
      "\n",
      "YOU:  quel est le nombre de voiture\n",
      "BOT:  #ask_id# #vin_seat#\n",
      "\n",
      "YOU:  quel est le nombre de voitures\n",
      "BOT:  #ask_id# #vin_seat#\n",
      "\n",
      "YOU:  combien de voitures\n",
      "BOT:  le parc est composé de #nb_veh#\n",
      "\n",
      "YOU:  combien de trajets\n",
      "BOT:  #ask_id# #combien# #trajet#\n",
      "\n",
      "\n",
      "YOU:  ou est mon contrat\n",
      "BOT:  #ask_id# #date_fin_contrat#\n",
      "\n",
      "YOU:  quel est le vin\n",
      "BOT:  #ask_id# #vin#\n",
      "\n",
      "YOU:  vin\n",
      "BOT:  #ask_id# #vin#\n",
      "\n",
      "YOU:  vin?\n",
      "BOT:  #ask_id# #vin#\n",
      "\n",
      "YOU:  quel véhicule est disponible\n",
      "BOT:  #list_vin_free#\n",
      "\n",
      "YOU:  pression des pneux\n",
      "BOT:  #ask_id# #pression#\n",
      "\n",
      "YOU:  quel est le tpms\n",
      "BOT:  peut on parler d’autre sujets\n",
      "\n",
      "YOU:  tpms\n",
      "BOT:  Désolé, je ne comprends pas ta question. Peux tu la reformuler s'il te plaît?\n",
      "\n",
      "YOU:  quelle marque pneu\n",
      "BOT:  la marque des pneus est #brand_tyre#\n",
      "\n",
      "YOU:  quelle marque voiture\n",
      "BOT:  la marque des pneus est #brand_tyre#\n",
      "\n",
      "YOU:  quelle voiture\n",
      "BOT:  la liste des véhicule est #listing_vin#\n",
      "\n",
      "YOU:  bonsoir\n",
      "BOT:  bonsoir\n",
      "\n",
      "YOU:  combien de voiture\n",
      "BOT:  le parc est composé de #nb_veh#\n",
      "\n",
      "YOU:  combien de véhicule qui roulent\n",
      "BOT:  #total_veh_movement# véhicules de la société roulent\n",
      "\n",
      "YOU:  comment tu va\n",
      "BOT:  ça va merci\n",
      "\n",
      "YOU:  combien de voitures qui roulent\n",
      "BOT:  #total_veh_movement# véhicules sont en service\n",
      "\n",
      "YOU:  combien de voitures hors services\n",
      "BOT:  merci de signaler au personnel de Avicen au #numéro_avicen#\n",
      "\n",
      "YOU:  je veux une voiture\n",
      "BOT:  ton véhicule #plus_proche# #position#\n",
      "\n",
      "YOU:  veux\n",
      "BOT:  je suis là pour t'aider\n",
      "\n",
      "YOU:  va\n",
      "BOT:  ça va et toi\n",
      "\n",
      "YOU:  carburant consommé\n",
      "BOT:  #ask_id# #consumption#\n",
      "\n",
      "YOU:  combien de voitures qui consommes plus de carburant\n",
      "BOT:  #consumption# #total#\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chatting_with_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objet object\n"
     ]
    }
   ],
   "source": [
    "print(stemmer.stem('objet'), stemmer.stem('objectif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'veux savoir problem'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'je veux savoir s\\'il y a des problèmes'\n",
    "clear_line(question, STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['veux savoir problem', '#problème#\\n']\n",
      "['veux savoir où véhicul', '#ask_id# #position#']\n"
     ]
    }
   ],
   "source": [
    "for pair in pairs_trains:\n",
    "    if 'savoir' in pair[0]:\n",
    "        print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, C'est le bot d'Avicen, pose tes questions, s'il te plaît!\n",
      "Vous: c'est qui le président de France\n",
      "bot:  désolé je ne sais pas peut on parler d’autre sujets ou reformuler ta question?\n",
      "Vous: c'est quoi\n",
      "bot:  le tco c'est le total cost of ownership\n",
      "Vous: combien kilomètrage a parcouru mon véhicule\n",
      "bot:  votre véhicule a parcouru #km#\n",
      "Vous: combien de km les véhicules sont parcouru en moyenne\n",
      "bot:  votre véhicule a parcouru #km#\n",
      "Vous: \n"
     ]
    }
   ],
   "source": [
    "chat(méthode = 'normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bonjour mademoisel', 'bonjour']\n",
      "['bonjour madam', 'bonjour monsieur']\n"
     ]
    }
   ],
   "source": [
    "for pair in pairs_trains:\n",
    "    if 'bonjou' in pair[0]:\n",
    "        print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs_trains)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
